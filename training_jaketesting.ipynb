{"cells":[{"cell_type":"markdown","metadata":{"id":"PSBW6ryo-H9v"},"source":["If using google drive please edit this line to connect to drive location"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":563,"status":"ok","timestamp":1733972950361,"user":{"displayName":"Jacob Gronlund","userId":"00200772917564897839"},"user_tz":480},"id":"w6ZQ_d3W-aQq"},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2\n"]},{"cell_type":"code","execution_count":100,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2781,"status":"ok","timestamp":1733987723299,"user":{"displayName":"Jacob Gronlund","userId":"00200772917564897839"},"user_tz":480},"id":"1YCGTlkW99pN","outputId":"18bccdb1-08a7-4ad9-fe37-ccbc797d9e91"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n","best_model_jake_12_10.pth\t recipe_checkpoint_12-08_23-15__Trial_2-best_model.pth\n","best_model_jake.pth\t\t recipe_checkpoint_12-09_22-53__Trial_4-best_model.pth\n","best_model.pth\t\t\t recipe_checkpoint_12-11_01-33__Trial_2-best_model.pth\n","image_2_recipe_bk.py\t\t recipe_embeddings_12_10_emilys.pth\n","image_2_recipe.py\t\t recipe_embeddings_12_10_jake_changegrad.pth\n","image_embeddings_proj_em_11.pth  recipe_embeddings_12_10_jake_noimage.pth\n","image_encoder.py\t\t recipe_embeddings_12_9_emilys.pth\n","MMR_jakes.py\t\t\t recipe_embeddings_12_9.pth\n","MMR_old.py\t\t\t recipe_embeddings_proj_em_11.pth\n","MMR.py\t\t\t\t recipe_embeddings.pth\n","MMR.py_clamp\t\t\t recipe_encoder_draft.py\n","__pycache__\t\t\t recipe_encoder.py\n"]}],"source":["from google.colab import drive\n","import os, sys\n","\n","# Mount the google colab\n","drive.mount(\"/content/drive/\")\n","GOOGLE_DRIVE_PATH_POST_MYDRIVE = 'DeepLearning_GroupProject/'\n","GOOGLE_DRIVE_PATH = os.path.join('/content', 'drive', 'MyDrive', GOOGLE_DRIVE_PATH_POST_MYDRIVE)\n","!ls {GOOGLE_DRIVE_PATH}/models\n","sys.path.append(GOOGLE_DRIVE_PATH)\n","\n","# GOOGLE_DRIVE_PATH = '.'\n","\n","\n","# relative paths\n","models_dir = 'models'\n","csv_path = 'Data/updated_data_with_lists.csv'\n","tensors_dir = 'Data/tensor_batch_notaugmented'"]},{"cell_type":"code","execution_count":101,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":224},"executionInfo":{"elapsed":774,"status":"ok","timestamp":1733987724070,"user":{"displayName":"Jacob Gronlund","userId":"00200772917564897839"},"user_tz":480},"id":"sGHSvkJG5fbt","outputId":"22b11abc-1324-4781-817d-69cc0922bf1b"},"outputs":[{"output_type":"stream","name":"stdout","text":["13496\n"]},{"output_type":"execute_result","data":{"text/plain":["   Unnamed: 0                                              Title  \\\n","0           0  Miso-Butter Roast Chicken With Acorn Squash Pa...   \n","1           1                    Crispy Salt and Pepper Potatoes   \n","2           2                        Thanksgiving Mac and Cheese   \n","3           3                 Italian Sausage and Bread Stuffing   \n","4           4                                       Newton's Law   \n","\n","                                        Instructions  \\\n","0  [Pat chicken dry with paper towels, season all...   \n","1  [Preheat oven to 400°F and line a rimmed bakin...   \n","2  [Place a rack in middle of oven; preheat to 40...   \n","3  [Preheat oven to 350°F with rack in middle. Ge...   \n","4  [Stir together brown sugar and hot water in a ...   \n","\n","                                          Image_Name  \\\n","0  miso-butter-roast-chicken-acorn-squash-panzanella   \n","1         crispy-salt-and-pepper-potatoes-dan-kluger   \n","2         thanksgiving-mac-and-cheese-erick-williams   \n","3          italian-sausage-and-bread-stuffing-240559   \n","4                 newtons-law-apple-bourbon-cocktail   \n","\n","                                 Cleaned_Ingredients  \n","0  [1 (3½–4-lb.) whole chicken, 2¾ tsp. kosher sa...  \n","1  [2 large egg whites, 1 pound new potatoes (abo...  \n","2  [1 cup evaporated milk, 1 cup whole milk, 1 ts...  \n","3  [1 (¾- to 1-pound) round Italian loaf, cut int...  \n","4  [1 teaspoon dark brown sugar, 1 teaspoon hot w...  "],"text/html":["\n","  <div id=\"df-28f49dc9-9b9c-4e4a-b3d2-32b8d618a10a\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Unnamed: 0</th>\n","      <th>Title</th>\n","      <th>Instructions</th>\n","      <th>Image_Name</th>\n","      <th>Cleaned_Ingredients</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>Miso-Butter Roast Chicken With Acorn Squash Pa...</td>\n","      <td>[Pat chicken dry with paper towels, season all...</td>\n","      <td>miso-butter-roast-chicken-acorn-squash-panzanella</td>\n","      <td>[1 (3½–4-lb.) whole chicken, 2¾ tsp. kosher sa...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Crispy Salt and Pepper Potatoes</td>\n","      <td>[Preheat oven to 400°F and line a rimmed bakin...</td>\n","      <td>crispy-salt-and-pepper-potatoes-dan-kluger</td>\n","      <td>[2 large egg whites, 1 pound new potatoes (abo...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>Thanksgiving Mac and Cheese</td>\n","      <td>[Place a rack in middle of oven; preheat to 40...</td>\n","      <td>thanksgiving-mac-and-cheese-erick-williams</td>\n","      <td>[1 cup evaporated milk, 1 cup whole milk, 1 ts...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>Italian Sausage and Bread Stuffing</td>\n","      <td>[Preheat oven to 350°F with rack in middle. Ge...</td>\n","      <td>italian-sausage-and-bread-stuffing-240559</td>\n","      <td>[1 (¾- to 1-pound) round Italian loaf, cut int...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>Newton's Law</td>\n","      <td>[Stir together brown sugar and hot water in a ...</td>\n","      <td>newtons-law-apple-bourbon-cocktail</td>\n","      <td>[1 teaspoon dark brown sugar, 1 teaspoon hot w...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-28f49dc9-9b9c-4e4a-b3d2-32b8d618a10a')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-28f49dc9-9b9c-4e4a-b3d2-32b8d618a10a button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-28f49dc9-9b9c-4e4a-b3d2-32b8d618a10a');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-7406b704-d0cf-4a88-8897-756ff65a2a85\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7406b704-d0cf-4a88-8897-756ff65a2a85')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-7406b704-d0cf-4a88-8897-756ff65a2a85 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 13496,\n  \"fields\": [\n    {\n      \"column\": \"Unnamed: 0\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3896,\n        \"min\": 0,\n        \"max\": 13500,\n        \"num_unique_values\": 13496,\n        \"samples\": [\n          6173,\n          833,\n          3289\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 13305,\n        \"samples\": [\n          \"Whole Grilled Fish with Lime\",\n          \"Espresso Chocolate Sable\\u0301s\",\n          \"Turkey Shawarma With Crunchy Vegetables\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Instructions\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Image_Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 13467,\n        \"samples\": [\n          \"asparagus-green-onion-cucumber-and-herb-salad-241637\",\n          \"mushroom-and-fontina-quiche-355191\",\n          \"grill-roasted-pineapple\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Cleaned_Ingredients\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":101}],"source":["import pandas as pd\n","from ast import literal_eval\n","import numpy as np\n","import torch\n","\n","# Explicitly adding models to the search path\n","models_path = os.path.join(GOOGLE_DRIVE_PATH, models_dir)\n","if models_path not in sys.path:\n","    sys.path.insert(0, models_path)\n","\n","from models import recipe_encoder\n","from models import MMR_jakes\n","csv_file = os.path.join(GOOGLE_DRIVE_PATH,csv_path)\n","df = pd.read_csv(csv_file, converters={\"Cleaned_Ingredients\": literal_eval, \"Instructions\": literal_eval})\n","print(len(df))\n","df.head()"]},{"cell_type":"markdown","metadata":{"id":"Zhh--PCsDH3b"},"source":["Concatenate the batches of preprocessed images into 1 tensor"]},{"cell_type":"code","execution_count":102,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4041,"status":"ok","timestamp":1733987728100,"user":{"displayName":"Jacob Gronlund","userId":"00200772917564897839"},"user_tz":480},"id":"Wi-yY_TlDHPn","outputId":"2013c959-07c4-431a-ae82-3235ccdf0e4c"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-102-ae3aa98ed976>:11: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  image_tensors, image_labels = torch.load(pt_filepath)\n"]},{"output_type":"stream","name":"stdout","text":["Loaded batch_0.pt\n","Loaded batch_1.pt\n","Loaded batch_2.pt\n","Loaded batch_3.pt\n","Loaded batch_4.pt\n","Number of images: 5000\n","Number of labels: 5000\n"]}],"source":["pt_files = os.listdir(os.path.join(GOOGLE_DRIVE_PATH,tensors_dir))\n","all_image_tensors = []\n","all_image_labels = []\n","\n","# Load and combine all .pt files\n","file_name = \"batch_\"\n","# for pt_file in pt_files[:5]:\n","for num in range(0,5):\n","    pt_file = file_name + str(num) + \".pt\"\n","    pt_filepath = os.path.join(GOOGLE_DRIVE_PATH,tensors_dir,pt_file)\n","    image_tensors, image_labels = torch.load(pt_filepath)\n","    all_image_tensors.append(image_tensors)\n","    all_image_labels.extend(image_labels)\n","    print(f\"Loaded {pt_file}\")\n","\n","# Concatenate tensors\n","all_image_tensors = torch.cat(all_image_tensors)\n","print(f\"Number of images: {all_image_tensors.size(0)}\")\n","print(f\"Number of labels: {len(all_image_labels)}\")\n","assert all_image_tensors.size(0) == len(all_image_labels), \"Mismatch between images and labels!\""]},{"cell_type":"markdown","metadata":{"id":"xPDFYvqaJv5w"},"source":["Reorganize dataframe to be in the same order as the Image Tensors using the image_label as the matching key"]},{"cell_type":"code","execution_count":103,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":531,"status":"ok","timestamp":1733987728622,"user":{"displayName":"Jacob Gronlund","userId":"00200772917564897839"},"user_tz":480},"id":"rtFcFs4-Ji7b","outputId":"ff8b1d5a-0229-473a-a653-975061ea26bf"},"outputs":[{"output_type":"stream","name":"stdout","text":["['spanish-style-grilled-vegetables-with-breadcrumb-picada-238806', 'three-cheese-pizza-with-onion-sage-and-arugula-233543', 'speedy-skillet-ravioli-lasagna', 'summer-anchovy-salad-51108430', 'spice-roasted-cornish-hens-with-cucumber-yogurt-sauce-353418', 'stovetop-butterscotch-apples-and-cranberries', 'tarte-tatin-51196820', 'spanish-olive-and-cream-cheese-canapes-231160', 'spice-rubbed-sustainable-fish-sliders', 'spiced-pumpkin-layer-cake-240123']\n","2            thanksgiving-mac-and-cheese-erick-williams\n","5                  warm-comfort-tequila-chamomile-toddy\n","7                     turmeric-hot-toddy-claire-sprouse\n","9        spiced-lentil-and-caramelized-onion-baked-eggs\n","11          spiral-ham-in-the-slow-cooker-guarnaschelli\n","19    roasted-beets-with-crispy-sunchokes-and-pickle...\n","24    sloppy-joe-shirred-eggs-with-spinach-vivian-ho...\n","27                           spicy-coconut-pumpkin-soup\n","30                                trinidad-curry-powder\n","31                                  shrimp-creole-14653\n","Name: Image_Name, dtype: object\n","(13496, 5)\n","(4968, 5) 5000\n","Number of filtered tensors: 4968\n","Number of filtered labels: 4968\n","Number of rows in filtered_df: 4968\n","0    spanish-style-grilled-vegetables-with-breadcru...\n","1    three-cheese-pizza-with-onion-sage-and-arugula...\n","2                       speedy-skillet-ravioli-lasagna\n","3                        summer-anchovy-salad-51108430\n","4    spice-roasted-cornish-hens-with-cucumber-yogur...\n","5         stovetop-butterscotch-apples-and-cranberries\n","6                                 tarte-tatin-51196820\n","7        spanish-olive-and-cream-cheese-canapes-231160\n","8                spice-rubbed-sustainable-fish-sliders\n","9                     spiced-pumpkin-layer-cake-240123\n","Name: Image_Name, dtype: object\n"]}],"source":["##Reset order of dataframe to match the image labels orders\n","all_image_labels_cleaned = [label.split(\".\")[0] for label in all_image_labels] #remove the .png and .jgp\n","print(all_image_labels_cleaned[:10]) #print to see if at the end the df matches\n","\n","filtered_df = df[df[\"Image_Name\"].isin(all_image_labels_cleaned)] #filter the df to only have values from the images\n","print(filtered_df[\"Image_Name\"][:10])\n","print(df.shape)\n","print(filtered_df.shape, len(all_image_labels_cleaned))\n","\n","valid_labels = set(filtered_df['Image_Name'])\n","\n","# Filter labels and tensors\n","filtered_labels_and_tensors = [\n","    (tensor, label) for tensor, label in zip(all_image_tensors, all_image_labels_cleaned) if label in valid_labels\n","]\n","\n","# Unpack the filtered data\n","filtered_tensors, filtered_labels = zip(*filtered_labels_and_tensors)\n","\n","# Convert back to tensors\n","filtered_tensors = torch.stack(filtered_tensors)\n","filtered_labels = list(filtered_labels)\n","\n","# Verify alignment\n","print(f\"Number of filtered tensors: {len(filtered_tensors)}\")\n","print(f\"Number of filtered labels: {len(filtered_labels)}\")\n","print(f\"Number of rows in filtered_df: {len(filtered_df)}\")\n","\n","# Finally reorganize the df to be in the same order as the image tensors\n","filtered_df = filtered_df.set_index(\"Image_Name\").loc[filtered_labels].reset_index()\n","print(filtered_df[\"Image_Name\"][:10])"]},{"cell_type":"markdown","metadata":{"id":"mFbLiKRFJxmj"},"source":["Reformat Ingredients, Recipes, and Image titles"]},{"cell_type":"markdown","metadata":{"id":"XgK81ynndVtG"},"source":["Tokenize Recipes, Ingredients, and Image Titles"]},{"cell_type":"code","execution_count":104,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":35305,"status":"ok","timestamp":1733987764979,"user":{"displayName":"Jacob Gronlund","userId":"00200772917564897839"},"user_tz":480},"id":"wyHgDU2OmUO0","outputId":"efeb676d-13cf-4e3d-8255-c6ff9b5196e8"},"outputs":[{"output_type":"stream","name":"stdout","text":["1\n","[[101, 1017, 2312, 2417, 4330, 23582, 1006, 2055, 1015, 1015, 1013, 1016, 7038, 1007, 1010, 27674, 1010, 13916, 1010, 4284, 2098, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1018, 2312, 2887, 8288, 24759, 11390, 1006, 2055, 1015, 1015, 1013, 1018, 7038, 1007, 1010, 21920, 1010, 3013, 3091, 14244, 2046, 1017, 25609, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1018, 5396, 2665, 2030, 3756, 16950, 25955, 3490, 1006, 9544, 8231, 1016, 1997, 2169, 1025, 2055, 1015, 9044, 1007, 1010, 21920, 1010, 3013, 3091, 14244, 2046, 1015, 1013, 1017, 1011, 4960, 1011, 4317, 25609, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 4469, 1011, 6261, 9724, 3514, 1006, 2005, 18651, 2075, 1007, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1020, 7251, 24667, 3619, 4469, 1011, 6261, 9724, 3514, 1010, 4055, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1016, 20548, 18856, 21818, 2015, 1010, 22126, 24881, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1015, 1013, 1016, 5572, 13102, 7828, 9550, 10560, 2417, 11565, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1015, 1013, 1016, 2452, 6090, 3683, 1006, 2887, 7852, 26775, 25438, 2015, 1007, 1008, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1016, 7251, 24667, 3619, 22268, 4511, 29387, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1015, 1013, 1018, 2452, 24881, 4840, 3059, 11968, 8002, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1016, 7251, 24667, 3619, 24881, 4840, 10848, 29451, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1008, 2800, 1999, 1996, 4004, 9440, 2930, 1997, 2070, 26676, 1998, 2012, 4004, 6089, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n","[[101, 7374, 26375, 1006, 5396, 3684, 1007, 1012, 13621, 11546, 2006, 21522, 8697, 1012, 8248, 2007, 3514, 1025, 11867, 6657, 19099, 2007, 5474, 1998, 11565, 1012, 18651, 23582, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 3096, 2217, 2091, 1998, 2302, 3810, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2127, 25788, 1998, 1038, 9863, 6850, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 3048, 5681, 2005, 2130, 8434, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2055, 2184, 2781, 1012, 4372, 20464, 9232, 1999, 6081, 4524, 1012, 2292, 3233, 2127, 21049, 29476, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2055, 2382, 2781, 1012, 18651, 8288, 24759, 11390, 1998, 16950, 25955, 3490, 2127, 29030, 1998, 8616, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 3810, 1998, 4373, 24388, 2075, 2005, 2130, 18778, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1019, 2000, 1020, 2781, 1012, 2173, 2006, 17910, 18194, 21522, 7123, 1012, 14113, 23582, 1012, 4651, 2000, 7123, 2007, 8288, 24759, 11390, 1998, 16950, 25955, 3490, 1012, 3684, 1017, 7251, 24667, 3619, 9724, 3514, 1999, 5396, 8066, 3388, 2058, 5396, 3684, 1012, 5587, 20548, 1998, 10560, 2417, 11565, 1025, 16130, 2127, 25312, 18980, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2055, 2382, 3823, 1012, 5587, 7852, 26775, 25438, 2015, 1025, 16130, 2127, 3585, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2055, 1017, 2781, 1012, 2161, 7852, 26775, 25438, 27263, 8447, 2000, 5510, 2007, 5474, 1025, 26988, 2046, 2235, 4605, 1012, 2173, 29387, 1999, 2178, 2235, 4605, 1025, 1059, 24158, 2243, 1999, 1017, 7251, 24667, 3619, 3514, 1012, 4666, 1999, 11968, 8002, 1998, 10848, 29451, 1012, 2161, 2000, 5510, 2007, 5474, 1012, 13621, 11546, 2006, 28005, 2121, 1012, 15642, 12810, 11225, 2058, 1025, 11867, 6657, 19099, 2007, 7852, 26775, 25438, 2015, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n"]}],"source":["from transformers import AutoTokenizer\n","total_max = 128\n","# Initialize the tokenizer\n","tokenizer_recipes = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n","\n","def tokenize_nested_list(nested_list, max_length=128):\n","    \"\"\"\n","    Tokenizes a nested list of strings (list of ingredients per recipe).\n","    Each inner list is tokenized into a list of token IDs.\n","    \"\"\"\n","    tokenized_list = []\n","    for sublist in nested_list:\n","        # Join the inner list into a string\n","        # text = \" \".join(sublist)\n","        text = str(sublist)\n","        # Tokenize the string\n","        tokens = tokenizer_recipes(\n","            text,\n","            max_length=max_length,\n","            padding=\"max_length\",\n","            truncation=True,\n","            return_tensors=\"pt\",\n","        )\n","        # Append tokenized input_ids to the result list\n","        tokenized_list.append(tokens[\"input_ids\"].squeeze(0).tolist())\n","    return tokenized_list\n","\n","filtered_df['Title_List'] = df['Title'].apply(lambda x: [x])\n","filtered_df['tokenized_ingredients'] = filtered_df['Cleaned_Ingredients'].apply(lambda x: tokenize_nested_list(x, total_max))\n","filtered_df['tokenized_instructions'] = filtered_df['Instructions'].apply(lambda x: tokenize_nested_list(x, total_max))\n","filtered_df['tokenized_titles'] = filtered_df['Title_List'].apply(lambda x: tokenize_nested_list(x, total_max))\n","\n","\n","print(len(filtered_df[\"tokenized_titles\"][0]))\n","print(filtered_df[\"tokenized_ingredients\"][0])\n","print(filtered_df[\"tokenized_instructions\"][0])\n"]},{"cell_type":"code","execution_count":105,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1733987764980,"user":{"displayName":"Jacob Gronlund","userId":"00200772917564897839"},"user_tz":480},"id":"52oSgq6k7Ldn","outputId":"99bf013e-bc06-46c2-ce93-06e33123b8cf"},"outputs":[{"output_type":"stream","name":"stdout","text":["42 23 1\n","42\n","[[101, 1015, 1013, 1018, 2452, 9724, 3514, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1016, 3009, 24444, 1010, 20956, 1998, 4857, 2135, 15920, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1016, 2312, 18856, 21818, 2015, 20548, 1010, 20956, 1998, 24881, 1010, 4606, 1018, 18856, 21818, 2015, 2878, 20548, 1010, 20956, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1015, 2452, 4318, 2317, 4511, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1016, 3016, 3727, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1020, 7251, 24667, 3619, 4895, 12002, 3064, 12136, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 10869, 1997, 1016, 14380, 2015, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1016, 1006, 1018, 1011, 9044, 1007, 2878, 2417, 10245, 7347, 1010, 12176, 1010, 2007, 2132, 1998, 5725, 10109, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1015, 2235, 20856, 1010, 15920, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1016, 10335, 8292, 3917, 2100, 1010, 11085, 7178, 2892, 14244, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 10869, 1997, 2184, 3145, 14123, 2015, 2030, 2235, 4857, 1011, 19937, 14123, 2015, 1010, 4606, 1018, 14123, 2015, 3013, 2046, 7728, 2005, 3529, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1015, 1013, 1016, 2452, 20392, 2135, 24881, 4840, 25022, 5802, 13181, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1015, 1006, 2260, 1011, 2011, 2324, 1011, 4960, 2030, 3469, 1007, 25043, 2075, 6090, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n","(4968, 9)\n"]}],"source":["def pad_or_truncate_nested(sublist, target_length, max_length, pad_token=0):\n","        \"\"\"\n","            Pad or truncate the outer list of a nested list to match the target_length.\n","            Each inner list remains untouched.\n","        \"\"\"\n","        # Pad with [pad_token] or truncate the outer list\n","        if len(sublist) < target_length:\n","            sublist.extend([[pad_token]* max_length] * (target_length - len(sublist)))\n","        else:\n","            sublist = sublist[:target_length]\n","        return sublist\n","\n","max_length_ing = filtered_df['tokenized_ingredients'].apply(len).max()\n","max_length_inst = filtered_df['tokenized_instructions'].apply(len).max()//4\n","max_length_title = filtered_df['tokenized_titles'].apply(len).max()\n","filtered_df['tokenized_ingredients'] = filtered_df['tokenized_ingredients'].apply(\n","    lambda ing: pad_or_truncate_nested(ing, max_length_ing,total_max))\n","\n","filtered_df['tokenized_instructions'] = filtered_df['tokenized_instructions'].apply(\n","    lambda inst: pad_or_truncate_nested(inst, max_length_inst, total_max))\n","# new_token_ing = [pad_or_truncate_nested(ing, max_length_title) for ing in tokenized_ingredients] #titles were all list length of 1\n","max_length_ing = filtered_df['tokenized_ingredients'].apply(len).max()\n","max_length_inst = filtered_df['tokenized_instructions'].apply(len).max()\n","max_length_title = filtered_df['tokenized_titles'].apply(len).max()\n","print(max_length_ing, max_length_inst, max_length_title)\n","print(len(filtered_df['tokenized_ingredients'][5]))\n","print(filtered_df['tokenized_ingredients'][100])\n","print(filtered_df.shape)"]},{"cell_type":"markdown","metadata":{"id":"1jZ1lhBw2DnV"},"source":["Tokenize the Image Labels for the Image Encoder"]},{"cell_type":"code","execution_count":106,"metadata":{"executionInfo":{"elapsed":2163,"status":"ok","timestamp":1733987767139,"user":{"displayName":"Jacob Gronlund","userId":"00200772917564897839"},"user_tz":480},"id":"w8EKVqNG2CGJ"},"outputs":[],"source":["from transformers import AutoTokenizer\n","from transformers import CLIPModel\n","model_name = \"openai/clip-vit-base-patch16\"\n","clip_model = CLIPModel.from_pretrained(model_name)\n","tokenizer_images = AutoTokenizer.from_pretrained(model_name)\n","\n","tokenized_labels = tokenizer_images(\n","    filtered_labels,\n","    padding=\"max_length\",\n","    truncation=True,\n","    max_length=tokenizer_images.model_max_length,\n","    return_tensors=\"pt\"\n",")"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11,"status":"ok","timestamp":1733974933061,"user":{"displayName":"Jacob Gronlund","userId":"00200772917564897839"},"user_tz":480},"id":"ilxU3rfNFI8j","outputId":"3f37d40d-f24b-429d-f592-a22b9d0f3bfe"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda:0\n"]}],"source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)\n","%reload_ext autoreload\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cOR7eQshjPKL"},"outputs":[],"source":["import torch.nn as nn\n","class RecipeDecoder(nn.Module):\n","    def __init__(self, embedding_dim, hidden_dim, vocab_size):\n","        super(RecipeDecoder, self).__init__()\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n","        self.rnn = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n","        self.fc_out = nn.Linear(hidden_dim, vocab_size)\n","        self.hidden_dim = hidden_dim\n","\n","    def forward(self, input_tokens):\n","        embedded = self.embedding(input_tokens)\n","        outputs, hidden_state = self.rnn(embedded, hidden_state)\n","        predictions = self.fc_out(outputs)\n","        return predictions"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":265,"status":"ok","timestamp":1733974180439,"user":{"displayName":"Jacob Gronlund","userId":"00200772917564897839"},"user_tz":480},"id":"N_UNJWI5GMCg"},"outputs":[],"source":["def calc_recall_name(top, image_features, recipe_embeddings, image_indices):\n","  true_pos = 0\n","  false_neg = 0\n","  tmp_batches = image_features.shape[0]\n","  # image_features = torch.nn.functional.normalize(image_features, dim=1)\n","  # recipe_embeddings = torch.nn.functional.normalize(recipe_embeddings, dim=1)\n","  top_embedded = []\n","  for i in range(tmp_batches):\n","    cosine_similarity = torch.nn.CosineSimilarity(dim=1)\n","    # similarities = cosine_similarity(image_features[i, :].unsqueeze(0), recipe_embeddings)\n","    similarities = cosine_similarity(image_features[i,:], recipe_embeddings)\n","    #top = amount of top results to retrieve\n","    top_results = top\n","    top_k_values, top_k_indices = torch.topk(similarities, top_results, largest=True)\n","    top_k_indices = top_k_indices.tolist()\n","    # top_images = [filtered_df['Image_Name'].iloc[i] for i in top_k_indices]\n","    # top_embedded.append(recipe_embeddings[top_k_indices[0]].detach().cpu().numpy())\n","    # print(top_k_values, top_k_indices)\n","    # print(\"Correct Image label: \", image_labels[i])\n","    print(top_k_indices)\n","    # print(top_images)\n","    # image_labels_str = image_labels[i].split(\".\")[0]\n","    if image_indices[i] in top_k_indices:\n","      print(\"found\")\n","      true_pos += 1\n","    else:\n","      false_neg += 1\n","    # if image_labels_str in [image for image in top_images]:\n","    #   print(\"found\")\n","    #   true_pos += 1\n","    # else:\n","    #   false_neg += 1\n","  print(\"total found = \", true_pos)\n","  # plot_2D(top_embedded, image_features, multiplier=None, batch_size=None)\n","  return true_pos\n"]},{"cell_type":"code","source":["def calc_recall_showimages(top, image_features, recipe_embeddings, image_indices, selected_images, image_label):\n","  true_pos = 0\n","  false_neg = 0\n","  tmp_batches = image_features.shape[0]\n","  image_features = torch.nn.functional.normalize(image_features, dim=1)\n","  recipe_embeddings = torch.nn.functional.normalize(recipe_embeddings, dim=1)\n","  top_embedded = []\n","  for i in range(tmp_batches):\n","    cosine_similarity = torch.nn.CosineSimilarity(dim=1)\n","    similarities = cosine_similarity(image_features[i,:], recipe_embeddings)\n","    top_results = top\n","    top_k_values, top_k_indices = torch.topk(similarities, top_results, largest=True)\n","    top_k_indices = top_k_indices.tolist()\n","    # print(len(image_label), top_k_indices)\n","    # print(i, selected_images)\n","    if i in selected_images:\n","      top_images = [image_label[num] for num in top_k_indices]\n","      print(\"----------------------------\")\n","      print(\"Correct Image \",image_label[image_indices[i]])\n","      print(\"Retrieved Images \",top_images)\n","      print(\"----------------------------\")\n","    if image_indices[i] in top_k_indices:\n","      true_pos += 1\n","      top_images = [image_label[num] for num in top_k_indices]\n","      print(\"----------------------------\")\n","      print(\"Correct Image \",image_label[image_indices[i]])\n","      print(\"Retrieved Images \",top_images)\n","      print(\"----------------------------\")\n","    else:\n","      false_neg += 1\n","  print(\"total found = \", true_pos)\n","  return true_pos"],"metadata":{"id":"FB6kbkfUVAln","executionInfo":{"status":"ok","timestamp":1733984449620,"user_tz":480,"elapsed":1542,"user":{"displayName":"Jacob Gronlund","userId":"00200772917564897839"}}},"execution_count":91,"outputs":[]},{"cell_type":"code","source":["def calc_recall_id(top, image_features, recipe_embeddings, image_indices):\n","  true_pos = 0\n","  false_neg = 0\n","  tmp_batches = image_features.shape[0]\n","  image_features = torch.nn.functional.normalize(image_features, dim=1)\n","  recipe_embeddings = torch.nn.functional.normalize(recipe_embeddings, dim=1)\n","  top_embedded = []\n","  for i in range(tmp_batches):\n","    cosine_similarity = torch.nn.CosineSimilarity(dim=1)\n","    similarities = cosine_similarity(image_features[i,:], recipe_embeddings)\n","    top_results = top\n","    top_k_values, top_k_indices = torch.topk(similarities, top_results, largest=True)\n","    top_k_indices = top_k_indices.tolist()\n","\n","    # print(top_k_indices)\n","    if image_indices[i] in top_k_indices:\n","      true_pos += 1\n","    else:\n","      false_neg += 1\n","  print(\"total found = \", true_pos)\n","  return true_pos"],"metadata":{"id":"8W4J4gre0Zsy","executionInfo":{"status":"ok","timestamp":1733987929993,"user_tz":480,"elapsed":789,"user":{"displayName":"Jacob Gronlund","userId":"00200772917564897839"}}},"execution_count":112,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4UgBJbpbkOcL"},"outputs":[],"source":["###Function for printing images and labels to check that the ordering is correct\n","\n","mean = [0.485, 0.456, 0.406]  # Mean for RGB channels\n","std = [0.229, 0.224, 0.225]   # Std for RGB channels\n","import matplotlib.pyplot as plt\n","\n","# Function to unnormalize\n","def unnormalize(tensor, mean, std):\n","    for t, m, s in zip(tensor, mean, std):\n","        t.mul_(s).add_(m)  # Scale by std, then add mean\n","    return tensor\n","\n","def print_out_pic(images, image_labels):\n","    for i in range(images.shape[0]):\n","        tensor = images[i]\n","        image_label = image_labels[i]\n","        tensor = tensor.cpu()\n","        tensor = unnormalize(tensor, mean, std)  # Reverse normalization\n","        tensor = tensor.permute(1, 2, 0).numpy()  # Rearrange to HWC format\n","\n","        plt.imshow(tensor)\n","        plt.title(image_label)\n","        plt.axis('off')\n","        plt.show()"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":2140,"status":"ok","timestamp":1733974191736,"user":{"displayName":"Jacob Gronlund","userId":"00200772917564897839"},"user_tz":480},"id":"5crWXR2dyzQ9"},"outputs":[],"source":["###Plot in tSNE to debug\n","from sklearn.manifold import TSNE\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import numpy as np\n","def plot_2D(recipe_embeddings, image_embeddings, multiplier=None, batch_size=None):\n","  batches = image_embeddings.shape[0]\n","  try:\n","    recipe_embeddings = recipe_embeddings.detach().cpu().numpy()\n","  except:\n","    recipe_embeddings = recipe_embeddings\n","  # print(type(recipe_embeddings))\n","  image_embeddings = image_embeddings.detach().cpu().numpy()\n","  combined_embeddings = np.concatenate((recipe_embeddings, image_embeddings), axis=0)\n","  x_list = np.arange(512)\n","  # print(x_list.shape)\n","  # print(recipe_embeddings[0])\n","  embedding_size = image_embeddings.shape[1]\n","  for batch in range(batches):\n","    plt.figure(figsize=(8, 8))\n","    if multiplier is not None:\n","      rec_batch = (multiplier*batch_size) + batch\n","      plt.scatter(np.arange(embedding_size), recipe_embeddings[rec_batch,:], label=f\"Recipe Embeddings {rec_batch}\", alpha=0.7)\n","      plt.scatter(np.arange(embedding_size), image_embeddings[batch,:], label=f\"Image Embeddings {rec_batch}\", alpha=0.7)\n","    else:\n","      plt.scatter(np.arange(embedding_size), recipe_embeddings[batch], label=f\"Recipe Embeddings {batch}\", alpha=0.7)\n","      plt.scatter(np.arange(embedding_size), image_embeddings[batch], label=f\"Image Embeddings {batch}\", alpha=0.7)\n","    plt.legend()\n","    plt.title(\"2D Visualization of Image and Recipe Embeddings\")\n","    plt.xlabel(\"Recipe Embedding\")\n","    plt.ylabel(\"Image Embedding\")\n","    plt.show()\n","\n","def plot_tsne(recipe_embeddings_batches, image_embeddings_batches):\n","  batches = image_embeddings_batches.shape[0]\n","  # recipe_3d = recipe_embeddings_batches.unsqueeze(0)\n","  # image_3d = image_embeddings_batches.unsqueeze(0)\n","  combined_embeddings = torch.cat((recipe_embeddings_batches, image_embeddings_batches), dim=0)\n","  np_embeddings = combined_embeddings.detach().cpu().numpy()\n","  print(np_embeddings.shape)\n","  tsne = TSNE(n_components=2, random_state=42, perplexity=9)\n","\n","  reduced_embeddings = tsne.fit_transform(np_embeddings)\n","\n","  # Separate reduced embeddings for visualization\n","  # num_images = np_embeddings.shape[1]\n","  # reduced_image_embeddings = reduced_embeddings[:num_images]\n","  # reduced_recipe_embeddings = reduced_embeddings[num_images:]\n","  print(reduced_embeddings.shape)\n","  # Plot the embeddings\n","  plt.figure(figsize=(8, 8))\n","  for batch in range(batches):\n","    plt.scatter(reduced_embeddings[batch+batches,:], reduced_embeddings[batch,:], label=f\"Embeddings {batch}\", alpha=0.7)\n","  plt.legend()\n","  plt.title(\"t-SNE Visualization of Image and Recipe Embeddings\")\n","  plt.xlabel(\"t-SNE Dim 1\")\n","  plt.ylabel(\"t-SNE Dim 2\")\n","  plt.show()\n","\n","def plot_tsne_recipefull(recipe_embeddings_batches):\n","  batches = recipe_embeddings_batches.shape[0]\n","  # recipe_3d = recipe_embeddings_batches.unsqueeze(0)\n","  # image_3d = image_embeddings_batches.unsqueeze(0)\n","  # combined_embeddings = torch.cat((recipe_embeddings_batches, image_embeddings_batches), dim=0)\n","  np_embeddings = recipe_embeddings_batches.detach().cpu().numpy()\n","  print(np_embeddings.shape)\n","  tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n","\n","  reduced_embeddings = tsne.fit_transform(np_embeddings)\n","\n","  # Separate reduced embeddings for visualization\n","  # num_images = np_embeddings.shape[1]\n","  # reduced_image_embeddings = reduced_embeddings[:num_images]\n","  # reduced_recipe_embeddings = reduced_embeddings[num_images:]\n","  print(reduced_embeddings.shape)\n","  # Plot the embeddings\n","  plt.figure(figsize=(8, 8))\n","  for batch in range(batches):\n","    if batch + 1 < batches:\n","      plt.scatter(reduced_embeddings[batch,:], reduced_embeddings[batch+1,:], label=f\"Embeddings {batch}\", alpha=0.7)\n","    else:\n","      break\n","  plt.legend()\n","  plt.title(\"t-SNE Visualization of Image and Recipe Embeddings\")\n","  plt.xlabel(\"t-SNE Dim 1\")\n","  plt.ylabel(\"t-SNE Dim 2\")\n","  plt.show()"]},{"cell_type":"code","execution_count":108,"metadata":{"executionInfo":{"elapsed":342,"status":"ok","timestamp":1733987840399,"user":{"displayName":"Jacob Gronlund","userId":"00200772917564897839"},"user_tz":480},"id":"nc71r5-Uyouz"},"outputs":[],"source":["from torch.utils.data import Dataset, DataLoader, random_split\n","import torch\n","from models.image_2_recipe import Image2Recipe\n","from models.image_encoder import Image_Encoder\n","from models.recipe_encoder import RecipeEncoder\n","from models.MMR import MMR\n","from models.MMR import MMR_losses\n","import matplotlib.pyplot as plt\n","from tqdm.auto import tqdm\n","\n","class Data_Loading(Dataset):\n","    \"\"\"\n","    Class to combine the Images, Labels, Recipes together to be used in combination when inputted into Model\n","    \"\"\"\n","    def __init__(self, tokenized_ingredients, tokenized_instructions, tokenized_titles, image_tensors, image_labels):\n","        self.ingredients = torch.tensor(tokenized_ingredients, dtype=torch.int16)\n","        self.instructions = torch.tensor(tokenized_instructions, dtype=torch.int16)\n","        self.titles = torch.tensor(tokenized_titles, dtype=torch.int16)\n","        self.images = image_tensors\n","        self.image_labels = image_labels\n","\n","    def __len__(self):\n","        return len(self.images)\n","\n","    def __getitem__(self, idx):\n","        return {\n","            \"ingredients\": self.ingredients[idx],\n","            \"instructions\": self.instructions[idx],\n","            \"titles\": self.titles[idx],\n","            \"images\": self.images[idx],\n","            \"image_labels\": self.image_labels[idx]\n","\n","        }\n","\n","\n","class Trainer(object):\n","    \"\"\"\n","    Class designed to run ViT (train, evaluate, plot)\n","    \"\"\"\n","\n","    def __init__(self, **kwargs):\n","        \"\"\"\n","        Initialize ViT\n","        \"\"\"\n","        self.epochs = kwargs['epochs']\n","        self.optimizer_name = kwargs['optimizer']\n","        self.device = kwargs['device']\n","        self.batch_size = kwargs['batch_size']\n","        self.lr = kwargs['learning_rate']\n","\n","        self.tokenized_ingredients = kwargs['ingredient_tokens']\n","        self.tokenized_instructions = kwargs['instruction_tokens']\n","        self.tokenized_title = kwargs['title_tokens']\n","        self.image_tensor = kwargs['image_tensors']\n","        self.image_labels = kwargs['image_labels']\n","        self.clip_model = kwargs['clip_model']\n","        self.vocab_size = kwargs['vocab_size']\n","        self.max_len = kwargs['max_len']\n","        self.instance_weight = kwargs['instance_weight']\n","        self.sem_weight = kwargs['sem_weight']\n","        self.itm_weight = kwargs['itm_weight']\n","        self.best_model_parameters = kwargs['best_model_parameters_path']\n","        self.initial_margin = kwargs['initial_margin']\n","        self.margin_step = kwargs['margin_step']\n","        self.max_margin = kwargs['max_margin']\n","        self.topk = kwargs['topk']\n","        self.fixed_margin = kwargs['fixed_margin']\n","        self.improvement_threshold = kwargs['improvement_threshold']\n","        self.patience = kwargs['patience']\n","        self.best_model_parameters = kwargs['best_model_parameters_path']\n","        mode = 'optuna'\n","\n","        self.mmr_heads = kwargs['mmr_heads']\n","        self.ITEM_lyrs = kwargs['ITEM_lyrs']\n","        self.MTD_lyrs = self.ITEM_lyrs\n","        self.hidden_dim = kwargs['hidden_dim']\n","        # self.recipe_enc_hidden = kwargs['recipe_enc_hidden']\n","        self.projection_dim=kwargs['projection_dim']\n","        self.MMR_type = kwargs['MMR_type']\n","        self.loss_calcs = MMR_losses(instance_weight=self.instance_weight, sem_weight=self.sem_weight, itm_weight=self.itm_weight)\n","        num_classes = len(set(self.image_labels))\n","\n","\n","        self.image_encoder = Image_Encoder(self.device, self.clip_model, num_classes).to(self.device)\n","        self.recipe_encoder = RecipeEncoder(self.device, self.vocab_size, self.max_len).to(self.device)\n","        # self.mmr = MMR(hidden_dim=self.image_encoder.clip_model.config.projection_dim).to(self.device)\n","        self.mmr = MMR(hidden_dim=self.image_encoder.clip_model.config.projection_dim, num_heads=self.mmr_heads, ITEM_lyrs=self.ITEM_lyrs, MTD_lyrs=self.MTD_lyrs, projection_dim=self.projection_dim, MMR_type=self.MMR_type).to(self.device)\n","\n","        # self.recipe_decoder = RecipeDecoder(512,512,self.vocab_size).to(self.device)\n","        # MMR varaibles: num_heads=num_heads, ITEM_lyrs=ITEM_lyrs, MTD_lyrs=MTD_lyrs, projection_dim=projection_dim\n","        self.model = Image2Recipe(self.image_encoder, self.recipe_encoder, self.mmr).to(self.device)\n","\n","        for param in self.model.image_encoder.parameters():\n","          param.requires_grad = False\n","\n","        ##DO we want to tune each of these learning rates for each model?\n","        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n","        # self.optimizer2 = torch.optim.Adam(self.recipe_decoder.parameters(), lr=self.lr)\n","        # self.optimizer = torch.optim.AdamW([\n","        #     {\"params\": self.model.image_encoder.parent_model.parameters(), \"lr\": 1e-6},\n","        #     {\"params\": self.model.recipe_encoder.parameters(), \"lr\": 1e-5},\n","        #     {\"params\": self.model.image_encoder.fc1.parameters(), \"lr\": 1e-5},\n","        #     {\"params\": self.model.recipe_encoder.ll_e.parameters(), \"lr\": 1e-5},\n","        # ])\n","\n","\n","        #Combine Images, Recipes, Instructions in training and eval datasets\n","        self.data_total = Data_Loading(\n","            self.tokenized_ingredients,\n","            self.tokenized_instructions,\n","            self.tokenized_title,\n","            self.image_tensor,\n","            self.image_labels\n","        )\n","        training_perc = .9\n","        train_size = int(training_perc * len(self.data_total))\n","        eval_size = len(self.data_total) - train_size\n","        train_dataset, eval_dataset = random_split(self.data_total, [train_size, eval_size])\n","        self.dataloader = {}\n","        self.dataloader['train'] = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True, drop_last=True)\n","        self.dataloader['eval'] = DataLoader(eval_dataset, batch_size=self.batch_size, shuffle=False, drop_last=True)\n","\n","        #Lists to fill up during training and plotted later for learning curves\n","        self.train_loss_list = []\n","        self.eval_loss_list = []\n","        self.eval_acc_list = []\n","        self.eval_acc_list = []\n","        self.best_score = 0\n","        self.best_loss = 10000\n","        print(\"finished initializing\")\n","\n","        # self.CELoss = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n","        # self.decoder_lambda = kwargs['decoder_lambda']\n","\n","    def train(self):\n","        \"\"\"\n","        Train ViT, image encoder, recipe encoder, MMR\n","        \"\"\"\n","        # Set initial margin\n","        self.margin = self.initial_margin\n","\n","        for epoch in range(self.epochs):\n","            if epoch == 15:\n","              for param in self.model.image_encoder.parameters():\n","                param.requires_grad = True\n","                print(\"unfreezing image encoder\")\n","              self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n","\n","            for phase in ['train', 'eval']:\n","                total_loss = 0\n","                total_accuracy = 0\n","                all_recipe_embeddings = []\n","                all_image_embeddings = []\n","                all_image_labels = []\n","                total_loss_actual = 0\n","                total_eval_loss = 0\n","                if phase == 'train':\n","                    self.model.train()\n","                else:\n","                    self.model.eval()\n","                for i, batch_data in enumerate(tqdm(self.dataloader[phase],position=0, leave=True)):\n","                    #Looping through batches of training data then eval data each epoch\n","                    #TODO: Add how the recipe, instructions, and titles will be tokenized\n","                    ingredients, instructions, titles, images, image_labels = (\n","                        batch_data['ingredients'].to(self.device),\n","                        batch_data['instructions'].to(self.device),\n","                        batch_data['titles'].to(self.device),\n","                        batch_data['images'].to(self.device),\n","                        batch_data['image_labels']\n","                    )\n","\n","                    recipe_enc_src = [titles, ingredients, instructions]\n","\n","                    self.optimizer.zero_grad()\n","\n","                    if phase == 'train':\n","                        output = self.model(images, image_labels, recipe_enc_src)\n","                        ##Combine the Recipe Encoder Losses and Image Encoder Losses based on TFOOD\n","                        mmr_logits = output[\"mmr_logits\"]\n","                        image_logits = output[\"image_logits\"]\n","                        image_embeddings_proj = output[\"image_embeddings_proj\"]\n","                        recipe_embeddings_proj = output[\"recipe_embeddings_proj\"]\n","                        # image_embeddings = output[\"image_embeddings\"]\n","                        # recipe_embeddings = output[\"recipe_embeddings\"]\n","                        # plot_2D(recipe_embeddings_proj, image_embeddings_proj)\n","                        # #Train the Recipe Decoder so it can output a generative (Title, Ingredient, Instructions)\n","                        # title_logits = self.recipe_decoder(image_embeddings, titles)\n","                        # ingredients_logits = self.recipe_decoder(image_embeddings, ingredients)\n","                        # instructions_logits = self.recipe_decoder(image_embeddings, instructions)\n","\n","                        # #Compute Reconstruction Loss\n","                        # title_loss = self.CELoss(title_logits.transpose(1, 2), titles)\n","                        # ingredients_loss = self.CELoss(ingredients_logits.transpose(1, 2), ingredients)\n","                        # instructions_loss = self.CELoss(instructions_logits.transpose(1, 2), instructions)\n","                        # decoder_loss = (title_loss + ingredients_loss + instructions_loss) *self.decoder_lambda\n","\n","                        loss = self.loss_calcs.total_loss(image_logits, image_embeddings_proj,\n","                                                          recipe_embeddings_proj, mmr_logits, self.margin)\n","\n","                        print(f'training loss for step: {loss.item()}')\n","                        # recall_score = calc_recall(self.topk, image_embeddings_proj, recipe_embeddings_proj, image_labels)\n","                        # print(recall_score)\n","                        loss.backward()\n","                        # print(\"-------------------------------------------\")\n","                        # for name, param in self.model.named_parameters():\n","                        #   if param.grad is not None:\n","                        #       print(f\"{name}: grad norm = {param.grad.norm()}\")\n","                        self.optimizer.step()\n","                        # self.optimizer2.step() #decoder optimizer\n","                        total_loss_actual += loss.item()\n","\n","\n","                    else: ##Eval mode\n","                        ###Test the last batches scores\n","                        with torch.no_grad():\n","                            output = self.model(images, image_labels, recipe_enc_src)\n","                            mmr_logits = output[\"mmr_logits\"]\n","                            image_logits = output[\"image_logits\"]\n","                            image_embeddings_proj = output[\"image_embeddings_proj\"]\n","                            recipe_embeddings_proj = output[\"recipe_embeddings_proj\"]\n","                            # #Train the Recipe Decoder so it can output a generative (Title, Ingredient, Instructions)\n","                            # title_logits = self.recipe_decoder(image_embeddings, titles)\n","                            # ingredients_logits = self.recipe_decoder(image_embeddings, ingredients)\n","                            # instructions_logits = self.recipe_decoder(image_embeddings, instructions)\n","\n","                            # #Compute Reconstruction Loss\n","                            # title_loss = self.CELoss(title_logits.transpose(1, 2), titles)\n","                            # ingredients_loss = self.CELoss(ingredients_logits.transpose(1, 2), ingredients)\n","                            # instructions_loss = self.CELoss(instructions_logits.transpose(1, 2), instructions)\n","                            # decoder_loss = (title_loss + ingredients_loss + instructions_loss) * self.decoder_lambda\n","                            eval_loss = self.loss_calcs.total_eval_loss(image_logits, image_embeddings_proj,\n","                                                                   recipe_embeddings_proj, margin=self.fixed_margin)  # + decoder_loss\n","\n","                            total_eval_loss += eval_loss.item()\n","\n","\n","                            # recall_score = calc_recall(self.topk, image_embeddings_proj, recipe_embeddings_proj, image_labels)\n","                            # print(recall_score)\n","                            # all_image_labels.append(image_labels)\n","                            # all_recipe_embeddings.append(recipe_embeddings_proj)\n","                            # all_image_embeddings.append(image_embeddings_proj)\n","                    # print(f\"Batch: {i}/{len(self.dataloader[phase])}\")\n","                    # del unused_tensor\n","                    torch.cuda.empty_cache() #clear cache after each batch\n","                    # print(i)\n","                    # print(output)\n","                    # total_loss += loss.item()\n","                # if phase == \"eval\":\n","                #     all_image_labels = [item for sublist in all_image_labels for item in sublist]\n","                #     recipe_embeddings_total = torch.cat(all_recipe_embeddings, dim=0)\n","                #     image_embeddings_total = torch.cat(all_image_embeddings, dim=0)\n","                #     # print(f\"Image Labels Shape: {len(all_image_labels)}\")\n","                #     # print(f\"Recipe Embeddings Shape: {recipe_embeddings_total.shape}\")\n","                #     # print(f\"Image Embeddings Shape: {image_embeddings_total.shape}\")\n","                #     recall_score = calc_recall(self.topk, image_embeddings_total, recipe_embeddings_total, all_image_labels)\n","                #     print(f\"Recall Score: {recall_score}\")\n","\n","                # print(f\"{phase}: Epoch {epoch+1}, Loss: {total_loss_actual / len(self.dataloader[phase])}\")#, with Recall Score: {recall_score}\")\n","\n","                # Update loss margin\n","                if self.margin <= (self.max_margin - self.margin_step):\n","                    self.margin += self.margin_step\n","                else:\n","                    self.margin = self.max_margin\n","                if phase == \"train\":\n","                  self.train_loss_list.append(total_loss_actual/len(self.dataloader[phase]))\n","                  print(f\"{phase}: Epoch {epoch+1}, Loss: {total_loss_actual / len(self.dataloader[phase])}\")#, with Recall Score: {recall_score}\")\n","\n","                else:\n","                  self.eval_loss_list.append(total_eval_loss/len(self.dataloader[phase]))\n","                  print(f\"{phase}: Epoch {epoch+1}, Loss: {total_eval_loss / len(self.dataloader[phase])}\")#, with Recall Score: {recall_score}\")\n","                  total_loss = total_eval_loss/len(self.dataloader[phase])\n","                  if total_loss < self.best_loss:\n","                      self.best_loss = total_loss\n","                      torch.save(self.model.state_dict(), self.best_model_parameters)\n","                      print(\"saving this model\")\n","                      ###save the model to then calculate the embedded space\n","\n","\n","\n","    ##Waiting on training code to finish\n","    def plot_learning_loss_curves(self):\n","        \"\"\"\n","        Plot accuracy and loss curves for training and eval accuracy/loss lists (item/epoch)\n","        \"\"\"\n","        plt.figure(figsize=(10, 5))\n","        plt.plot(self.train_loss_list, label='Training Loss')\n","        plt.plot(self.eval_loss_list, label='Validation Loss')\n","        plt.xlabel('Epoch')\n","        plt.ylabel('Loss')\n","        plt.title('Loss Curve')\n","        plt.legend()\n","        plt.show()\n","\n","        # plt.figure(figsize=(10, 5))\n","        # plt.plot(self.train_acc_list, label='Training Accuracy')\n","        # plt.plot(self.eval_acc_list, label='Validation Accuracy')\n","        # plt.xlabel('Epoch')\n","        # plt.ylabel('Accuracy')\n","        # plt.title('Accuracy Curve')\n","        # plt.legend()\n","        # plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oCpaIgTRca8s"},"outputs":[],"source":["%autoreload 2"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":237,"status":"ok","timestamp":1733898253036,"user":{"displayName":"Jacob Gronlund","userId":"00200772917564897839"},"user_tz":480},"id":"jXA0oBF70OCN","outputId":"4625038c-f3a7-40af-f58a-22edc5112404"},"outputs":[{"output_type":"stream","name":"stdout","text":["128\n","128\n","128\n"]}],"source":["print(len(filtered_df['tokenized_ingredients'][1][0]))\n","print(len(filtered_df['tokenized_instructions'][1][0]))\n","print(len(filtered_df['tokenized_titles'][1][0]))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1733898253036,"user":{"displayName":"Jacob Gronlund","userId":"00200772917564897839"},"user_tz":480},"id":"4lOE7ew3Czjr","outputId":"67cb3a70-681d-4bcd-b7ce-f83308fbd33d"},"outputs":[{"output_type":"stream","name":"stdout","text":["cuda:0\n"]}],"source":["# torch.cuda.empty_cache()\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"]},{"cell_type":"code","source":["stop"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":141},"id":"26dLC5V6Yy-_","executionInfo":{"status":"error","timestamp":1733898253257,"user_tz":480,"elapsed":224,"user":{"displayName":"Jacob Gronlund","userId":"00200772917564897839"}},"outputId":"69d8cd4f-6c9f-4b62-e4ba-a149b99a2dc3"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'stop' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-4f76a9dad686>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'stop' is not defined"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DL-FetOiVKeT"},"outputs":[],"source":["# Cuda issues\n","print(torch.__version__)\n","print(torch.cuda.is_available())\n","vocab_size = tokenizer_recipes.vocab_size\n","param_path = os.path.join(GOOGLE_DRIVE_PATH, \"models/best_model_jake_12_10.pth\")\n","recipe_embeddings_path  = os.path.join(GOOGLE_DRIVE_PATH, \"models/recipe_embeddings.pth\")\n","\n","kwargs = {\n","    'epochs': 10,\n","    'ingredient_tokens': filtered_df['tokenized_ingredients'].to_list(),\n","    'instruction_tokens': filtered_df['tokenized_instructions'].to_list(),\n","    'title_tokens': filtered_df['tokenized_titles'].to_list(),\n","    'image_tensors': filtered_tensors,\n","    'image_labels': filtered_df['Image_Name'],\n","    'device': device,\n","    'vocab_size': vocab_size,\n","    'max_len': total_max,\n","    'clip_model': clip_model,\n","    'optimizer': 'adam',\n","    'learning_rate': 1e-1,\n","    'batch_size': 15,\n","    'instance_weight': 1,\n","    'sem_weight': 5,\n","    'itm_weight': 0.5,\n","    'initial_margin': 5.0,\n","    'margin_step': 1,\n","    'max_margin': 1000.0,\n","    'best_model_parameters_path': param_path,\n","    'decoder_lambda': 0.1,\n","    'topk': 10,\n","    'patience': 6,\n","    'improvement_threshold': 0.001,\n","    'projection_dim': 1024,\n","    'fixed_margin': 20,\n","    'hidden_dim' : 512,\n","    'mmr_heads': 2,\n","    'ITEM_lyrs': 1,\n","    'MTD_lyrs': 1,\n","    'MMR_type': 'type_separate'\n","\n","}\n","image2recipe = Trainer(**kwargs)\n","image2recipe.train()\n","image2recipe.plot_learning_loss_curves()"]},{"cell_type":"markdown","metadata":{"id":"IQDow2_yJQO1"},"source":["Now that the model is trained, use it to guess images recipes!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EBf0DvhNLGt8"},"outputs":[],"source":["stop"]},{"cell_type":"markdown","metadata":{"id":"Bv-T3jXCiEJ3"},"source":["Create the recipe Embedded space with the best parameters (lowest loss)"]},{"cell_type":"code","execution_count":113,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":269476,"status":"ok","timestamp":1733988214555,"user":{"displayName":"Jacob Gronlund","userId":"00200772917564897839"},"user_tz":480},"id":"QTmEiMK8iDwm","outputId":"93dd5790-23e9-49f1-ac24-212349506e37"},"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([4968, 3, 224, 224])\n","(4968, 9)\n","(4968, 9)\n","512\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-113-3d0d354d072f>:30: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load(model_path))\n"]},{"output_type":"stream","name":"stdout","text":["total found =  4\n","Recall Score: 0.4\n","Batch: 0/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 1/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 2/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 3/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 4/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 5/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 6/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 7/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 8/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 9/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 10/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 11/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 12/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 13/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 14/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 15/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 16/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 17/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 18/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 19/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 20/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 21/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 22/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 23/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 24/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 25/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 26/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 27/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 28/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 29/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 30/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 31/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 32/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 33/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 34/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 35/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 36/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 37/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 38/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 39/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 40/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 41/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 42/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 43/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 44/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 45/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 46/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 47/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 48/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 49/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 50/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 51/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 52/496\n","total found =  3\n","Recall Score: 0.3\n","Batch: 53/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 54/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 55/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 56/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 57/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 58/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 59/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 60/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 61/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 62/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 63/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 64/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 65/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 66/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 67/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 68/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 69/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 70/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 71/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 72/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 73/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 74/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 75/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 76/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 77/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 78/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 79/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 80/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 81/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 82/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 83/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 84/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 85/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 86/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 87/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 88/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 89/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 90/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 91/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 92/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 93/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 94/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 95/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 96/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 97/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 98/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 99/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 100/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 101/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 102/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 103/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 104/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 105/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 106/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 107/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 108/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 109/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 110/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 111/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 112/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 113/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 114/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 115/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 116/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 117/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 118/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 119/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 120/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 121/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 122/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 123/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 124/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 125/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 126/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 127/496\n","total found =  3\n","Recall Score: 0.3\n","Batch: 128/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 129/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 130/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 131/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 132/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 133/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 134/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 135/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 136/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 137/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 138/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 139/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 140/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 141/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 142/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 143/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 144/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 145/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 146/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 147/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 148/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 149/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 150/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 151/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 152/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 153/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 154/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 155/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 156/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 157/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 158/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 159/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 160/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 161/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 162/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 163/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 164/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 165/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 166/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 167/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 168/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 169/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 170/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 171/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 172/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 173/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 174/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 175/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 176/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 177/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 178/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 179/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 180/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 181/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 182/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 183/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 184/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 185/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 186/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 187/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 188/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 189/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 190/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 191/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 192/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 193/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 194/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 195/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 196/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 197/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 198/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 199/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 200/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 201/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 202/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 203/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 204/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 205/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 206/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 207/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 208/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 209/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 210/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 211/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 212/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 213/496\n","total found =  3\n","Recall Score: 0.3\n","Batch: 214/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 215/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 216/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 217/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 218/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 219/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 220/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 221/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 222/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 223/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 224/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 225/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 226/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 227/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 228/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 229/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 230/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 231/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 232/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 233/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 234/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 235/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 236/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 237/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 238/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 239/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 240/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 241/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 242/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 243/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 244/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 245/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 246/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 247/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 248/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 249/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 250/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 251/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 252/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 253/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 254/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 255/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 256/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 257/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 258/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 259/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 260/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 261/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 262/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 263/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 264/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 265/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 266/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 267/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 268/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 269/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 270/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 271/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 272/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 273/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 274/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 275/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 276/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 277/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 278/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 279/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 280/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 281/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 282/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 283/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 284/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 285/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 286/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 287/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 288/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 289/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 290/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 291/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 292/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 293/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 294/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 295/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 296/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 297/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 298/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 299/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 300/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 301/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 302/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 303/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 304/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 305/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 306/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 307/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 308/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 309/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 310/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 311/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 312/496\n","total found =  3\n","Recall Score: 0.3\n","Batch: 313/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 314/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 315/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 316/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 317/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 318/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 319/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 320/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 321/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 322/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 323/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 324/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 325/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 326/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 327/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 328/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 329/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 330/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 331/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 332/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 333/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 334/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 335/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 336/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 337/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 338/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 339/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 340/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 341/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 342/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 343/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 344/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 345/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 346/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 347/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 348/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 349/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 350/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 351/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 352/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 353/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 354/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 355/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 356/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 357/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 358/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 359/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 360/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 361/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 362/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 363/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 364/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 365/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 366/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 367/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 368/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 369/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 370/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 371/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 372/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 373/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 374/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 375/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 376/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 377/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 378/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 379/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 380/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 381/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 382/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 383/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 384/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 385/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 386/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 387/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 388/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 389/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 390/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 391/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 392/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 393/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 394/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 395/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 396/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 397/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 398/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 399/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 400/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 401/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 402/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 403/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 404/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 405/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 406/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 407/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 408/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 409/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 410/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 411/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 412/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 413/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 414/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 415/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 416/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 417/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 418/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 419/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 420/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 421/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 422/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 423/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 424/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 425/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 426/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 427/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 428/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 429/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 430/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 431/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 432/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 433/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 434/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 435/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 436/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 437/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 438/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 439/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 440/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 441/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 442/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 443/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 444/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 445/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 446/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 447/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 448/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 449/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 450/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 451/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 452/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 453/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 454/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 455/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 456/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 457/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 458/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 459/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 460/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 461/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 462/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 463/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 464/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 465/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 466/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 467/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 468/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 469/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 470/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 471/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 472/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 473/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 474/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 475/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 476/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 477/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 478/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 479/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 480/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 481/496\n","total found =  3\n","Recall Score: 0.3\n","Batch: 482/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 483/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 484/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 485/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 486/496\n","total found =  2\n","Recall Score: 0.2\n","Batch: 487/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 488/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 489/496\n","total found =  0\n","Recall Score: 0.0\n","Batch: 490/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 491/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 492/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 493/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 494/496\n","total found =  1\n","Recall Score: 0.1\n","Batch: 495/496\n","Total Recall Score: 9.818548387096774%\n"]}],"source":["recipe_embeddings_path = os.path.join(GOOGLE_DRIVE_PATH, \"models/recipe_embeddings_proj_chel_11.pth\")\n","image_embeddings_path = os.path.join(GOOGLE_DRIVE_PATH, \"models/image_embeddings_proj_chel_11.pth\")\n","param_path = os.path.join(GOOGLE_DRIVE_PATH, \"models/recipe_checkpoint_12-09_22-53__Trial_4-best_model.pth\")\n","vocab_size = tokenizer_recipes.vocab_size\n","from models.MMR import MMR\n","\n","print(filtered_tensors.shape)\n","print(filtered_df.shape)\n","mmr_heads = 4\n","MMR_type = 'type_seperate'\n","projection_dim = 512\n","ITEM_lyrs = 4\n","MTD_lyrs = 4\n","\n","\n","print(filtered_df.shape)\n","##load up the model\n","def load_model(model_path):\n","    num_classes = len(set(filtered_df['Image_Name']))\n","    max_len = total_max\n","    image_encoder = Image_Encoder(device, clip_model, num_classes).to(device)\n","    recipe_encoder = RecipeEncoder(device, vocab_size, max_len).to(device)\n","    print(image_encoder.clip_model.config.projection_dim)\n","    # mmr = MMR(hidden_dim=image_encoder.clip_model.config.projection_dim).to(device)\n","    mmr = MMR(hidden_dim=image_encoder.clip_model.config.projection_dim, num_heads=mmr_heads,\n","              ITEM_lyrs=ITEM_lyrs, MTD_lyrs=MTD_lyrs, projection_dim=projection_dim, MMR_type=MMR_type).to(device)\n","\n","    # mmr = MMR(hidden_dim=1024).to(device)\n","    model = Image2Recipe(image_encoder, recipe_encoder, mmr).to(device)\n","    model.load_state_dict(torch.load(model_path))\n","    model.eval()\n","    return model\n","\n","model = load_model(param_path)\n","\n","data_total = Data_Loading(\n","            filtered_df['tokenized_ingredients'].to_list(),\n","            filtered_df['tokenized_instructions'].to_list(),\n","            filtered_df['tokenized_titles'].to_list(),\n","            filtered_tensors,\n","            filtered_df['Image_Name']\n","        )\n","batch_size=10\n","positives_total = 0\n","dataloader = DataLoader(data_total, batch_size=batch_size, shuffle=False, drop_last=True)\n","##Create the recipe embedded space\n","all_recipe_embeddings = []\n","all_image_embeddings = []\n","selected = [1,2,3]\n","for i, batch in enumerate(dataloader):\n","  with torch.no_grad():\n","    ingredients, instructions, titles, images, image_labels = (\n","        batch['ingredients'].to(device),\n","        batch['instructions'].to(device),\n","        batch['titles'].to(device),\n","        batch['images'].to(device),\n","        batch['image_labels']\n","    )\n","    recipe_enc_src = [titles, ingredients, instructions]\n","    output = model(images, image_labels, recipe_enc_src)\n","    image_projection = output['image_embeddings_mmr']\n","    recipe_projection = output[\"recipe_projection_mmr\"]\n","    image_indices = np.arange(0,batch_size)\n","    # positives = calc_recall_showimages(10, image_projection, recipe_projection, image_indices, selected, image_labels)\n","    positives = calc_recall_id(1, image_projection, recipe_projection, image_indices)\n","    positives_total += positives\n","    recall_score = positives/batch_size\n","    print(f\"Recall Score: {recall_score}\")\n","    all_image_embeddings.append(image_projection)\n","    all_recipe_embeddings.append(recipe_projection)\n","    print(f\"Batch: {i}/{len(dataloader)}\")\n","\n","total_recall = (positives_total/(len(dataloader)*batch_size))*100\n","print(f\"Total Recall Score: {total_recall}%\")\n","recipe_embeddings_total = torch.cat(all_recipe_embeddings, dim=0)\n","image_embeddings_total = torch.cat(all_image_embeddings, dim=0)\n","# # print(recipe_embeddings_total.shape)\n","torch.save(recipe_embeddings_total, recipe_embeddings_path)\n","torch.save(image_embeddings_total, image_embeddings_path)\n"]},{"cell_type":"markdown","metadata":{"id":"xqWNyO_PN7_1"},"source":["Test images from dataset to get a recall score"]},{"cell_type":"code","source":["recipe_embeddings_path = os.path.join(GOOGLE_DRIVE_PATH, \"models/recipe_embeddings_proj_chel_11.pth\")\n","image_embeddings_path = os.path.join(GOOGLE_DRIVE_PATH, \"models/image_embeddings_proj_chel_11.pth\")\n","recipe_embeddings = torch.load(recipe_embeddings_path)\n","image_embeddings = torch.load(image_embeddings_path)\n","print(recipe_embeddings.shape)\n","print(image_embeddings.shape)\n","\n","image_indices = np.arange(0,image_embeddings.shape[0])\n","print(image_indices.shape)\n","topk_vals = [1,5,10]\n","selected = [10, 35, 600]\n","for topk in topk_vals:\n","  recall_score = calc_recall_id(topk, image_embeddings, recipe_embeddings, image_indices)\n","\n","  print(f\"Recall score for {topk}: {round(recall_score/image_embeddings.shape[0] *100,3)}%\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WVtQwDM2_SUb","executionInfo":{"status":"ok","timestamp":1733988368376,"user_tz":480,"elapsed":8578,"user":{"displayName":"Jacob Gronlund","userId":"00200772917564897839"}},"outputId":"752eba4f-6beb-46bb-ed29-9f5df816c58a"},"execution_count":114,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-114-dd6ac7a2ade4>:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  recipe_embeddings = torch.load(recipe_embeddings_path)\n","<ipython-input-114-dd6ac7a2ade4>:4: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  image_embeddings = torch.load(image_embeddings_path)\n"]},{"output_type":"stream","name":"stdout","text":["torch.Size([4960, 512])\n","torch.Size([4960, 512])\n","(4960,)\n","total found =  1\n","Recall score for 1: 0.02%\n","total found =  5\n","Recall score for 5: 0.101%\n","total found =  10\n","Recall score for 10: 0.202%\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9ESNkKRoJlmU"},"outputs":[],"source":["recipe_embeddings_path = os.path.join(GOOGLE_DRIVE_PATH, \"models/recipe_embeddings_12_10_jake_noimage.pth\")\n","param_path = os.path.join(GOOGLE_DRIVE_PATH, \"models/best_model_jake_12_10.pth\")\n","recipe_embeddings = torch.load(recipe_embeddings_path)\n","vocab_size = tokenizer_recipes.vocab_size\n","mmr_heads = 2\n","MMR_type = 'type_separate'\n","projection_dim = 1024\n","ITEM_lyrs = 1\n","MTD_lyrs = 1\n","\n","##load up the model\n","def load_model(model_path):\n","    num_classes = len(set(filtered_df['Image_Name']))\n","    max_len = total_max\n","    image_encoder = Image_Encoder(device, clip_model, num_classes).to(device)\n","    recipe_encoder = RecipeEncoder(device, vocab_size, max_len).to(device)\n","    mmr = MMR(hidden_dim=image_encoder.clip_model.config.projection_dim, num_heads=mmr_heads,\n","              ITEM_lyrs=ITEM_lyrs, MTD_lyrs=MTD_lyrs, projection_dim=projection_dim, MMR_type=MMR_type).to(device)\n","    model = Image2Recipe(image_encoder, recipe_encoder, mmr).to(device)\n","    model.load_state_dict(torch.load(model_path))\n","    model.eval()\n","    return model\n","\n","model = load_model(param_path)\n","\n","data_total = Data_Loading(\n","            filtered_df['tokenized_ingredients'].to_list(),\n","            filtered_df['tokenized_instructions'].to_list(),\n","            filtered_df['tokenized_titles'].to_list(),\n","            filtered_tensors,\n","            filtered_labels\n","        )\n","batch_size=10\n","dataloader = DataLoader(data_total, batch_size=batch_size, shuffle=False, drop_last=True)\n","##Create the recipe embedded space\n","all_recipe_embeddings = []\n","for i, batch in enumerate(dataloader):\n","  with torch.no_grad():\n","    ingredients, instructions, titles, images, image_labels = (\n","        batch['ingredients'].to(device),\n","        batch['instructions'].to(device),\n","        batch['titles'].to(device),\n","        batch['images'].to(device),\n","        batch['image_labels']\n","    )\n","\n","    recipe_enc_src = [titles, ingredients, instructions]\n","    output = model(images, image_labels, recipe_enc_src)\n","    image_embeddings_proj = output[\"image_embeddings_proj\"]\n","    # plot_2D(recipe_embeddings, image_embeddings_proj, multiplier=i, batch_size = batch_size)\n","    recall_score = calc_recall(10, image_embeddings_proj, recipe_embeddings, image_labels)\n","    print(recall_score)\n","    print(f\"Batch: {i}/{len(dataloader)}\")\n","    torch.cuda.empty_cache()\n"]},{"cell_type":"markdown","metadata":{"id":"DSPF80b-AJhE"},"source":["Test the model on 1000 pictures"]},{"cell_type":"code","execution_count":93,"metadata":{"executionInfo":{"elapsed":2440,"status":"error","timestamp":1733984780240,"user":{"displayName":"Jacob Gronlund","userId":"00200772917564897839"},"user_tz":480},"id":"z-U9830iF48G","colab":{"base_uri":"https://localhost:8080/","height":446},"outputId":"97f71427-2d3f-4111-9337-f1ea834d8719"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-93-55827c419e49>:34: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n","  model.load_state_dict(torch.load(model_path))\n"]},{"output_type":"error","ename":"RuntimeError","evalue":"Error(s) in loading state_dict for Image2Recipe:\n\tsize mismatch for image_encoder.fc1.weight: copying a param with shape torch.Size([996, 512]) from checkpoint, the shape in current model is torch.Size([4968, 512]).\n\tsize mismatch for image_encoder.fc1.bias: copying a param with shape torch.Size([996]) from checkpoint, the shape in current model is torch.Size([4968]).","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-93-55827c419e49>\u001b[0m in \u001b[0;36m<cell line: 39>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0mimage_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGOOGLE_DRIVE_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Data/test_images/cookie.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mtensor_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m \u001b[0mimage2recipe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0mimage_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_image_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-93-55827c419e49>\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(model_path)\u001b[0m\n\u001b[1;32m     32\u001b[0m               ITEM_lyrs=ITEM_lyrs, MTD_lyrs=MTD_lyrs, projection_dim=projection_dim, MMR_type=MMR_type).to(device)\n\u001b[1;32m     33\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage2Recipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecipe_encoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2583\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2584\u001b[0;31m             raise RuntimeError(\n\u001b[0m\u001b[1;32m   2585\u001b[0m                 \"Error(s) in loading state_dict for {}:\\n\\t{}\".format(\n\u001b[1;32m   2586\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"\\n\\t\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Image2Recipe:\n\tsize mismatch for image_encoder.fc1.weight: copying a param with shape torch.Size([996, 512]) from checkpoint, the shape in current model is torch.Size([4968, 512]).\n\tsize mismatch for image_encoder.fc1.bias: copying a param with shape torch.Size([996]) from checkpoint, the shape in current model is torch.Size([4968])."]}],"source":["from PIL import Image\n","import torchvision.transforms as transforms\n","recipe_embeddings_path = os.path.join(GOOGLE_DRIVE_PATH, \"models/recipe_embeddings_proj_em_11.pth\")\n","recipe_embeddings = torch.load(recipe_embeddings_path)\n","param_path = os.path.join(GOOGLE_DRIVE_PATH, \"models/best_model_jake_12_10.pth\")\n","mmr_heads = 2\n","MMR_type = 'type_separate'\n","projection_dim = 1024\n","ITEM_lyrs = 1\n","MTD_lyrs = 1\n","transform = transforms.Compose([\n","    transforms.Resize((224, 224)),  #same size as training\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) #same norm as training\n","])\n","\n","def preprocess_image(image_path):\n","    image = Image.open(image_path).convert(\"RGB\")\n","    return transform(image).unsqueeze(0) #add batch dim of 1 at 0 indice\n","\n","def extract_image_features(image, model, device):\n","  model.eval()\n","  with torch.no_grad():\n","      image_logits, image_features = model.image_encoder(image.to(device), image_labels)\n","  return image_features\n","\n","def load_model(model_path):\n","    num_classes = len(set(filtered_df['Image_Name']))\n","    max_len = total_max\n","    image_encoder = Image_Encoder(device, clip_model, num_classes).to(device)\n","    recipe_encoder = RecipeEncoder(device, vocab_size, max_len).to(device)\n","    mmr = MMR(hidden_dim=image_encoder.clip_model.config.projection_dim, num_heads=mmr_heads,\n","              ITEM_lyrs=ITEM_lyrs, MTD_lyrs=MTD_lyrs, projection_dim=projection_dim, MMR_type=MMR_type).to(device)\n","    model = Image2Recipe(image_encoder, recipe_encoder, mmr).to(device)\n","    model.load_state_dict(torch.load(model_path))\n","    return model\n","\n","image_path = os.path.join(GOOGLE_DRIVE_PATH, \"Data/test_images/cookie.png\")\n","tensor_image = preprocess_image(image_path)\n","image2recipe = load_model(param_path)\n","image_features = extract_image_features(tensor_image, model, device)\n","print(image_features.shape)\n","\n","recipe_embeddings = torch.load(recipe_embeddings_path)\n","\n","recall_score = calc_recall_showimages(10, image_features, recipe_embeddings, filtered_df['Image_Name'].to_list())\n","print(recall_score)\n","\n","#Compute cosine similarities\n","\n","\n","\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[{"file_id":"1vbU7R0aYmPWKwxfvUv8jfO9mcqQnN2Pc","timestamp":1733362659265}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.20"}},"nbformat":4,"nbformat_minor":0}