{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PSBW6ryo-H9v"
   },
   "source": [
    "If using google drive please edit this line to connect to drive location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w6ZQ_d3W-aQq",
    "outputId": "c301d035-2726-4397-f0bf-196671fa717e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1YCGTlkW99pN",
    "outputId": "ed47b11e-e216-4829-f22e-288cf4c31bfa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n",
      " Code  'Image Recipe.gdoc'   models\t\t\t __pycache__\t     runner.py\n",
      " Data   Main.ipynb\t    'Project Task List.gsheet'\t recipe_encoder.py   training.ipynb\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "import os, sys\n",
    "\n",
    "# Mount the google colab\n",
    "drive.mount(\"/content/drive/\")\n",
    "GOOGLE_DRIVE_PATH_POST_MYDRIVE = 'DeepLearning_GroupProject/'\n",
    "GOOGLE_DRIVE_PATH = os.path.join('/content', 'drive', 'MyDrive', GOOGLE_DRIVE_PATH_POST_MYDRIVE)\n",
    "!ls {GOOGLE_DRIVE_PATH}\n",
    "sys.path.append(GOOGLE_DRIVE_PATH)\n",
    "\n",
    "# Explicitly adding models to the search path\n",
    "models_path = os.path.join(GOOGLE_DRIVE_PATH, 'models')\n",
    "if models_path not in sys.path:\n",
    "    sys.path.insert(0, models_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 578
    },
    "id": "sGHSvkJG5fbt",
    "outputId": "f3d1b994-4301-4bc8-e40f-23fea5c5adc8"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'GOOGLE_DRIVE_PATH' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\u001b[38;5;241m,\u001b[39m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m recipe_encoder\n\u001b[0;32m----> 8\u001b[0m csv_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(GOOGLE_DRIVE_PATH,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData/updated_data_with_lists.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      9\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(csv_file, converters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCleaned_Ingredients\u001b[39m\u001b[38;5;124m\"\u001b[39m: literal_eval, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstructions\u001b[39m\u001b[38;5;124m\"\u001b[39m: literal_eval})\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(df))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'GOOGLE_DRIVE_PATH' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "import numpy as np\n",
    "import torch\n",
    "import os, sys\n",
    "from models import recipe_encoder\n",
    "\n",
    "csv_file = os.path.join(GOOGLE_DRIVE_PATH,'Data/updated_data_with_lists.csv')\n",
    "df = pd.read_csv(csv_file, converters={\"Cleaned_Ingredients\": literal_eval, \"Instructions\": literal_eval})\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Data/updated_data_with_lists.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m recipe_encoder\n\u001b[1;32m      8\u001b[0m csv_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData/updated_data_with_lists.csv\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m----> 9\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(csv_file, converters\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCleaned_Ingredients\u001b[39m\u001b[38;5;124m\"\u001b[39m: literal_eval, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInstructions\u001b[39m\u001b[38;5;124m\"\u001b[39m: literal_eval})\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(df))\n\u001b[1;32m     11\u001b[0m df\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[1;32m   1736\u001b[0m     f,\n\u001b[1;32m   1737\u001b[0m     mode,\n\u001b[1;32m   1738\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1739\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1740\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[1;32m   1741\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[1;32m   1742\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1743\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[1;32m   1744\u001b[0m )\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    857\u001b[0m             handle,\n\u001b[1;32m    858\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[1;32m    859\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[1;32m    860\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m    861\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    862\u001b[0m         )\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Data/updated_data_with_lists.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "import numpy as np\n",
    "import torch\n",
    "import os, sys\n",
    "from models import recipe_encoder\n",
    "\n",
    "csv_file = 'Data/updated_data_with_lists.csv'\n",
    "df = pd.read_csv(csv_file, converters={\"Cleaned_Ingredients\": literal_eval, \"Instructions\": literal_eval})\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zhh--PCsDH3b"
   },
   "source": [
    "Concatenate the batches of preprocessed images into 1 tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wi-yY_TlDHPn",
    "outputId": "2b693d01-0574-496b-e3c3-55c8fa10ff4d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-29-11e042d92f1d>:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  image_tensors, image_labels = torch.load(pt_filepath)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded batch_0.pt\n",
      "Loaded batch_1.pt\n",
      "Loaded batch_2.pt\n",
      "Loaded batch_3.pt\n",
      "Loaded batch_4.pt\n",
      "Loaded batch_5.pt\n",
      "Loaded batch_6.pt\n",
      "Loaded batch_7.pt\n",
      "Loaded batch_8.pt\n",
      "Loaded batch_9.pt\n",
      "Loaded batch_10.pt\n",
      "Loaded batch_11.pt\n",
      "Loaded batch_12.pt\n",
      "Loaded batch_13.pt\n",
      "Number of images: 13582\n",
      "Number of labels: 13582\n"
     ]
    }
   ],
   "source": [
    "pt_files = os.listdir(os.path.join(GOOGLE_DRIVE_PATH,'Data/tensor_batches'))\n",
    "all_image_tensors = []\n",
    "all_image_labels = []\n",
    "\n",
    "# Load and combine all .pt files\n",
    "for pt_file in pt_files:\n",
    "    pt_filepath = os.path.join(GOOGLE_DRIVE_PATH,'Data/tensor_batches',pt_file)\n",
    "    image_tensors, image_labels = torch.load(pt_filepath)\n",
    "    all_image_tensors.append(image_tensors)\n",
    "    all_image_labels.extend(image_labels)\n",
    "    print(f\"Loaded {pt_file}\")\n",
    "\n",
    "# Concatenate tensors\n",
    "all_image_tensors = torch.cat(all_image_tensors)\n",
    "print(f\"Number of images: {all_image_tensors.size(0)}\")\n",
    "print(f\"Number of labels: {len(all_image_labels)}\")\n",
    "assert all_image_tensors.size(0) == len(all_image_labels), \"Mismatch between images and labels!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xPDFYvqaJv5w"
   },
   "source": [
    "Reorganize dataframe to be in the same order as the Image Tensors using the image_label as the matching key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rtFcFs4-Ji7b"
   },
   "outputs": [],
   "source": [
    "##Reset order of dataframe to match the image labels orders\n",
    "all_image_labels_cleaned = [label.split(\".\")[0] for label in all_image_labels] #remove the .png and .jgp\n",
    "print(all_image_labels_cleaned[:10]) #print to see if at the end the df matches\n",
    "\n",
    "filtered_df = df[df[\"Image_Name\"].isin(all_image_labels_cleaned)] #filter the df to only have values from the images\n",
    "print(filtered_df[\"Image_Name\"][:10])\n",
    "print(df.shape)\n",
    "print(filtered_df.shape, len(all_image_labels_cleaned))\n",
    "\n",
    "valid_labels = set(filtered_df['Image_Name'])\n",
    "\n",
    "# Filter labels and tensors\n",
    "filtered_labels_and_tensors = [\n",
    "    (tensor, label) for tensor, label in zip(all_image_tensors, all_image_labels_cleaned) if label in valid_labels\n",
    "]\n",
    "\n",
    "# Unpack the filtered data\n",
    "filtered_tensors, filtered_labels = zip(*filtered_labels_and_tensors)\n",
    "\n",
    "# Convert back to tensors\n",
    "filtered_tensors = torch.stack(filtered_tensors)\n",
    "filtered_labels = list(filtered_labels)\n",
    "\n",
    "# Verify alignment\n",
    "print(f\"Number of filtered tensors: {len(filtered_tensors)}\")\n",
    "print(f\"Number of filtered labels: {len(filtered_labels)}\")\n",
    "print(f\"Number of rows in filtered_df: {len(filtered_df)}\")\n",
    "\n",
    "# Finally reorganize the df to be in the same order as the image tensors\n",
    "filtered_df = filtered_df.set_index(\"Image_Name\").loc[filtered_labels].reset_index()\n",
    "print(filtered_df[\"Image_Name\"][:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mFbLiKRFJxmj"
   },
   "source": [
    "Reformat Ingredients, Recipes, and Image titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7jj7Z9DA5fbw"
   },
   "outputs": [],
   "source": [
    "column = filtered_df[\"Cleaned_Ingredients\"]\n",
    "# item_list = [word\n",
    "#                     for w_list in column\n",
    "#                     for str_list in w_list\n",
    "#                     # Make period and comma separate words\n",
    "#                     # # Remove parentheses and quotes\n",
    "#                     for word in str_list.replace('.', ' . ').replace(',',' , ').replace('(','').replace(')','').replace('\"','').split()]\n",
    "\n",
    "item_list = []\n",
    "element_list = []\n",
    "ingr_max = 0\n",
    "print(\"Column length\", len(column))\n",
    "for w_list in column:\n",
    "    tmp =[]\n",
    "    for str_list in w_list:\n",
    "        # for word in str_list:\n",
    "        formatted = str_list.replace('.', ' . ').replace(',',' , ').replace('(',' ( ').replace(')',' ) ').replace('\"','').split()\n",
    "        item_list.extend(formatted)\n",
    "        new_len = len(formatted)\n",
    "        tmp.extend(formatted)\n",
    "        if new_len>ingr_max:\n",
    "            ingr_max=new_len\n",
    "    element_list.append(tmp)\n",
    "\n",
    "print(item_list[:10])\n",
    "print(element_list[0])\n",
    "print(\"Len Elements:\", len(element_list))\n",
    "ingr_vocab = set(item_list) #We need to keep these even if they are redundant so image tensors stay matching\n",
    "ingr_vocab_size = len(ingr_vocab)\n",
    "print(\"Size:\", ingr_vocab_size)\n",
    "print(\"Max:\", ingr_max)\n",
    "print(ingr_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vPlA1U-v5fbx",
    "outputId": "cbcec89c-d3af-4359-f1d4-b7ba47ce6697"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Prepare', 'barbecue', 'medium', 'heat', '.', 'Arrange', 'vegetables', 'on', 'baking', 'sheets']\n",
      "Size: 21148\n",
      "Max: 247\n"
     ]
    }
   ],
   "source": [
    "column = filtered_df[\"Instructions\"]\n",
    "# item_list = [word\n",
    "#                     for w_list in column\n",
    "#                     for str_list in w_list\n",
    "#                     # Make period and comma separate words\n",
    "#                     # # Remove parentheses and quotes\n",
    "#                     for word in str_list.replace('.', ' . ').replace(',',' , ').replace('(','').replace(')','').replace('\"','').split()]\n",
    "\n",
    "item_list = []\n",
    "inst_max = 0\n",
    "for w_list in column:\n",
    "    for str_list in w_list:\n",
    "        # for word in str_list:\n",
    "        formatted = str_list.replace('.', ' . ').replace(',',' , ').replace('(','').replace(')','').replace('\"','').split()\n",
    "        item_list.extend(formatted)\n",
    "        new_len = len(formatted)\n",
    "        if new_len>inst_max:\n",
    "            inst_max=new_len\n",
    "\n",
    "print(item_list[:10])\n",
    "inst_vocab = set(item_list)\n",
    "inst_vocab_size = len(inst_vocab)\n",
    "print(\"Size:\",inst_vocab_size)\n",
    "print(\"Max:\", inst_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aC8imdkQ5fby"
   },
   "outputs": [],
   "source": [
    "column = filtered_df[\"Title\"].to_list()\n",
    "# item_list = [word\n",
    "#                 for str_list in column\n",
    "#     #                     # Make period and comma separate words\n",
    "#     #                     # # Remove parentheses and quotes\n",
    "#                 for word in str_list.replace('.', ' . ').replace(',',' , ').replace('(','').replace(')','').replace('\"','').split()\n",
    "#                 if word]\n",
    "\n",
    "item_list = []\n",
    "title_max = 0\n",
    "for str_list in column:\n",
    "        # for word in str_list:\n",
    "        formatted = str_list.replace('.', ' . ').replace(',',' , ').replace('(','').replace(')','').replace('\"','').split()\n",
    "        item_list.extend(formatted)\n",
    "        new_len = len(formatted)\n",
    "        if new_len>title_max:\n",
    "            title_max=new_len\n",
    "\n",
    "print(item_list[:10])\n",
    "title_vocab = set(item_list)\n",
    "title_vocab_size = len(title_vocab)\n",
    "print(\"Size:\", title_vocab_size)\n",
    "print(\"Max:\", title_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GFkbm_ZQ5fbz",
    "outputId": "70bd0873-e7aa-41ea-88ff-9188d8c489a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size: 31523\n",
      "Max: 247\n"
     ]
    }
   ],
   "source": [
    "total_vocab = set(list(inst_vocab) + list(ingr_vocab) + list(title_vocab))\n",
    "total_vocab_size = len(total_vocab)\n",
    "print(\"Size:\",total_vocab_size)\n",
    "total_max = max([inst_max, ingr_max, title_max])\n",
    "print(\"Max:\",total_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XgK81ynndVtG"
   },
   "source": [
    "Tokenize Recipes, Ingredients, and Image Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-yVPnmKM5fbz"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "# word_to_ix = {word: i for i, word in enumerate(total_vocab)}\n",
    "\n",
    "# word_to_ix_ingr = {word: i for i, word in enumerate(ingr_vocab)}\n",
    "# word_to_ix_inst = {word: i for i, word in enumerate(inst_vocab)}\n",
    "# word_to_ix_title = {word: i for i, word in enumerate(title_vocab)}\n",
    "\n",
    "word_to_ix = {word: i for i, (word,empty) in enumerate(Counter(total_vocab).most_common(), start=1)}\n",
    "word_to_ix['<PAD>'] = 0\n",
    "print(word_to_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X4yh3sx1XaZi"
   },
   "outputs": [],
   "source": [
    "def tokenize_text(list_object, vocab, max_length):\n",
    "    text = \" \".join(list_object)\n",
    "    tokens = [vocab.get(word, vocab['<PAD>']) for word in text.split()]\n",
    "    # Pad or truncate to max_length\n",
    "    if len(tokens) < max_length:\n",
    "        tokens.extend([vocab['<PAD>']] * (max_length - len(tokens)))\n",
    "    else:\n",
    "        tokens = tokens[:max_length]\n",
    "    return tokens\n",
    "# Tokenize all columns\n",
    "filtered_df['tokenized_ingredients'] = filtered_df['Cleaned_Ingredients'].apply(lambda x: tokenize_text(x, word_to_ix,total_max))\n",
    "filtered_df['tokenized_instructions'] = filtered_df['Instructions'].apply(lambda x: tokenize_text(x, word_to_ix,total_max))\n",
    "filtered_df['tokenized_titles'] = filtered_df['Title'].apply(lambda x: tokenize_text(x, word_to_ix,total_max))\n",
    "\n",
    "print(filtered_df[['tokenized_ingredients', 'tokenized_instructions', 'tokenized_titles', 'Cleaned_Ingredients']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1jZ1lhBw2DnV"
   },
   "source": [
    "Tokenize the Image Labels for the Image Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "w8EKVqNG2CGJ"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import CLIPModel\n",
    "model_name = \"openai/clip-vit-base-patch16\"\n",
    "clip_model = CLIPModel.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "tokenized_labels = tokenizer(\n",
    "    filtered_labels,\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=tokenizer.model_max_length,\n",
    "    return_tensors=\"pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 144
    },
    "id": "-wyy2QXRGF_N",
    "outputId": "3f821fac-b5d8-4bdf-8b7a-3dd92fe7b900"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clip_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-377143b4fab3>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclip_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprojection_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'clip_model' is not defined"
     ]
    }
   ],
   "source": [
    "print(clip_model.config.projection_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iR2ABkwgjtDS"
   },
   "outputs": [],
   "source": [
    "!pip freeze > requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ilxU3rfNFI8j"
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "DL-FetOiVKeT",
    "outputId": "c847acb6-e45f-4e79-87fa-49eaa0f4da9c"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'backward'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-cca43fc08188>\u001b[0m in \u001b[0;36m<cell line: 19>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m }\n\u001b[1;32m     18\u001b[0m \u001b[0mimage2recipe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mR\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mimage2recipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/content/drive/MyDrive/DeepLearning_GroupProject/runner.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    131\u001b[0m                         \u001b[0;31m##Combine the Recipe Encoder Losses and Image Encoder Losses based on TFOOD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m                         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'backward'"
     ]
    }
   ],
   "source": [
    "from runner import Runner as R\n",
    "kwargs = {\n",
    "    'epochs': 10,\n",
    "    'ingredient_tokens': filtered_df['tokenized_ingredients'].to_list(),\n",
    "    'instruction_tokens': filtered_df['tokenized_instructions'].to_list(),\n",
    "    'title_tokens': filtered_df['tokenized_titles'].to_list(),\n",
    "    'image_tensors': filtered_tensors,\n",
    "    'image_labels': tokenized_labels,\n",
    "    'device': device,\n",
    "    'vocab_size': total_vocab_size,\n",
    "    'max_len': total_max,\n",
    "    'clip_model': clip_model,\n",
    "    'optimizer': 'adam',\n",
    "    'learning_rate': 1e-3,\n",
    "    'batch_size': 4\n",
    "\n",
    "}\n",
    "image2recipe = R(**kwargs)\n",
    "image2recipe.train()\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
