{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b48eeacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from My_MMR import MMR\n",
    "from models.MMR import TDB\n",
    "from models.MMR import MMR_losses\n",
    "\n",
    "# Define dummy data parameters\n",
    "batch_size = 8  # Adjust as needed\n",
    "seq_len = 10  # Length of the token sequence, adjust as needed\n",
    "hidden_dim = 1024  # Size of the feature vectors\n",
    "num_heads = 4  # Number of attention heads\n",
    "ITEM_lyrs = 2  # Number of ITEM layers\n",
    "MTD_lyrs = 2  # Number of MTD layers\n",
    "projection_dim = 512  # Projection dimension\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "228a31a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dummy data (projected recipe and image embeddings)\n",
    "recipe_tokens = torch.randn(batch_size, seq_len, hidden_dim)  # Shape: [batch_size, seq_len, hidden_dim]\n",
    "image_tokens = torch.randn(batch_size, seq_len, hidden_dim)  # Shape: [batch_size, seq_len, hidden_dim]\n",
    "# Create labels for testing\n",
    "labels = torch.randint(0, 2, (batch_size,)).float()  # Random binary labels for instance loss calculation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8ca931da",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'headsi' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Instantiate the MMR model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m mmr_model \u001b[38;5;241m=\u001b[39m MMR(hidden_dim\u001b[38;5;241m=\u001b[39mhidden_dim, num_heads\u001b[38;5;241m=\u001b[39mnum_heads, ITEM_lyrs\u001b[38;5;241m=\u001b[39mITEM_lyrs, MTD_lyrs\u001b[38;5;241m=\u001b[39mMTD_lyrs, projection_dim\u001b[38;5;241m=\u001b[39mprojection_dim)\n",
      "File \u001b[0;32m~/OMSCS/DL_7643/indv_proj/My_MMR.py:164\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, hidden_dim, num_heads, ITEM_lyrs, MTD_lyrs, projection_dim)\u001b[0m\n\u001b[1;32m    162\u001b[0m # CITATION: https://pytorch.org/docs/stable/generated/torch.nn.TransformerDecoderLayer.html \n\u001b[1;32m    163\u001b[0m # self.ITEM = nn.ModuleList([TDB(self.hidden_dim, self.num_heads) for _ in range(self.ITEM_lyrs)])\n\u001b[0;32m--> 164\u001b[0m self.ITEM = nn.ModuleList([TDB(self.hidden_dim, self.num_heads) for _ in range(self.ITEM_lyrs)])\n\u001b[1;32m    165\u001b[0m # Multimodal transformer decoder (MTD) --> using tdb implentation\n\u001b[1;32m    166\u001b[0m self.MTD = nn.ModuleList([TDB(self.hidden_dim, self.num_heads) for _ in range(self.MTD_lyrs)])\n",
      "File \u001b[0;32m~/OMSCS/DL_7643/indv_proj/My_MMR.py:164\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    162\u001b[0m # CITATION: https://pytorch.org/docs/stable/generated/torch.nn.TransformerDecoderLayer.html \n\u001b[1;32m    163\u001b[0m # self.ITEM = nn.ModuleList([TDB(self.hidden_dim, self.num_heads) for _ in range(self.ITEM_lyrs)])\n\u001b[0;32m--> 164\u001b[0m self.ITEM = nn.ModuleList([TDB(self.hidden_dim, self.num_heads) for _ in range(self.ITEM_lyrs)])\n\u001b[1;32m    165\u001b[0m # Multimodal transformer decoder (MTD) --> using tdb implentation\n\u001b[1;32m    166\u001b[0m self.MTD = nn.ModuleList([TDB(self.hidden_dim, self.num_heads) for _ in range(self.MTD_lyrs)])\n",
      "File \u001b[0;32m~/OMSCS/DL_7643/indv_proj/My_MMR.py:111\u001b[0m, in \u001b[0;36m__init__\u001b[0;34m(self, hidden_dim, heads, hidden_factor)\u001b[0m\n\u001b[1;32m    109\u001b[0m \n\u001b[1;32m    110\u001b[0m         # Self attention --> ouput is attn_output, attn_output_weights, so we only care about the first\n\u001b[0;32m--> 111\u001b[0m         self.self_attn = nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=headsi, batch_first=True)\n\u001b[1;32m    112\u001b[0m         self.norm_sa = nn.LayerNorm(hidden_dim)\n\u001b[1;32m    113\u001b[0m         # Cross attention\n",
      "\u001b[0;31mNameError\u001b[0m: name 'headsi' is not defined"
     ]
    }
   ],
   "source": [
    "# Instantiate the MMR model\n",
    "mmr_model = MMR(hidden_dim=hidden_dim, num_heads=num_heads, ITEM_lyrs=ITEM_lyrs, MTD_lyrs=MTD_lyrs, projection_dim=projection_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a6922d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass through the model\n",
    "logits = mmr_model(recipe_tokens, image_tokens, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def4e157",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sem_loss = instance_semantic_loss(image_tokens, recipe_tokens, labels, 1, mode='semantic')\n",
    "inst_loss = instance_semantic_loss(image_tokens, recipe_tokens, labels, 1, mode='instance')\n",
    "itm_loss = itm_loss(mmr_logits, labels)\n",
    "\n",
    "loss = MMR_losses.total_loss(self, labels, image_tokens, text_tokens, mmr_logits, margin=1.0, instance_weight=1.0, sem_weight=1.0, itm_weight=1.0)\n",
    "\n",
    "# Print the outputs for verification\n",
    "print(\"Logits:\", logits)\n",
    "print(\"Instance Loss:\", instance_loss.item())\n",
    "print(\"Semantic Loss:\", semantic_loss.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
