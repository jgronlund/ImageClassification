{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PSBW6ryo-H9v"
   },
   "source": [
    "If using google drive please edit this line to connect to drive location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "w6ZQ_d3W-aQq"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2225,
     "status": "ok",
     "timestamp": 1733360749282,
     "user": {
      "displayName": "Jacob Gronlund",
      "userId": "00200772917564897839"
     },
     "user_tz": 480
    },
    "id": "1YCGTlkW99pN",
    "outputId": "3b5de00c-1a21-4ae3-b1dc-f110855f0831"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "import os, sys\n",
    "\n",
    "# # Mount the google colab\n",
    "# drive.mount(\"/content/drive/\")\n",
    "# GOOGLE_DRIVE_PATH_POST_MYDRIVE = 'DeepLearning_GroupProject/'\n",
    "# GOOGLE_DRIVE_PATH = os.path.join('/content', 'drive', 'MyDrive', GOOGLE_DRIVE_PATH_POST_MYDRIVE)\n",
    "# !ls {GOOGLE_DRIVE_PATH}\n",
    "# sys.path.append(GOOGLE_DRIVE_PATH)\n",
    "\n",
    "GOOGLE_DRIVE_PATH = '.'\n",
    "\n",
    "\n",
    "# relative paths\n",
    "models_dir = 'models'\n",
    "csv_path = 'Data/updated_data_with_lists.csv'\n",
    "tensors_dir = 'Data/tensor_batch_notaugmented'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "executionInfo": {
     "elapsed": 3645,
     "status": "ok",
     "timestamp": 1733360752925,
     "user": {
      "displayName": "Jacob Gronlund",
      "userId": "00200772917564897839"
     },
     "user_tz": 480
    },
    "id": "sGHSvkJG5fbt",
    "outputId": "441d26a7-d8e7-49a8-8fd9-d00753c22da2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13496\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Title</th>\n",
       "      <th>Instructions</th>\n",
       "      <th>Image_Name</th>\n",
       "      <th>Cleaned_Ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Miso-Butter Roast Chicken With Acorn Squash Pa...</td>\n",
       "      <td>[Pat chicken dry with paper towels, season all...</td>\n",
       "      <td>miso-butter-roast-chicken-acorn-squash-panzanella</td>\n",
       "      <td>[1 (3½–4-lb.) whole chicken, 2¾ tsp. kosher sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Crispy Salt and Pepper Potatoes</td>\n",
       "      <td>[Preheat oven to 400°F and line a rimmed bakin...</td>\n",
       "      <td>crispy-salt-and-pepper-potatoes-dan-kluger</td>\n",
       "      <td>[2 large egg whites, 1 pound new potatoes (abo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Thanksgiving Mac and Cheese</td>\n",
       "      <td>[Place a rack in middle of oven; preheat to 40...</td>\n",
       "      <td>thanksgiving-mac-and-cheese-erick-williams</td>\n",
       "      <td>[1 cup evaporated milk, 1 cup whole milk, 1 ts...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Italian Sausage and Bread Stuffing</td>\n",
       "      <td>[Preheat oven to 350°F with rack in middle. Ge...</td>\n",
       "      <td>italian-sausage-and-bread-stuffing-240559</td>\n",
       "      <td>[1 (¾- to 1-pound) round Italian loaf, cut int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Newton's Law</td>\n",
       "      <td>[Stir together brown sugar and hot water in a ...</td>\n",
       "      <td>newtons-law-apple-bourbon-cocktail</td>\n",
       "      <td>[1 teaspoon dark brown sugar, 1 teaspoon hot w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              Title  \\\n",
       "0           0  Miso-Butter Roast Chicken With Acorn Squash Pa...   \n",
       "1           1                    Crispy Salt and Pepper Potatoes   \n",
       "2           2                        Thanksgiving Mac and Cheese   \n",
       "3           3                 Italian Sausage and Bread Stuffing   \n",
       "4           4                                       Newton's Law   \n",
       "\n",
       "                                        Instructions  \\\n",
       "0  [Pat chicken dry with paper towels, season all...   \n",
       "1  [Preheat oven to 400°F and line a rimmed bakin...   \n",
       "2  [Place a rack in middle of oven; preheat to 40...   \n",
       "3  [Preheat oven to 350°F with rack in middle. Ge...   \n",
       "4  [Stir together brown sugar and hot water in a ...   \n",
       "\n",
       "                                          Image_Name  \\\n",
       "0  miso-butter-roast-chicken-acorn-squash-panzanella   \n",
       "1         crispy-salt-and-pepper-potatoes-dan-kluger   \n",
       "2         thanksgiving-mac-and-cheese-erick-williams   \n",
       "3          italian-sausage-and-bread-stuffing-240559   \n",
       "4                 newtons-law-apple-bourbon-cocktail   \n",
       "\n",
       "                                 Cleaned_Ingredients  \n",
       "0  [1 (3½–4-lb.) whole chicken, 2¾ tsp. kosher sa...  \n",
       "1  [2 large egg whites, 1 pound new potatoes (abo...  \n",
       "2  [1 cup evaporated milk, 1 cup whole milk, 1 ts...  \n",
       "3  [1 (¾- to 1-pound) round Italian loaf, cut int...  \n",
       "4  [1 teaspoon dark brown sugar, 1 teaspoon hot w...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "import numpy as np\n",
    "import torch\n",
    "import optuna\n",
    "\n",
    "\n",
    "# Explicitly adding models to the search path\n",
    "models_path = os.path.join(GOOGLE_DRIVE_PATH, models_dir)\n",
    "if models_path not in sys.path:\n",
    "    sys.path.insert(0, models_path)\n",
    "\n",
    "from models import recipe_encoder\n",
    "\n",
    "csv_file = os.path.join(GOOGLE_DRIVE_PATH,csv_path)\n",
    "df = pd.read_csv(csv_file, converters={\"Cleaned_Ingredients\": literal_eval, \"Instructions\": literal_eval})\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zhh--PCsDH3b"
   },
   "source": [
    "Concatenate the batches of preprocessed images into 1 tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4136,
     "status": "ok",
     "timestamp": 1733360757054,
     "user": {
      "displayName": "Jacob Gronlund",
      "userId": "00200772917564897839"
     },
     "user_tz": 480
    },
    "id": "Wi-yY_TlDHPn",
    "outputId": "1d9ce4a1-df50-4a25-ce6f-24be3bbac290"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded batch_0.pt\n",
      "Loaded batch_1.pt\n",
      "Loaded batch_2.pt\n",
      "Loaded batch_3.pt\n",
      "Loaded batch_4.pt\n",
      "Number of images: 5000\n",
      "Number of labels: 5000\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "# Use natural sorting: https://stackoverflow.com/a/16090640\n",
    "nat_sort = lambda s: [int(t) if t.isdigit() else t.lower() for t in re.split(r'(\\d+)', s)]\n",
    "\n",
    "pt_files = sorted(os.listdir(os.path.join(GOOGLE_DRIVE_PATH,tensors_dir)), key=nat_sort)\n",
    "all_image_tensors = []\n",
    "all_image_labels = []\n",
    "\n",
    "# Load and combine all .pt files\n",
    "for pt_file in pt_files[:5]:\n",
    "    pt_filepath = os.path.join(GOOGLE_DRIVE_PATH,tensors_dir,pt_file)\n",
    "    image_tensors, image_labels = torch.load(pt_filepath, weights_only=False)\n",
    "    all_image_tensors.append(image_tensors)\n",
    "    all_image_labels.extend(image_labels)\n",
    "    print(f\"Loaded {pt_file}\")\n",
    "\n",
    "# Concatenate tensors\n",
    "all_image_tensors = torch.cat(all_image_tensors)\n",
    "print(f\"Number of images: {all_image_tensors.size(0)}\")\n",
    "print(f\"Number of labels: {len(all_image_labels)}\")\n",
    "assert all_image_tensors.size(0) == len(all_image_labels), \"Mismatch between images and labels!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xPDFYvqaJv5w"
   },
   "source": [
    "Reorganize dataframe to be in the same order as the Image Tensors using the image_label as the matching key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 337,
     "status": "ok",
     "timestamp": 1733360757386,
     "user": {
      "displayName": "Jacob Gronlund",
      "userId": "00200772917564897839"
     },
     "user_tz": 480
    },
    "id": "rtFcFs4-Ji7b",
    "outputId": "f8beaaf9-4e17-4804-edcf-1b18fcbd7173"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['spanish-style-grilled-vegetables-with-breadcrumb-picada-238806', 'three-cheese-pizza-with-onion-sage-and-arugula-233543', 'speedy-skillet-ravioli-lasagna', 'summer-anchovy-salad-51108430', 'spice-roasted-cornish-hens-with-cucumber-yogurt-sauce-353418', 'stovetop-butterscotch-apples-and-cranberries', 'tarte-tatin-51196820', 'spanish-olive-and-cream-cheese-canapes-231160', 'spice-rubbed-sustainable-fish-sliders', 'spiced-pumpkin-layer-cake-240123']\n",
      "2            thanksgiving-mac-and-cheese-erick-williams\n",
      "5                  warm-comfort-tequila-chamomile-toddy\n",
      "7                     turmeric-hot-toddy-claire-sprouse\n",
      "9        spiced-lentil-and-caramelized-onion-baked-eggs\n",
      "11          spiral-ham-in-the-slow-cooker-guarnaschelli\n",
      "19    roasted-beets-with-crispy-sunchokes-and-pickle...\n",
      "24    sloppy-joe-shirred-eggs-with-spinach-vivian-ho...\n",
      "27                           spicy-coconut-pumpkin-soup\n",
      "30                                trinidad-curry-powder\n",
      "31                                  shrimp-creole-14653\n",
      "Name: Image_Name, dtype: object\n",
      "(13496, 5)\n",
      "(4968, 5) 5000\n",
      "Number of filtered tensors: 4968\n",
      "Number of filtered labels: 4968\n",
      "Number of rows in filtered_df: 4968\n",
      "0    spanish-style-grilled-vegetables-with-breadcru...\n",
      "1    three-cheese-pizza-with-onion-sage-and-arugula...\n",
      "2                       speedy-skillet-ravioli-lasagna\n",
      "3                        summer-anchovy-salad-51108430\n",
      "4    spice-roasted-cornish-hens-with-cucumber-yogur...\n",
      "5         stovetop-butterscotch-apples-and-cranberries\n",
      "6                                 tarte-tatin-51196820\n",
      "7        spanish-olive-and-cream-cheese-canapes-231160\n",
      "8                spice-rubbed-sustainable-fish-sliders\n",
      "9                     spiced-pumpkin-layer-cake-240123\n",
      "Name: Image_Name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "##Reset order of dataframe to match the image labels orders\n",
    "all_image_labels_cleaned = [label.split(\".\")[0] for label in all_image_labels] #remove the .png and .jgp\n",
    "print(all_image_labels_cleaned[:10]) #print to see if at the end the df matches\n",
    "\n",
    "filtered_df = df[df[\"Image_Name\"].isin(all_image_labels_cleaned)] #filter the df to only have values from the images\n",
    "print(filtered_df[\"Image_Name\"][:10])\n",
    "print(df.shape)\n",
    "print(filtered_df.shape, len(all_image_labels_cleaned))\n",
    "\n",
    "valid_labels = set(filtered_df['Image_Name'])\n",
    "\n",
    "# Filter labels and tensors\n",
    "filtered_labels_and_tensors = [\n",
    "    (tensor, label) for tensor, label in zip(all_image_tensors, all_image_labels_cleaned) if label in valid_labels\n",
    "]\n",
    "\n",
    "# Unpack the filtered data\n",
    "filtered_tensors, filtered_labels = zip(*filtered_labels_and_tensors)\n",
    "\n",
    "# Convert back to tensors\n",
    "filtered_tensors = torch.stack(filtered_tensors)\n",
    "filtered_labels = list(filtered_labels)\n",
    "\n",
    "# Verify alignment\n",
    "print(f\"Number of filtered tensors: {len(filtered_tensors)}\")\n",
    "print(f\"Number of filtered labels: {len(filtered_labels)}\")\n",
    "print(f\"Number of rows in filtered_df: {len(filtered_df)}\")\n",
    "\n",
    "# Finally reorganize the df to be in the same order as the image tensors\n",
    "filtered_df = filtered_df.set_index(\"Image_Name\").loc[filtered_labels].reset_index()\n",
    "print(filtered_df[\"Image_Name\"][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 276
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1733360757387,
     "user": {
      "displayName": "Jacob Gronlund",
      "userId": "00200772917564897839"
     },
     "user_tz": 480
    },
    "id": "GeAOZnJ6A5mR",
    "outputId": "7618adce-cc40-4bed-9a8b-cf7f366bdaed"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_Name</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Title</th>\n",
       "      <th>Instructions</th>\n",
       "      <th>Cleaned_Ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spanish-style-grilled-vegetables-with-breadcru...</td>\n",
       "      <td>10787</td>\n",
       "      <td>Spanish-Style Grilled Vegetables with Breadcru...</td>\n",
       "      <td>[Prepare barbecue (medium heat). Arrange veget...</td>\n",
       "      <td>[3 large red bell peppers (about 1 1/2 pounds)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>three-cheese-pizza-with-onion-sage-and-arugula...</td>\n",
       "      <td>12145</td>\n",
       "      <td>Three-Cheese Pizza with Onion, Sage, and Arugula</td>\n",
       "      <td>[Place pizza stone on floor of gas oven or on ...</td>\n",
       "      <td>[1 (1/4-oz) package active dry yeast (2 1/4 te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>speedy-skillet-ravioli-lasagna</td>\n",
       "      <td>551</td>\n",
       "      <td>Speedy Skillet Ravioli Lasagna</td>\n",
       "      <td>[Preheat the oven to 450°F with a rack in the ...</td>\n",
       "      <td>[2 tbsp. extra-virgin olive oil, 2 large garli...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>summer-anchovy-salad-51108430</td>\n",
       "      <td>6117</td>\n",
       "      <td>Summer Anchovy Salad</td>\n",
       "      <td>[Cut tomatoes into fat wedges. Drizzle with ol...</td>\n",
       "      <td>[Tomatoes, Olive oil, Splash of vinegar, Crumb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spice-roasted-cornish-hens-with-cucumber-yogur...</td>\n",
       "      <td>8769</td>\n",
       "      <td>Spice-Roasted Cornish Hens with Cucumber-Yogur...</td>\n",
       "      <td>[Position rack in top third of oven; preheat t...</td>\n",
       "      <td>[3 1 1/4 to 1 1/2-pound Cornish game hens, spl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Image_Name  Unnamed: 0  \\\n",
       "0  spanish-style-grilled-vegetables-with-breadcru...       10787   \n",
       "1  three-cheese-pizza-with-onion-sage-and-arugula...       12145   \n",
       "2                     speedy-skillet-ravioli-lasagna         551   \n",
       "3                      summer-anchovy-salad-51108430        6117   \n",
       "4  spice-roasted-cornish-hens-with-cucumber-yogur...        8769   \n",
       "\n",
       "                                               Title  \\\n",
       "0  Spanish-Style Grilled Vegetables with Breadcru...   \n",
       "1   Three-Cheese Pizza with Onion, Sage, and Arugula   \n",
       "2                     Speedy Skillet Ravioli Lasagna   \n",
       "3                               Summer Anchovy Salad   \n",
       "4  Spice-Roasted Cornish Hens with Cucumber-Yogur...   \n",
       "\n",
       "                                        Instructions  \\\n",
       "0  [Prepare barbecue (medium heat). Arrange veget...   \n",
       "1  [Place pizza stone on floor of gas oven or on ...   \n",
       "2  [Preheat the oven to 450°F with a rack in the ...   \n",
       "3  [Cut tomatoes into fat wedges. Drizzle with ol...   \n",
       "4  [Position rack in top third of oven; preheat t...   \n",
       "\n",
       "                                 Cleaned_Ingredients  \n",
       "0  [3 large red bell peppers (about 1 1/2 pounds)...  \n",
       "1  [1 (1/4-oz) package active dry yeast (2 1/4 te...  \n",
       "2  [2 tbsp. extra-virgin olive oil, 2 large garli...  \n",
       "3  [Tomatoes, Olive oil, Splash of vinegar, Crumb...  \n",
       "4  [3 1 1/4 to 1 1/2-pound Cornish game hens, spl...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mFbLiKRFJxmj"
   },
   "source": [
    "Reformat Ingredients, Recipes, and Image titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XgK81ynndVtG"
   },
   "source": [
    "Tokenize Recipes, Ingredients, and Image Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35793,
     "status": "ok",
     "timestamp": 1733360793175,
     "user": {
      "displayName": "Jacob Gronlund",
      "userId": "00200772917564897839"
     },
     "user_tz": 480
    },
    "id": "wyHgDU2OmUO0",
    "outputId": "4487ffb3-fd35-47d0-cc02-e64cc0867cd7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chelsea/anaconda3/envs/tfood_torch/lib/python3.12/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[[101, 1017, 2312, 2417, 4330, 23582, 1006, 2055, 1015, 1015, 1013, 1016, 7038, 1007, 1010, 27674, 1010, 13916, 1010, 4284, 2098, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1018, 2312, 2887, 8288, 24759, 11390, 1006, 2055, 1015, 1015, 1013, 1018, 7038, 1007, 1010, 21920, 1010, 3013, 3091, 14244, 2046, 1017, 25609, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1018, 5396, 2665, 2030, 3756, 16950, 25955, 3490, 1006, 9544, 8231, 1016, 1997, 2169, 1025, 2055, 1015, 9044, 1007, 1010, 21920, 1010, 3013, 3091, 14244, 2046, 1015, 1013, 1017, 1011, 4960, 1011, 4317, 25609, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 4469, 1011, 6261, 9724, 3514, 1006, 2005, 18651, 2075, 1007, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1020, 7251, 24667, 3619, 4469, 1011, 6261, 9724, 3514, 1010, 4055, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1016, 20548, 18856, 21818, 2015, 1010, 22126, 24881, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1015, 1013, 1016, 5572, 13102, 7828, 9550, 10560, 2417, 11565, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1015, 1013, 1016, 2452, 6090, 3683, 1006, 2887, 7852, 26775, 25438, 2015, 1007, 1008, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1016, 7251, 24667, 3619, 22268, 4511, 29387, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1015, 1013, 1018, 2452, 24881, 4840, 3059, 11968, 8002, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1016, 7251, 24667, 3619, 24881, 4840, 10848, 29451, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1008, 2800, 1999, 1996, 4004, 9440, 2930, 1997, 2070, 26676, 1998, 2012, 4004, 6089, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "[[101, 7374, 26375, 1006, 5396, 3684, 1007, 1012, 13621, 11546, 2006, 21522, 8697, 1012, 8248, 2007, 3514, 1025, 11867, 6657, 19099, 2007, 5474, 1998, 11565, 1012, 18651, 23582, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 3096, 2217, 2091, 1998, 2302, 3810, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2127, 25788, 1998, 1038, 9863, 6850, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 3048, 5681, 2005, 2130, 8434, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2055, 2184, 2781, 1012, 4372, 20464, 9232, 1999, 6081, 4524, 1012, 2292, 3233, 2127, 21049, 29476, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2055, 2382, 2781, 1012, 18651, 8288, 24759, 11390, 1998, 16950, 25955, 3490, 2127, 29030, 1998, 8616, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 3810, 1998, 4373, 24388, 2075, 2005, 2130, 18778, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1019, 2000, 1020, 2781, 1012, 2173, 2006, 17910, 18194, 21522, 7123, 1012, 14113, 23582, 1012, 4651, 2000, 7123, 2007, 8288, 24759, 11390, 1998, 16950, 25955, 3490, 1012, 3684, 1017, 7251, 24667, 3619, 9724, 3514, 1999, 5396, 8066, 3388, 2058, 5396, 3684, 1012, 5587, 20548, 1998, 10560, 2417, 11565, 1025, 16130, 2127, 25312, 18980, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2055, 2382, 3823, 1012, 5587, 7852, 26775, 25438, 2015, 1025, 16130, 2127, 3585, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2055, 1017, 2781, 1012, 2161, 7852, 26775, 25438, 27263, 8447, 2000, 5510, 2007, 5474, 1025, 26988, 2046, 2235, 4605, 1012, 2173, 29387, 1999, 2178, 2235, 4605, 1025, 1059, 24158, 2243, 1999, 1017, 7251, 24667, 3619, 3514, 1012, 4666, 1999, 11968, 8002, 1998, 10848, 29451, 1012, 2161, 2000, 5510, 2007, 5474, 1012, 13621, 11546, 2006, 28005, 2121, 1012, 15642, 12810, 11225, 2058, 1025, 11867, 6657, 19099, 2007, 7852, 26775, 25438, 2015, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "total_max = 128\n",
    "# Initialize the tokenizer\n",
    "tokenizer_recipes = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def tokenize_nested_list(nested_list, max_length=128):\n",
    "    \"\"\"\n",
    "    Tokenizes a nested list of strings (list of ingredients per recipe).\n",
    "    Each inner list is tokenized into a list of token IDs.\n",
    "    \"\"\"\n",
    "    tokenized_list = []\n",
    "    for sublist in nested_list:\n",
    "        # Join the inner list into a string\n",
    "        # text = \" \".join(sublist)\n",
    "        text = str(sublist)\n",
    "        # Tokenize the string\n",
    "        tokens = tokenizer_recipes(\n",
    "            text,\n",
    "            max_length=max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        # Append tokenized input_ids to the result list\n",
    "        tokenized_list.append(tokens[\"input_ids\"].squeeze(0).tolist())\n",
    "    return tokenized_list\n",
    "\n",
    "filtered_df['Title_List'] = df['Title'].apply(lambda x: [x])\n",
    "filtered_df['tokenized_ingredients'] = filtered_df['Cleaned_Ingredients'].apply(lambda x: tokenize_nested_list(x, total_max))\n",
    "filtered_df['tokenized_instructions'] = filtered_df['Instructions'].apply(lambda x: tokenize_nested_list(x, total_max))\n",
    "filtered_df['tokenized_titles'] = filtered_df['Title_List'].apply(lambda x: tokenize_nested_list(x, total_max))\n",
    "\n",
    "\n",
    "print(len(filtered_df[\"tokenized_titles\"][0]))\n",
    "print(filtered_df[\"tokenized_ingredients\"][0])\n",
    "print(filtered_df[\"tokenized_instructions\"][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1733360793176,
     "user": {
      "displayName": "Jacob Gronlund",
      "userId": "00200772917564897839"
     },
     "user_tz": 480
    },
    "id": "52oSgq6k7Ldn",
    "outputId": "3286a7d5-3516-49e1-db8b-238a603fd33f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42 23 1\n",
      "42\n",
      "[[101, 1015, 1013, 1018, 2452, 9724, 3514, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1016, 3009, 24444, 1010, 20956, 1998, 4857, 2135, 15920, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1016, 2312, 18856, 21818, 2015, 20548, 1010, 20956, 1998, 24881, 1010, 4606, 1018, 18856, 21818, 2015, 2878, 20548, 1010, 20956, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1015, 2452, 4318, 2317, 4511, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1016, 3016, 3727, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1020, 7251, 24667, 3619, 4895, 12002, 3064, 12136, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 10869, 1997, 1016, 14380, 2015, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1016, 1006, 1018, 1011, 9044, 1007, 2878, 2417, 10245, 7347, 1010, 12176, 1010, 2007, 2132, 1998, 5725, 10109, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1015, 2235, 20856, 1010, 15920, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1016, 10335, 8292, 3917, 2100, 1010, 11085, 7178, 2892, 14244, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 10869, 1997, 2184, 3145, 14123, 2015, 2030, 2235, 4857, 1011, 19937, 14123, 2015, 1010, 4606, 1018, 14123, 2015, 3013, 2046, 7728, 2005, 3529, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1015, 1013, 1016, 2452, 20392, 2135, 24881, 4840, 25022, 5802, 13181, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1015, 1006, 2260, 1011, 2011, 2324, 1011, 4960, 2030, 3469, 1007, 25043, 2075, 6090, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "(4968, 9)\n"
     ]
    }
   ],
   "source": [
    "def pad_or_truncate_nested(sublist, target_length, max_length, pad_token=0):\n",
    "        \"\"\"\n",
    "            Pad or truncate the outer list of a nested list to match the target_length.\n",
    "            Each inner list remains untouched.\n",
    "        \"\"\"\n",
    "        # Pad with [pad_token] or truncate the outer list\n",
    "        if len(sublist) < target_length:\n",
    "            sublist.extend([[pad_token]* max_length] * (target_length - len(sublist)))\n",
    "        else:\n",
    "            sublist = sublist[:target_length]\n",
    "        return sublist\n",
    "\n",
    "max_length_ing = filtered_df['tokenized_ingredients'].apply(len).max()\n",
    "max_length_inst = filtered_df['tokenized_instructions'].apply(len).max()//4\n",
    "max_length_title = filtered_df['tokenized_titles'].apply(len).max()\n",
    "filtered_df['tokenized_ingredients'] = filtered_df['tokenized_ingredients'].apply(\n",
    "    lambda ing: pad_or_truncate_nested(ing, max_length_ing,total_max))\n",
    "\n",
    "filtered_df['tokenized_instructions'] = filtered_df['tokenized_instructions'].apply(\n",
    "    lambda inst: pad_or_truncate_nested(inst, max_length_inst, total_max))\n",
    "# new_token_ing = [pad_or_truncate_nested(ing, max_length_title) for ing in tokenized_ingredients] #titles were all list length of 1\n",
    "max_length_ing = filtered_df['tokenized_ingredients'].apply(len).max()\n",
    "max_length_inst = filtered_df['tokenized_instructions'].apply(len).max()\n",
    "max_length_title = filtered_df['tokenized_titles'].apply(len).max()\n",
    "print(max_length_ing, max_length_inst, max_length_title)\n",
    "print(len(filtered_df['tokenized_ingredients'][5]))\n",
    "print(filtered_df['tokenized_ingredients'][100])\n",
    "print(filtered_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1jZ1lhBw2DnV"
   },
   "source": [
    "Tokenize the Image Labels for the Image Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "w8EKVqNG2CGJ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chelsea/anaconda3/envs/tfood_torch/lib/python3.12/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import CLIPModel\n",
    "model_name = \"openai/clip-vit-base-patch16\"\n",
    "clip_model = CLIPModel.from_pretrained(model_name)\n",
    "tokenizer_images = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "tokenized_labels = tokenizer_images(\n",
    "    filtered_labels,\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=tokenizer_images.model_max_length,\n",
    "    return_tensors=\"pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1733360798470,
     "user": {
      "displayName": "Jacob Gronlund",
      "userId": "00200772917564897839"
     },
     "user_tz": 480
    },
    "id": "ilxU3rfNFI8j",
    "outputId": "ff756ea5-34c3-481a-ec39-4ae4038ac240"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "%reload_ext autoreload\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "cOR7eQshjPKL"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class RecipeDecoder(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size):\n",
    "        super(RecipeDecoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc_out = nn.Linear(hidden_dim, vocab_size)\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "    def forward(self, input_tokens):\n",
    "        embedded = self.embedding(input_tokens)\n",
    "        outputs, hidden_state = self.rnn(embedded, hidden_state)\n",
    "        predictions = self.fc_out(outputs)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "N_UNJWI5GMCg"
   },
   "outputs": [],
   "source": [
    "def calc_recall(top, image_features, recipe_embeddings, image_labels):\n",
    "  true_pos = 0\n",
    "  false_neg = 0\n",
    "  tmp_batches = image_features.shape[0]\n",
    "  image_features = torch.nn.functional.normalize(image_features, dim=1)\n",
    "  recipe_embeddings = torch.nn.functional.normalize(recipe_embeddings, dim=1)\n",
    "  top_embedded = []\n",
    "  for i in range(tmp_batches):\n",
    "    cosine_similarity = torch.nn.CosineSimilarity(dim=1)\n",
    "    # similarities = cosine_similarity(image_features[i, :].unsqueeze(0), recipe_embeddings)\n",
    "    similarities = cosine_similarity(image_features[i], recipe_embeddings)\n",
    "    #top = amount of top results to retrieve\n",
    "    top_results = top\n",
    "    top_k_values, top_k_indices = torch.topk(similarities, top_results, largest=True)\n",
    "    top_k_indices = top_k_indices.tolist()\n",
    "    top_images = [filtered_df['Image_Name'].iloc[i] for i in top_k_indices]\n",
    "    top_embedded.append(recipe_embeddings[top_k_indices[0]].detach().cpu().numpy())\n",
    "    # print(top_k_values, top_k_indices)\n",
    "    print(\"Correct Image label: \", image_labels[i])\n",
    "    print(top_k_indices)\n",
    "    print(top_images)\n",
    "    image_labels_str = image_labels[i].split(\".\")[0]\n",
    "    if image_labels_str in [image[0] for image in top_images]:\n",
    "      true_pos += 1\n",
    "    else:\n",
    "      false_neg += 1\n",
    "  print(\"total found = \", true_pos)\n",
    "  plot_2D(top_embedded, image_features, multiplier=None, batch_size=None)\n",
    "  return true_pos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "nc71r5-Uyouz"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch\n",
    "from models.image_2_recipe import Image2Recipe\n",
    "from models.image_encoder import Image_Encoder\n",
    "from models.recipe_encoder import RecipeEncoder\n",
    "from models.MMR import MMR\n",
    "from models.MMR import MMR_losses\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "class Data_Loading(Dataset):\n",
    "    \"\"\"\n",
    "    Class to combine the Images, Labels, Recipes together to be used in combination when inputted into Model\n",
    "    \"\"\"\n",
    "    def __init__(self, tokenized_ingredients, tokenized_instructions, tokenized_titles, image_tensors, image_labels):\n",
    "        self.ingredients = torch.tensor(tokenized_ingredients, dtype=torch.int16)\n",
    "        self.instructions = torch.tensor(tokenized_instructions, dtype=torch.int16)\n",
    "        self.titles = torch.tensor(tokenized_titles, dtype=torch.int16)\n",
    "        self.images = image_tensors\n",
    "        self.image_labels = image_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"ingredients\": self.ingredients[idx],\n",
    "            \"instructions\": self.instructions[idx],\n",
    "            \"titles\": self.titles[idx],\n",
    "            \"images\": self.images[idx],\n",
    "            \"image_labels\": self.image_labels[idx]\n",
    "\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "class Trainer(object):\n",
    "    \"\"\"\n",
    "    Class designed to run ViT (train, evaluate, plot)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Initialize ViT\n",
    "        \"\"\"\n",
    "        self.epochs = kwargs['epochs']\n",
    "        self.optimizer_name = kwargs['optimizer']\n",
    "        self.device = kwargs['device']\n",
    "        self.batch_size = kwargs['batch_size']\n",
    "        self.lr = kwargs['learning_rate']\n",
    "\n",
    "        self.tokenized_ingredients = kwargs['ingredient_tokens']\n",
    "        self.tokenized_instructions = kwargs['instruction_tokens']\n",
    "        self.tokenized_title = kwargs['title_tokens']\n",
    "        self.image_tensor = kwargs['image_tensors']\n",
    "        self.image_labels = kwargs['image_labels']\n",
    "        self.clip_model = kwargs['clip_model']\n",
    "        self.vocab_size = kwargs['vocab_size']\n",
    "        self.max_len = kwargs['max_len']\n",
    "        self.instance_weight = kwargs['instance_weight']\n",
    "        self.sem_weight = kwargs['sem_weight']\n",
    "        self.itm_weight = kwargs['itm_weight']\n",
    "        self.best_model_parameters = kwargs['best_model_parameters_path']\n",
    "        # self.margin = kwargs['margin']\n",
    "        self.initial_margin = kwargs['initial_margin']\n",
    "        self.margin_step = kwargs['margin_step']\n",
    "        self.max_margin = kwargs['max_margin']\n",
    "        self.topk = kwargs['topk']\n",
    "        self.fixed_margin = kwargs['fixed_margin']\n",
    "        self.unfreeze_epochs = kwargs['unfreeze_epochs']\n",
    "        # self.improvement_threshold = kwargs['improvement_threshold']\n",
    "        self.patience = kwargs['patience']\n",
    "        \n",
    "        # Pending variable margin calc\n",
    "        # self.loss_calcs = MMR_losses(margin=1.0, instance_weight=self.instance_weight, sem_weight=self.sem_weight, itm_weight=self.itm_weight)\n",
    "        self.loss_calcs = MMR_losses(instance_weight=self.instance_weight, sem_weight=self.sem_weight, itm_weight=self.itm_weight)\n",
    "        # num_classes = len(set(self.image_labels['input_ids']))\n",
    "        num_classes = len(set(self.image_labels))\n",
    "        # print(num_classes)\n",
    "\n",
    "\n",
    "        self.image_encoder = Image_Encoder(self.device, self.clip_model, num_classes).to(self.device)\n",
    "        self.recipe_encoder = RecipeEncoder(self.device, self.vocab_size, self.max_len).to(self.device)\n",
    "        self.mmr = MMR(hidden_dim=self.image_encoder.clip_model.config.projection_dim).to(self.device)\n",
    "        # self.recipe_decoder = RecipeDecoder(512,512,self.vocab_size).to(self.device)\n",
    "        # MMR varaibles: num_heads=num_heads, ITEM_lyrs=ITEM_lyrs, MTD_lyrs=MTD_lyrs, projection_dim=projection_dim\n",
    "        self.model = Image2Recipe(self.image_encoder, self.recipe_encoder, self.mmr).to(self.device)\n",
    "\n",
    "\n",
    "        # Freeze image encoder initially\n",
    "        for param in self.model.image_encoder.parameters():\n",
    "          param.requires_grad = False\n",
    "\n",
    "        ##DO we want to tune each of these learning rates for each model?\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        # self.optimizer2 = torch.optim.Adam(self.recipe_decoder.parameters(), lr=self.lr)\n",
    "        # self.optimizer = torch.optim.AdamW([\n",
    "        #     {\"params\": self.model.image_encoder.parent_model.parameters(), \"lr\": 1e-6},\n",
    "        #     {\"params\": self.model.recipe_encoder.parameters(), \"lr\": 1e-5},\n",
    "        #     {\"params\": self.model.image_encoder.fc1.parameters(), \"lr\": 1e-5},\n",
    "        #     {\"params\": self.model.recipe_encoder.ll_e.parameters(), \"lr\": 1e-5},\n",
    "        # ])\n",
    "\n",
    "\n",
    "        #Combine Images, Recipes, Instructions in training and eval datasets\n",
    "        self.data_total = Data_Loading(\n",
    "            self.tokenized_ingredients,\n",
    "            self.tokenized_instructions,\n",
    "            self.tokenized_title,\n",
    "            self.image_tensor,\n",
    "            self.image_labels\n",
    "        )\n",
    "        training_perc = .9\n",
    "        train_size = int(training_perc * len(self.data_total))\n",
    "        eval_size = len(self.data_total) - train_size\n",
    "        train_dataset, eval_dataset = random_split(self.data_total, [train_size, eval_size])\n",
    "        self.dataloader = {}\n",
    "        self.dataloader['train'] = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True, drop_last=True)\n",
    "        self.dataloader['eval'] = DataLoader(eval_dataset, batch_size=self.batch_size, shuffle=False, drop_last=True)\n",
    "\n",
    "        #Lists to fill up during training and plotted later for learning curves\n",
    "        self.train_loss_list = []\n",
    "        self.eval_loss_list = []\n",
    "        self.eval_acc_list = []\n",
    "        self.eval_acc_list = []\n",
    "        self.best_score = 0\n",
    "        self.best_loss = 1000\n",
    "        print(\"finished initializing\")\n",
    "\n",
    "        # self.CELoss = nn.CrossEntropyLcoss(ignore_index=PAD_IDX)\n",
    "        # self.decoder_lambda = kwargs['decoder_lambda']\n",
    "\n",
    "    def train(self, trial=None):\n",
    "        \"\"\"\n",
    "        Train ViT, image encoder, recipe encoder, MMR\n",
    "        \"\"\"\n",
    "        # Set initial margin\n",
    "        self.margin = self.initial_margin\n",
    "        patience_count = 0\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "            if epoch==self.unfreeze_epochs:\n",
    "                # Unfreeze image encoder\n",
    "                for param in self.model.image_encoder.parameters():\n",
    "                    param.requires_grad = True\n",
    "                print(\"unfreezing image encoder\")\n",
    "                self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr) \n",
    "            for phase in ['train', 'eval']:\n",
    "                total_loss = 0\n",
    "                total_accuracy = 0\n",
    "                total_eval_loss = 0\n",
    "                if phase == 'train':\n",
    "                    self.model.train()\n",
    "                else:\n",
    "                    self.model.eval()\n",
    "                for i, batch_data in enumerate(tqdm(self.dataloader[phase],position=0, leave=True)):\n",
    "                    #Looping through batches of training data then eval data each epoch\n",
    "                    #TODO: Add how the recipe, instructions, and titles will be tokenized\n",
    "                    ingredients, instructions, titles, images, image_labels = (\n",
    "                        batch_data['ingredients'].to(self.device),\n",
    "                        batch_data['instructions'].to(self.device),\n",
    "                        batch_data['titles'].to(self.device),\n",
    "                        batch_data['images'].to(self.device),\n",
    "                        batch_data['image_labels']\n",
    "                    )\n",
    "\n",
    "                    recipe_enc_src = [titles, ingredients, instructions]\n",
    "                    self.optimizer.zero_grad()\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        output = self.model(images, image_labels, recipe_enc_src)\n",
    "                        ##Combine the Recipe Encoder Losses and Image Encoder Losses based on TFOOD\n",
    "                        mmr_logits = output[\"mmr_logits\"]\n",
    "                        image_logits = output[\"image_logits\"]\n",
    "                        image_embeddings_proj = output[\"image_embeddings_proj\"]\n",
    "                        recipe_embeddings_proj = output[\"recipe_embeddings_proj\"]\n",
    "                        # image_embeddings = output[\"image_embeddings\"]\n",
    "                        # recipe_embeddings = output[\"recipe_embeddings\"]\n",
    "\n",
    "                        # #Train the Recipe Decoder so it can output a generative (Title, Ingredient, Instructions)\n",
    "                        # title_logits = self.recipe_decoder(image_embeddings, titles)\n",
    "                        # ingredients_logits = self.recipe_decoder(image_embeddings, ingredients)\n",
    "                        # instructions_logits = self.recipe_decoder(image_embeddings, instructions)\n",
    "\n",
    "                        # #Compute Reconstruction Loss\n",
    "                        # title_loss = self.CELoss(title_logits.transpose(1, 2), titles)\n",
    "                        # ingredients_loss = self.CELoss(ingredients_logits.transpose(1, 2), ingredients)\n",
    "                        # instructions_loss = self.CELoss(instructions_logits.transpose(1, 2), instructions)\n",
    "                        # decoder_loss = (title_loss + ingredients_loss + instructions_loss) *self.decoder_lambda\n",
    "\n",
    "                        loss = self.loss_calcs.total_loss(image_logits, image_embeddings_proj,\n",
    "                                                          recipe_embeddings_proj, mmr_logits, margin=self.margin)\n",
    "\n",
    "                        # print(f'training loss for step: {loss.item()}')\n",
    "                        # recall_score = calc_recall(self.topk, image_embeddings_proj, recipe_embeddings_proj, image_labels)\n",
    "                        # print(recall_score)\n",
    "                        loss.backward()\n",
    "                        self.optimizer.step()\n",
    "                        # self.optimizer2.step() #decoder optimizer\n",
    "                        total_loss += loss.item()\n",
    "\n",
    "\n",
    "\n",
    "                    else: ##Eval mode\n",
    "                        with torch.no_grad():\n",
    "                            output = self.model(images, image_labels, recipe_enc_src)\n",
    "                            mmr_logits = output[\"mmr_logits\"]\n",
    "                            image_logits = output[\"image_logits\"]\n",
    "                            image_embeddings_proj = output[\"image_embeddings_proj\"]\n",
    "                            recipe_embeddings_proj = output[\"recipe_embeddings_proj\"]\n",
    "                            # #Train the Recipe Decoder so it can output a generative (Title, Ingredient, Instructions)\n",
    "                            # title_logits = self.recipe_decoder(image_embeddings, titles)\n",
    "                            # ingredients_logits = self.recipe_decoder(image_embeddings, ingredients)\n",
    "                            # instructions_logits = self.recipe_decoder(image_embeddings, instructions)\n",
    "\n",
    "                            # #Compute Reconstruction Loss\n",
    "                            # title_loss = self.CELoss(title_logits.transpose(1, 2), titles)\n",
    "                            # ingredients_loss = self.CELoss(ingredients_logits.transpose(1, 2), ingredients)\n",
    "                            # instructions_loss = self.CELoss(instructions_logits.transpose(1, 2), instructions)\n",
    "                            # decoder_loss = (title_loss + ingredients_loss + instructions_loss) * self.decoder_lambda\n",
    "                            eval_loss = self.loss_calcs.total_eval_loss(image_logits, image_embeddings_proj,\n",
    "                                                                   recipe_embeddings_proj, margin=self.fixed_margin)# + decoder_loss\n",
    "                            total_eval_loss += eval_loss.item()\n",
    "                            # print(f'eval loss for step: {loss}')\n",
    "                            # self.eval_loss_list.append(loss.item())\n",
    "\n",
    "                            # recall_score = calc_recall(self.topk, image_embeddings_proj, recipe_embeddings_proj, image_labels)\n",
    "                            # print(recall_score)\n",
    " \n",
    "                    \n",
    "                    # del unused_tensor\n",
    "                    torch.cuda.empty_cache() #clear cache after each batch\n",
    "                    # print(i)\n",
    "                    # print(output)\n",
    "                    \n",
    "\n",
    "                # Update loss margin\n",
    "                if self.margin <= (self.max_margin - self.margin_step):\n",
    "                    self.margin += self.margin_step\n",
    "                else:\n",
    "                    self.margin = self.max_margin\n",
    "                if phase == \"train\":\n",
    "                    # Avg loss over the epoch\n",
    "                    epoch_loss = total_loss / len(self.dataloader[phase])\n",
    "                    print(f\"{phase}: Epoch {epoch+1}, Loss: {epoch_loss}\")\n",
    "                    self.train_loss_list.append(epoch_loss)\n",
    "\n",
    "                    # Check if optuna's training trial should continue\n",
    "                    if trial:\n",
    "                        trial.report(epoch_loss, epoch)\n",
    "                        if trial.should_prune():\n",
    "                            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "                else:\n",
    "                    epoch_eval_loss = total_eval_loss/len(self.dataloader[phase])\n",
    "                    self.eval_loss_list.append(epoch_eval_loss)\n",
    "                    print(f\"{phase}: Epoch {epoch+1}, Loss: {epoch_eval_loss}\")\n",
    "\n",
    "                    if total_eval_loss < self.best_loss:\n",
    "                        patience_count = 0\n",
    "                        self.best_loss = total_eval_loss\n",
    "                        torch.save(self.model.state_dict(), self.best_model_parameters)\n",
    "                        print(\"Saving best model\")\n",
    "                        # torch.save()\n",
    "                    else:\n",
    "                        patience_count += 1\n",
    "                        if patience_count >= self.patience:\n",
    "                            print(\"Early stopping\")\n",
    "                            return epoch_loss\n",
    "\n",
    "        return epoch_loss # Epoch loss from final epoch\n",
    "\n",
    "    ##Waiting on training code to finish\n",
    "    def plot_learning_loss_curves(self, name=None, title=None):\n",
    "        \"\"\"\n",
    "        Plot accuracy and loss curves for training and eval accuracy/loss lists (item/epoch)\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(self.train_loss_list, label='Training Loss')\n",
    "        plt.plot(self.eval_loss_list, label='Validation Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        if not title:\n",
    "            title = 'Loss Curve'\n",
    "\n",
    "        plt.title(title)\n",
    "        plt.legend()\n",
    "        if not name:\n",
    "            name = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "        plt.savefig(f'{name}.png')\n",
    "        plt.show()\n",
    "\n",
    "        # plt.figure(figsize=(10, 5))\n",
    "        # plt.plot(self.train_acc_list, label='Training Accuracy')\n",
    "        # plt.plot(self.eval_acc_list, label='Validation Accuracy')\n",
    "        # plt.xlabel('Epoch')\n",
    "        # plt.ylabel('Accuracy')\n",
    "        # plt.title('Accuracy Curve')\n",
    "        # plt.legend()\n",
    "        # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1733360799007,
     "user": {
      "displayName": "Jacob Gronlund",
      "userId": "00200772917564897839"
     },
     "user_tz": 480
    },
    "id": "4lOE7ew3Czjr",
    "outputId": "de763ca3-9a69-4081-9c58-122f686eb8c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-11 01:33:44,059] A new study created in RDB with name: recipe_checkpoint_12-11_01-33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished initializing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37e8d9f743e6444281c90c9ff5bd5d49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/447 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##  Optuna\n",
    "\n",
    "# name of the resuting optuna file\n",
    "current_time = datetime.now().strftime('%m-%d_%H-%M')\n",
    "study_name=f\"recipe_checkpoint_{current_time}\"\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "vocab_size = tokenizer_recipes.vocab_size\n",
    "param_path = os.path.join(GOOGLE_DRIVE_PATH, \"best_models/{}-best_model.pth\")\n",
    "os.makedirs(os.path.join(GOOGLE_DRIVE_PATH, \"best_models\"), exist_ok=True)\n",
    "recipe_embeddings_path  = os.path.join(GOOGLE_DRIVE_PATH, \"models/recipe_embeddings.pth\")\n",
    "n_trials = 30\n",
    "\n",
    "def objective(trial):\n",
    "    try:\n",
    "        trial_name = f\"{study_name}__Trial_{trial.number}\"\n",
    "        \n",
    "        kwargs = {\n",
    "            'epochs': 15,\n",
    "            'ingredient_tokens': filtered_df['tokenized_ingredients'].to_list(),\n",
    "            'instruction_tokens': filtered_df['tokenized_instructions'].to_list(),\n",
    "            'title_tokens': filtered_df['tokenized_titles'].to_list(),\n",
    "            'image_tensors': filtered_tensors,\n",
    "            'image_labels': filtered_df['Image_Name'],\n",
    "            'device': device,\n",
    "            'vocab_size': vocab_size,\n",
    "            'max_len': total_max,\n",
    "            'clip_model': clip_model,\n",
    "            'optimizer': 'adam',\n",
    "            'learning_rate': trial.suggest_float('lr', 1e-9, 1e-2, log=True),\n",
    "            'batch_size': 10,\n",
    "            'instance_weight': trial.suggest_float('inst_w', 1e-3, 50, log=True),\n",
    "            'sem_weight': trial.suggest_float('sem_w', 1e-3, 50, log=True),\n",
    "            'itm_weight': trial.suggest_float('itm_w', 1e-3, 50, log=True),\n",
    "            'initial_margin': trial.suggest_float('init_margin', 5e-4, 30, log=True),\n",
    "            'margin_step': trial.suggest_float('margin_step', 5e-4, 3, log=True),\n",
    "            'max_margin':trial.suggest_float('max_margin', 0.3, 1000, log=True),\n",
    "            'best_model_parameters_path': param_path.format(f\"{trial_name}\"),\n",
    "            # 'decoder_lambda': trial.suggest_float('lambda', 1e-4, 1, log=True),\n",
    "            'unfreeze_epochs': trial.suggest_int('unfreeze_epochs', 0, 10),\n",
    "            'topk': 10,\n",
    "            'fixed_margin': trial.suggest_float('fixed_margin', 5e-4, 50, log=True),\n",
    "            'patience': 10\n",
    "\n",
    "            # 'max_lengths': {\n",
    "            #     'ingredient_tokens': max_length_ing,\n",
    "            #     'instruction_tokens': max_length_inst,\n",
    "            #     'title_tokens': max_length_title\n",
    "            # }\n",
    "        }\n",
    "        torch.cuda.empty_cache() #clear cache before each run\n",
    "\n",
    "        image2recipe = Trainer(**kwargs)\n",
    "        final_loss = image2recipe.train(trial)\n",
    "    finally:\n",
    "        image2recipe.plot_learning_loss_curves(name=f\"{trial_name}\",\n",
    "                                           title=f\"Trial {trial.number} Loss Curves\")\n",
    "    \n",
    "    return final_loss\n",
    "\n",
    "\n",
    "# Create a study object and optimize the objective function.\n",
    "# A new file will be saved called {study_name}.db containing the study\n",
    "storage_name = \"sqlite:///{}.db\".format(study_name)\n",
    "study = optuna.create_study(study_name=study_name,\n",
    "                            storage=storage_name,\n",
    "                            direction='minimize',\n",
    "                            sampler=optuna.samplers.RandomSampler(),\n",
    "                            pruner=optuna.pruners.MedianPruner(),\n",
    "                            load_if_exists=True # allows for study to be resumed\n",
    "                            )\n",
    "study.optimize(objective, n_trials=n_trials)\n",
    "\n",
    "pruned_trials = study.get_trials(states=(optuna.trial.TrialState.PRUNED,))\n",
    "complete_trials = study.get_trials(states=(optuna.trial.TrialState.COMPLETE,))\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tfood_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "358a4e5e3b984f279ae03e8d26d43d2b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "36365b4998824614b8bfa84a9e5e86a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_407856979a714799a01c25eec68c93d1",
      "placeholder": "​",
      "style": "IPY_MODEL_a71edb6d334e4eef82c827cbc0817a65",
      "value": "  0%"
     }
    },
    "37d2b668bb2a4230bfedaa925bb70551": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "407856979a714799a01c25eec68c93d1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5428352e9fab4cd3a415bee09d5cc6e9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "946ba10c9b9b4d4b90e317deff7c73ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ab6173676ed54c13a72323956e0fcc08",
      "placeholder": "​",
      "style": "IPY_MODEL_37d2b668bb2a4230bfedaa925bb70551",
      "value": " 0/447 [00:01&lt;?, ?it/s]"
     }
    },
    "a71edb6d334e4eef82c827cbc0817a65": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ab6173676ed54c13a72323956e0fcc08": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bdff5aea515a4f6a88a4aef08c1d0792": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c8d80345b3d04503a0ba492d2e21437f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_36365b4998824614b8bfa84a9e5e86a9",
       "IPY_MODEL_f38e682756534d4bae6e203cdb371697",
       "IPY_MODEL_946ba10c9b9b4d4b90e317deff7c73ab"
      ],
      "layout": "IPY_MODEL_bdff5aea515a4f6a88a4aef08c1d0792"
     }
    },
    "f38e682756534d4bae6e203cdb371697": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5428352e9fab4cd3a415bee09d5cc6e9",
      "max": 447,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_358a4e5e3b984f279ae03e8d26d43d2b",
      "value": 0
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
