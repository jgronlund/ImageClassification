{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PSBW6ryo-H9v"
   },
   "source": [
    "If using google drive please edit this line to connect to drive location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "w6ZQ_d3W-aQq"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2225,
     "status": "ok",
     "timestamp": 1733360749282,
     "user": {
      "displayName": "Jacob Gronlund",
      "userId": "00200772917564897839"
     },
     "user_tz": 480
    },
    "id": "1YCGTlkW99pN",
    "outputId": "3b5de00c-1a21-4ae3-b1dc-f110855f0831"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "import os, sys\n",
    "\n",
    "# # Mount the google colab\n",
    "# drive.mount(\"/content/drive/\")\n",
    "# GOOGLE_DRIVE_PATH_POST_MYDRIVE = 'DeepLearning_GroupProject/'\n",
    "# GOOGLE_DRIVE_PATH = os.path.join('/content', 'drive', 'MyDrive', GOOGLE_DRIVE_PATH_POST_MYDRIVE)\n",
    "# !ls {GOOGLE_DRIVE_PATH}\n",
    "# sys.path.append(GOOGLE_DRIVE_PATH)\n",
    "\n",
    "GOOGLE_DRIVE_PATH = '.'\n",
    "\n",
    "\n",
    "# relative paths\n",
    "models_dir = 'models'\n",
    "csv_path = 'Data/updated_data_with_lists.csv'\n",
    "tensors_dir = 'Data/tensor_batch_notaugmented'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "executionInfo": {
     "elapsed": 3645,
     "status": "ok",
     "timestamp": 1733360752925,
     "user": {
      "displayName": "Jacob Gronlund",
      "userId": "00200772917564897839"
     },
     "user_tz": 480
    },
    "id": "sGHSvkJG5fbt",
    "outputId": "441d26a7-d8e7-49a8-8fd9-d00753c22da2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13496\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Title</th>\n",
       "      <th>Instructions</th>\n",
       "      <th>Image_Name</th>\n",
       "      <th>Cleaned_Ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Miso-Butter Roast Chicken With Acorn Squash Pa...</td>\n",
       "      <td>[Pat chicken dry with paper towels, season all...</td>\n",
       "      <td>miso-butter-roast-chicken-acorn-squash-panzanella</td>\n",
       "      <td>[1 (3½–4-lb.) whole chicken, 2¾ tsp. kosher sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Crispy Salt and Pepper Potatoes</td>\n",
       "      <td>[Preheat oven to 400°F and line a rimmed bakin...</td>\n",
       "      <td>crispy-salt-and-pepper-potatoes-dan-kluger</td>\n",
       "      <td>[2 large egg whites, 1 pound new potatoes (abo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Thanksgiving Mac and Cheese</td>\n",
       "      <td>[Place a rack in middle of oven; preheat to 40...</td>\n",
       "      <td>thanksgiving-mac-and-cheese-erick-williams</td>\n",
       "      <td>[1 cup evaporated milk, 1 cup whole milk, 1 ts...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Italian Sausage and Bread Stuffing</td>\n",
       "      <td>[Preheat oven to 350°F with rack in middle. Ge...</td>\n",
       "      <td>italian-sausage-and-bread-stuffing-240559</td>\n",
       "      <td>[1 (¾- to 1-pound) round Italian loaf, cut int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Newton's Law</td>\n",
       "      <td>[Stir together brown sugar and hot water in a ...</td>\n",
       "      <td>newtons-law-apple-bourbon-cocktail</td>\n",
       "      <td>[1 teaspoon dark brown sugar, 1 teaspoon hot w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              Title  \\\n",
       "0           0  Miso-Butter Roast Chicken With Acorn Squash Pa...   \n",
       "1           1                    Crispy Salt and Pepper Potatoes   \n",
       "2           2                        Thanksgiving Mac and Cheese   \n",
       "3           3                 Italian Sausage and Bread Stuffing   \n",
       "4           4                                       Newton's Law   \n",
       "\n",
       "                                        Instructions  \\\n",
       "0  [Pat chicken dry with paper towels, season all...   \n",
       "1  [Preheat oven to 400°F and line a rimmed bakin...   \n",
       "2  [Place a rack in middle of oven; preheat to 40...   \n",
       "3  [Preheat oven to 350°F with rack in middle. Ge...   \n",
       "4  [Stir together brown sugar and hot water in a ...   \n",
       "\n",
       "                                          Image_Name  \\\n",
       "0  miso-butter-roast-chicken-acorn-squash-panzanella   \n",
       "1         crispy-salt-and-pepper-potatoes-dan-kluger   \n",
       "2         thanksgiving-mac-and-cheese-erick-williams   \n",
       "3          italian-sausage-and-bread-stuffing-240559   \n",
       "4                 newtons-law-apple-bourbon-cocktail   \n",
       "\n",
       "                                 Cleaned_Ingredients  \n",
       "0  [1 (3½–4-lb.) whole chicken, 2¾ tsp. kosher sa...  \n",
       "1  [2 large egg whites, 1 pound new potatoes (abo...  \n",
       "2  [1 cup evaporated milk, 1 cup whole milk, 1 ts...  \n",
       "3  [1 (¾- to 1-pound) round Italian loaf, cut int...  \n",
       "4  [1 teaspoon dark brown sugar, 1 teaspoon hot w...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "import numpy as np\n",
    "import torch\n",
    "import optuna\n",
    "\n",
    "\n",
    "# Explicitly adding models to the search path\n",
    "models_path = os.path.join(GOOGLE_DRIVE_PATH, models_dir)\n",
    "if models_path not in sys.path:\n",
    "    sys.path.insert(0, models_path)\n",
    "\n",
    "from models import recipe_encoder\n",
    "\n",
    "csv_file = os.path.join(GOOGLE_DRIVE_PATH,csv_path)\n",
    "df = pd.read_csv(csv_file, converters={\"Cleaned_Ingredients\": literal_eval, \"Instructions\": literal_eval})\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zhh--PCsDH3b"
   },
   "source": [
    "Concatenate the batches of preprocessed images into 1 tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4136,
     "status": "ok",
     "timestamp": 1733360757054,
     "user": {
      "displayName": "Jacob Gronlund",
      "userId": "00200772917564897839"
     },
     "user_tz": 480
    },
    "id": "Wi-yY_TlDHPn",
    "outputId": "1d9ce4a1-df50-4a25-ce6f-24be3bbac290"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25734/3557820744.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  image_tensors, image_labels = torch.load(pt_filepath)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded batch_6.pt\n",
      "Loaded batch_7.pt\n",
      "Loaded batch_0.pt\n",
      "Loaded batch_11.pt\n",
      "Loaded batch_10.pt\n",
      "Number of images: 5000\n",
      "Number of labels: 5000\n"
     ]
    }
   ],
   "source": [
    "pt_files = os.listdir(os.path.join(GOOGLE_DRIVE_PATH,tensors_dir))\n",
    "all_image_tensors = []\n",
    "all_image_labels = []\n",
    "\n",
    "# Load and combine all .pt files\n",
    "for pt_file in pt_files[:5]:\n",
    "    pt_filepath = os.path.join(GOOGLE_DRIVE_PATH,tensors_dir,pt_file)\n",
    "    image_tensors, image_labels = torch.load(pt_filepath)\n",
    "    all_image_tensors.append(image_tensors)\n",
    "    all_image_labels.extend(image_labels)\n",
    "    print(f\"Loaded {pt_file}\")\n",
    "\n",
    "# Concatenate tensors\n",
    "all_image_tensors = torch.cat(all_image_tensors)\n",
    "print(f\"Number of images: {all_image_tensors.size(0)}\")\n",
    "print(f\"Number of labels: {len(all_image_labels)}\")\n",
    "assert all_image_tensors.size(0) == len(all_image_labels), \"Mismatch between images and labels!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xPDFYvqaJv5w"
   },
   "source": [
    "Reorganize dataframe to be in the same order as the Image Tensors using the image_label as the matching key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 337,
     "status": "ok",
     "timestamp": 1733360757386,
     "user": {
      "displayName": "Jacob Gronlund",
      "userId": "00200772917564897839"
     },
     "user_tz": 480
    },
    "id": "rtFcFs4-Ji7b",
    "outputId": "f8beaaf9-4e17-4804-edcf-1b18fcbd7173"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lemon-rhubarb-chicken-237100', 'maple-soy-barbecue-grilled-chicken', 'little-gem-wedge-salad-with-tahini-ranch', 'lemon-balm-honeysuckle-366697', 'nectarine-and-peach-salad-with-pecans-blue-cheese-and-lavender-syrup', 'old-fashioned-fruitcake-cookies-350832', 'kona-swizzle-394668', 'lemon-souffles-with-boysenberries-241606', 'lemony-green-beans-and-peas-368550', 'miso-cured-black-cod-with-chilled-cucumbers-56389995']\n",
      "1      crispy-salt-and-pepper-potatoes-dan-kluger\n",
      "3       italian-sausage-and-bread-stuffing-240559\n",
      "4              newtons-law-apple-bourbon-cocktail\n",
      "5            warm-comfort-tequila-chamomile-toddy\n",
      "7               turmeric-hot-toddy-claire-sprouse\n",
      "10       hot-pimento-cheese-dip-polina-chesnakova\n",
      "12             butternut-squash-apple-soup-365210\n",
      "13                     caesar-salad-roast-chicken\n",
      "14    chicken-and-rice-with-leeks-and-salsa-verde\n",
      "17                   caramelized-plantain-parfait\n",
      "Name: Image_Name, dtype: object\n",
      "(13496, 5)\n",
      "(4969, 5) 5000\n",
      "Number of filtered tensors: 4969\n",
      "Number of filtered labels: 4969\n",
      "Number of rows in filtered_df: 4969\n",
      "0                         lemon-rhubarb-chicken-237100\n",
      "1                   maple-soy-barbecue-grilled-chicken\n",
      "2             little-gem-wedge-salad-with-tahini-ranch\n",
      "3                        lemon-balm-honeysuckle-366697\n",
      "4    nectarine-and-peach-salad-with-pecans-blue-che...\n",
      "5               old-fashioned-fruitcake-cookies-350832\n",
      "6                                  kona-swizzle-394668\n",
      "7             lemon-souffles-with-boysenberries-241606\n",
      "8                   lemony-green-beans-and-peas-368550\n",
      "9    miso-cured-black-cod-with-chilled-cucumbers-56...\n",
      "Name: Image_Name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "##Reset order of dataframe to match the image labels orders\n",
    "all_image_labels_cleaned = [label.split(\".\")[0] for label in all_image_labels] #remove the .png and .jgp\n",
    "print(all_image_labels_cleaned[:10]) #print to see if at the end the df matches\n",
    "\n",
    "filtered_df = df[df[\"Image_Name\"].isin(all_image_labels_cleaned)] #filter the df to only have values from the images\n",
    "print(filtered_df[\"Image_Name\"][:10])\n",
    "print(df.shape)\n",
    "print(filtered_df.shape, len(all_image_labels_cleaned))\n",
    "\n",
    "valid_labels = set(filtered_df['Image_Name'])\n",
    "\n",
    "# Filter labels and tensors\n",
    "filtered_labels_and_tensors = [\n",
    "    (tensor, label) for tensor, label in zip(all_image_tensors, all_image_labels_cleaned) if label in valid_labels\n",
    "]\n",
    "\n",
    "# Unpack the filtered data\n",
    "filtered_tensors, filtered_labels = zip(*filtered_labels_and_tensors)\n",
    "\n",
    "# Convert back to tensors\n",
    "filtered_tensors = torch.stack(filtered_tensors)\n",
    "filtered_labels = list(filtered_labels)\n",
    "\n",
    "# Verify alignment\n",
    "print(f\"Number of filtered tensors: {len(filtered_tensors)}\")\n",
    "print(f\"Number of filtered labels: {len(filtered_labels)}\")\n",
    "print(f\"Number of rows in filtered_df: {len(filtered_df)}\")\n",
    "\n",
    "# Finally reorganize the df to be in the same order as the image tensors\n",
    "filtered_df = filtered_df.set_index(\"Image_Name\").loc[filtered_labels].reset_index()\n",
    "print(filtered_df[\"Image_Name\"][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 276
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1733360757387,
     "user": {
      "displayName": "Jacob Gronlund",
      "userId": "00200772917564897839"
     },
     "user_tz": 480
    },
    "id": "GeAOZnJ6A5mR",
    "outputId": "7618adce-cc40-4bed-9a8b-cf7f366bdaed"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_Name</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Title</th>\n",
       "      <th>Instructions</th>\n",
       "      <th>Cleaned_Ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lemon-rhubarb-chicken-237100</td>\n",
       "      <td>11165</td>\n",
       "      <td>Lemon-Rhubarb Chicken</td>\n",
       "      <td>[Heat 2 tablespoons olive oil in heavy large s...</td>\n",
       "      <td>[5 tablespoons olive oil, divided, 2 tablespoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>maple-soy-barbecue-grilled-chicken</td>\n",
       "      <td>57</td>\n",
       "      <td>Maple Barbecue Grilled Chicken</td>\n",
       "      <td>[Heat olive oil in a small saucepan over mediu...</td>\n",
       "      <td>[2 Tbsp. extra-virgin olive oil, 3 garlic clov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>little-gem-wedge-salad-with-tahini-ranch</td>\n",
       "      <td>1300</td>\n",
       "      <td>Little Gem Wedge Salad with Tahini Ranch</td>\n",
       "      <td>[Whisk garlic, yogurt, tahini, lemon juice, an...</td>\n",
       "      <td>[1 small garlic clove, finely grated, 1 cup pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lemon-balm-honeysuckle-366697</td>\n",
       "      <td>6946</td>\n",
       "      <td>Lemon Balm Honeysuckle</td>\n",
       "      <td>[Stir honey and 6 tablespoons hot water in a l...</td>\n",
       "      <td>[6 tablespoons honey, 2 cups lemon vodka or wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nectarine-and-peach-salad-with-pecans-blue-che...</td>\n",
       "      <td>1924</td>\n",
       "      <td>Nectarines and Peaches with Lavender Syrup</td>\n",
       "      <td>[Preheat oven to 350°F. Toast pecans on a rimm...</td>\n",
       "      <td>[1/2 cup pecans, 3 tablespoons honey, 2 tables...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Image_Name  Unnamed: 0  \\\n",
       "0                       lemon-rhubarb-chicken-237100       11165   \n",
       "1                 maple-soy-barbecue-grilled-chicken          57   \n",
       "2           little-gem-wedge-salad-with-tahini-ranch        1300   \n",
       "3                      lemon-balm-honeysuckle-366697        6946   \n",
       "4  nectarine-and-peach-salad-with-pecans-blue-che...        1924   \n",
       "\n",
       "                                        Title  \\\n",
       "0                       Lemon-Rhubarb Chicken   \n",
       "1              Maple Barbecue Grilled Chicken   \n",
       "2    Little Gem Wedge Salad with Tahini Ranch   \n",
       "3                      Lemon Balm Honeysuckle   \n",
       "4  Nectarines and Peaches with Lavender Syrup   \n",
       "\n",
       "                                        Instructions  \\\n",
       "0  [Heat 2 tablespoons olive oil in heavy large s...   \n",
       "1  [Heat olive oil in a small saucepan over mediu...   \n",
       "2  [Whisk garlic, yogurt, tahini, lemon juice, an...   \n",
       "3  [Stir honey and 6 tablespoons hot water in a l...   \n",
       "4  [Preheat oven to 350°F. Toast pecans on a rimm...   \n",
       "\n",
       "                                 Cleaned_Ingredients  \n",
       "0  [5 tablespoons olive oil, divided, 2 tablespoo...  \n",
       "1  [2 Tbsp. extra-virgin olive oil, 3 garlic clov...  \n",
       "2  [1 small garlic clove, finely grated, 1 cup pl...  \n",
       "3  [6 tablespoons honey, 2 cups lemon vodka or wh...  \n",
       "4  [1/2 cup pecans, 3 tablespoons honey, 2 tables...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mFbLiKRFJxmj"
   },
   "source": [
    "Reformat Ingredients, Recipes, and Image titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XgK81ynndVtG"
   },
   "source": [
    "Tokenize Recipes, Ingredients, and Image Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35793,
     "status": "ok",
     "timestamp": 1733360793175,
     "user": {
      "displayName": "Jacob Gronlund",
      "userId": "00200772917564897839"
     },
     "user_tz": 480
    },
    "id": "wyHgDU2OmUO0",
    "outputId": "4487ffb3-fd35-47d0-cc02-e64cc0867cd7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chelsea/anaconda3/envs/tfood_torch/lib/python3.12/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[[101, 1019, 7251, 24667, 3619, 9724, 3514, 1010, 4055, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1016, 7251, 24667, 3619, 4606, 1015, 1013, 1018, 2452, 24881, 4618, 12868, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1018, 1015, 1013, 1016, 10268, 18740, 2094, 1054, 6979, 8237, 2497, 1010, 4055, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1015, 7251, 24667, 2078, 4840, 14380, 10869, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1016, 5572, 13102, 27174, 22126, 24665, 4383, 14380, 14113, 1010, 4055, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1015, 1013, 1018, 2452, 1006, 1015, 1013, 1016, 6293, 1007, 12136, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1015, 1013, 1016, 2452, 15920, 4895, 28084, 3709, 4840, 14580, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1017, 1013, 1018, 2452, 5699, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1020, 7251, 24667, 3619, 17951, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1018, 10268, 2659, 1011, 5474, 7975, 22953, 2705, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1015, 2878, 2732, 2019, 5562, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1015, 3016, 7053, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1020, 5923, 3238, 7975, 7388, 23672, 2007, 3096, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "[[101, 3684, 1016, 7251, 24667, 3619, 9724, 3514, 1999, 3082, 2312, 8066, 3388, 2058, 5396, 1011, 2152, 3684, 1012, 5587, 1016, 7251, 24667, 3619, 24881, 4618, 12868, 1998, 1016, 10268, 1054, 6979, 8237, 2497, 1025, 7842, 10421, 2127, 3730, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2055, 1019, 2781, 1012, 16130, 1999, 14380, 10869, 1998, 1015, 5572, 13102, 7828, 14380, 14113, 1012, 2161, 2007, 5474, 1998, 11565, 1012, 4658, 1054, 6979, 8237, 2497, 28652, 1012, 14899, 12136, 1999, 3082, 2312, 12901, 9739, 2058, 2659, 3684, 1012, 5587, 2538, 1013, 1016, 10268, 1054, 6979, 8237, 2497, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1015, 1013, 1018, 2452, 4618, 12868, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1998, 14580, 1025, 7842, 10421, 2127, 3730, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2055, 2184, 2781, 1012, 3623, 3684, 2000, 2152, 1012, 5587, 5699, 1998, 17951, 1025, 26077, 1015, 3371, 1012, 5587, 22953, 2705, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2732, 2019, 5562, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1998, 3016, 7053, 1012, 21934, 5017, 2058, 2659, 3684, 2127, 8150, 2003, 4359, 2000, 1016, 10268, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2055, 1015, 3178, 1012, 10178, 12901, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 5860, 29154, 26778, 1999, 10178, 2121, 1012, 16130, 1015, 1013, 1017, 2452, 1054, 6979, 8237, 2497, 28652, 2046, 12901, 1012, 2079, 3805, 28652, 1998, 12901, 2064, 2022, 2081, 1016, 2420, 3805, 1012, 3104, 2169, 10329, 1998, 10720, 1012, 2128, 9028, 2213, 12901, 2077, 2478, 1012, 3653, 20192, 2102, 17428, 2000, 23285, 7737, 2546, 1012, 2478, 12206, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 3584, 3096, 2013, 5771, 1997, 7975, 12682, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 5716, 4979, 1012, 2173, 2055, 1016, 7251, 24667, 3619, 1054, 6979, 8237, 2497, 28652, 1999, 4979, 1012, 11867, 6657, 19099, 7975, 2007, 5474, 1998, 11565, 1012, 3684, 1017, 7251, 24667, 3619, 3514, 1999, 2312, 8066, 3388, 2058, 5396, 1011, 2152, 3684, 1012, 2551, 1999, 1016, 14108, 2229, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 5587, 7975, 12682, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 3096, 2217, 2091, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2000, 8066, 3388, 1025, 5660, 2127, 2829, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2055, 1021, 2781, 1012, 4651, 7975, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 3096, 2217, 2091, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2000, 25043, 2075, 6090, 1012, 25043, 7975, 2184, 2781, 1025, 19021, 2618, 2007, 6090, 10869, 2015, 1012, 25043, 2127, 12984, 2083, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2055, 2184, 2781, 2936, 1012, 4651, 7975, 2000, 28005, 2121, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 11867, 6657, 19099, 2007, 1015, 5572, 13102, 7828, 14380, 14113, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1998, 3710, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 4458, 12901, 4077, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "total_max = 128\n",
    "# Initialize the tokenizer\n",
    "tokenizer_recipes = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def tokenize_nested_list(nested_list, max_length=128):\n",
    "    \"\"\"\n",
    "    Tokenizes a nested list of strings (list of ingredients per recipe).\n",
    "    Each inner list is tokenized into a list of token IDs.\n",
    "    \"\"\"\n",
    "    tokenized_list = []\n",
    "    for sublist in nested_list:\n",
    "        # Join the inner list into a string\n",
    "        # text = \" \".join(sublist)\n",
    "        text = str(sublist)\n",
    "        # Tokenize the string\n",
    "        tokens = tokenizer_recipes(\n",
    "            text,\n",
    "            max_length=max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        # Append tokenized input_ids to the result list\n",
    "        tokenized_list.append(tokens[\"input_ids\"].squeeze(0).tolist())\n",
    "    return tokenized_list\n",
    "\n",
    "filtered_df['Title_List'] = df['Title'].apply(lambda x: [x])\n",
    "filtered_df['tokenized_ingredients'] = filtered_df['Cleaned_Ingredients'].apply(lambda x: tokenize_nested_list(x, total_max))\n",
    "filtered_df['tokenized_instructions'] = filtered_df['Instructions'].apply(lambda x: tokenize_nested_list(x, total_max))\n",
    "filtered_df['tokenized_titles'] = filtered_df['Title_List'].apply(lambda x: tokenize_nested_list(x, total_max))\n",
    "\n",
    "\n",
    "# # Store tokenized data in a dictionary for your DataLoader\n",
    "# filtered_df[\"tokenized_titles\"] = title_tokens[\"input_ids\"]\n",
    "# filtered_df[\"title_attention_mask\"] = title_tokens[\"attention_mask\"]\n",
    "\n",
    "# filtered_df[\"tokenized_ingredients\"] = ingredients_tokens[\"input_ids\"]\n",
    "# filtered_df[\"ingredients_attention_mask\"] = ingredients_tokens[\"attention_mask\"]\n",
    "\n",
    "# filtered_df[\"tokenized_instructions\"] = instructions_tokens[\"input_ids\"]\n",
    "# filtered_df[\"instructions_attention_mask\"] = instructions_tokens[\"attention_mask\"]\n",
    "print(len(filtered_df[\"tokenized_titles\"][0]))\n",
    "print(filtered_df[\"tokenized_ingredients\"][0])\n",
    "print(filtered_df[\"tokenized_instructions\"][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1733360793176,
     "user": {
      "displayName": "Jacob Gronlund",
      "userId": "00200772917564897839"
     },
     "user_tz": 480
    },
    "id": "52oSgq6k7Ldn",
    "outputId": "3286a7d5-3516-49e1-db8b-238a603fd33f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51 22 1\n",
      "51\n",
      "[[101, 1015, 9044, 2598, 4977, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1017, 1013, 1018, 2452, 4840, 7852, 13675, 25438, 2015, 1006, 2013, 1016, 25609, 2422, 2878, 1011, 10500, 7852, 1007, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1015, 1013, 1016, 2452, 22126, 24881, 29259, 2401, 2030, 2060, 4086, 24444, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1015, 1013, 1017, 2452, 24665, 4383, 25659, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1015, 1013, 1018, 2452, 1015, 1003, 6501, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1015, 1013, 1018, 2452, 20856, 12901, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1015, 2312, 8288, 1010, 8217, 7854, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1015, 20548, 18856, 21818, 1010, 22126, 24881, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1015, 7251, 24667, 2078, 20218, 12901, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1017, 1013, 1018, 5572, 13102, 7828, 5474, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1015, 1013, 1018, 5572, 13102, 7828, 20229, 2598, 2304, 11565, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1016, 7251, 24667, 3619, 17710, 10649, 6279, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1016, 5572, 13102, 27174, 2422, 2829, 5699, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1015, 5572, 13102, 7828, 3756, 23187, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "def pad_or_truncate_nested(sublist, target_length, max_length, pad_token=0):\n",
    "        \"\"\"\n",
    "            Pad or truncate the outer list of a nested list to match the target_length.\n",
    "            Each inner list remains untouched.\n",
    "        \"\"\"\n",
    "        # Pad with [pad_token] or truncate the outer list\n",
    "        if len(sublist) < target_length:\n",
    "            sublist.extend([[pad_token]* max_length] * (target_length - len(sublist)))\n",
    "        else:\n",
    "            sublist = sublist[:target_length]\n",
    "        return sublist\n",
    "\n",
    "max_length_ing = filtered_df['tokenized_ingredients'].apply(len).max()\n",
    "max_length_inst = filtered_df['tokenized_instructions'].apply(len).max()//4\n",
    "max_length_title = filtered_df['tokenized_titles'].apply(len).max()\n",
    "filtered_df['tokenized_ingredients'] = filtered_df['tokenized_ingredients'].apply(\n",
    "    lambda ing: pad_or_truncate_nested(ing, max_length_ing,total_max))\n",
    "\n",
    "filtered_df['tokenized_instructions'] = filtered_df['tokenized_instructions'].apply(\n",
    "    lambda inst: pad_or_truncate_nested(inst, max_length_inst, total_max))\n",
    "# new_token_ing = [pad_or_truncate_nested(ing, max_length_title) for ing in tokenized_ingredients] #titles were all list length of 1\n",
    "max_length_ing = filtered_df['tokenized_ingredients'].apply(len).max()\n",
    "max_length_inst = filtered_df['tokenized_instructions'].apply(len).max()\n",
    "max_length_title = filtered_df['tokenized_titles'].apply(len).max()\n",
    "print(max_length_ing, max_length_inst, max_length_title)\n",
    "print(len(filtered_df['tokenized_ingredients'][5]))\n",
    "print(filtered_df['tokenized_ingredients'][100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1jZ1lhBw2DnV"
   },
   "source": [
    "Tokenize the Image Labels for the Image Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "w8EKVqNG2CGJ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chelsea/anaconda3/envs/tfood_torch/lib/python3.12/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import CLIPModel\n",
    "model_name = \"openai/clip-vit-base-patch16\"\n",
    "clip_model = CLIPModel.from_pretrained(model_name)\n",
    "tokenizer_images = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "tokenized_labels = tokenizer_images(\n",
    "    filtered_labels,\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=tokenizer_images.model_max_length,\n",
    "    return_tensors=\"pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1733360798470,
     "user": {
      "displayName": "Jacob Gronlund",
      "userId": "00200772917564897839"
     },
     "user_tz": 480
    },
    "id": "ilxU3rfNFI8j",
    "outputId": "ff756ea5-34c3-481a-ec39-4ae4038ac240"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "%reload_ext autoreload\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "cOR7eQshjPKL"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class RecipeDecoder(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size):\n",
    "        super(RecipeDecoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc_out = nn.Linear(hidden_dim, vocab_size)\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "    def forward(self, input_tokens):\n",
    "        embedded = self.embedding(input_tokens)\n",
    "        outputs, hidden_state = self.rnn(embedded, hidden_state)\n",
    "        predictions = self.fc_out(outputs)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "N_UNJWI5GMCg"
   },
   "outputs": [],
   "source": [
    "def calc_recall(top, image_features, recipe_embeddings, image_labels):\n",
    "  true_pos = 0\n",
    "  false_neg = 0\n",
    "  tmp_batches = image_features.shape[0]\n",
    "  print(image_features.shape, recipe_embeddings.shape)\n",
    "  for i in range(tmp_batches):\n",
    "    cosine_similarity = torch.nn.CosineSimilarity(dim=1)\n",
    "    similarities = cosine_similarity(image_features[i, :].unsqueeze(0), recipe_embeddings)\n",
    "    print(similarities)\n",
    "    #top = amount of top results to retrieve\n",
    "    top_results = top\n",
    "    top_k_values, top_k_indices = torch.topk(similarities, top_results, largest=True)\n",
    "    print(top_k_values, top_k_indices)\n",
    "    top_images = [(filtered_df['Image_Name'][i]) for i in top_k_indices]\n",
    "    if image_labels[i] in [image[0] for image in top_images]:\n",
    "      true_pos += 1\n",
    "    else:\n",
    "      false_neg += 1\n",
    "\n",
    "  return (true_pos / tmp_batches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nc71r5-Uyouz"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch\n",
    "from models.image_2_recipe import Image2Recipe\n",
    "from models.image_encoder import Image_Encoder\n",
    "from models.recipe_encoder import RecipeEncoder\n",
    "from models.MMR import MMR\n",
    "from models.MMR import MMR_losses\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "class Data_Loading(Dataset):\n",
    "    \"\"\"\n",
    "    Class to combine the Images, Labels, Recipes together to be used in combination when inputted into Model\n",
    "    \"\"\"\n",
    "    def __init__(self, tokenized_ingredients, tokenized_instructions, tokenized_titles, image_tensors, image_labels):\n",
    "        self.ingredients = torch.tensor(tokenized_ingredients, dtype=torch.int16)\n",
    "        self.instructions = torch.tensor(tokenized_instructions, dtype=torch.int16)\n",
    "        self.titles = torch.tensor(tokenized_titles, dtype=torch.int16)\n",
    "        self.images = image_tensors\n",
    "        self.image_labels = image_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"ingredients\": self.ingredients[idx],\n",
    "            \"instructions\": self.instructions[idx],\n",
    "            \"titles\": self.titles[idx],\n",
    "            \"images\": self.images[idx],\n",
    "            \"image_labels\": self.image_labels[idx]\n",
    "            # \"tokenized_labels\": {\n",
    "            #     \"input_ids\": self.tokenized_labels['input_ids'][idx].to(dtype=torch.long),\n",
    "            #     \"attention_mask\": self.tokenized_labels['attention_mask'][idx].to(dtype=torch.uint8)\n",
    "            # }\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "class Trainer(object):\n",
    "    \"\"\"\n",
    "    Class designed to run ViT (train, evaluate, plot)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Initialize ViT\n",
    "        \"\"\"\n",
    "        self.epochs = kwargs['epochs']\n",
    "        self.optimizer_name = kwargs['optimizer']\n",
    "        self.device = kwargs['device']\n",
    "        self.batch_size = kwargs['batch_size']\n",
    "        self.lr = kwargs['learning_rate']\n",
    "\n",
    "        self.tokenized_ingredients = kwargs['ingredient_tokens']\n",
    "        self.tokenized_instructions = kwargs['instruction_tokens']\n",
    "        self.tokenized_title = kwargs['title_tokens']\n",
    "        self.image_tensor = kwargs['image_tensors']\n",
    "        self.image_labels = kwargs['image_labels']\n",
    "        self.clip_model = kwargs['clip_model']\n",
    "        self.vocab_size = kwargs['vocab_size']\n",
    "        self.max_len = kwargs['max_len']\n",
    "        self.instance_weight = kwargs['instance_weight']\n",
    "        self.sem_weight = kwargs['sem_weight']\n",
    "        self.itm_weight = kwargs['itm_weight']\n",
    "        self.best_model_parameters = kwargs['best_model_parameters_path']\n",
    "        # self.margin = kwargs['margin']\n",
    "        self.initial_margin = kwargs['initial_margin']\n",
    "        self.margin_step = kwargs['margin_step']\n",
    "        self.max_margin = kwargs['max_margin']\n",
    "        self.topk = kwargs['topk']\n",
    "        # Pending variable margin calc\n",
    "        # self.loss_calcs = MMR_losses(margin=1.0, instance_weight=self.instance_weight, sem_weight=self.sem_weight, itm_weight=self.itm_weight)\n",
    "        self.loss_calcs = MMR_losses(instance_weight=self.instance_weight, sem_weight=self.sem_weight, itm_weight=self.itm_weight)\n",
    "        # num_classes = len(set(self.image_labels['input_ids']))\n",
    "        num_classes = len(set(self.image_labels))\n",
    "        # print(num_classes)\n",
    "\n",
    "\n",
    "        self.image_encoder = Image_Encoder(self.device, self.clip_model, num_classes).to(self.device)\n",
    "        self.recipe_encoder = RecipeEncoder(self.device, self.vocab_size, self.max_len).to(self.device)\n",
    "        self.mmr = MMR(hidden_dim=self.image_encoder.clip_model.config.projection_dim).to(self.device)\n",
    "        # self.recipe_decoder = RecipeDecoder(512,512,self.vocab_size).to(self.device)\n",
    "        # MMR varaibles: num_heads=num_heads, ITEM_lyrs=ITEM_lyrs, MTD_lyrs=MTD_lyrs, projection_dim=projection_dim\n",
    "        self.model = Image2Recipe(self.image_encoder, self.recipe_encoder, self.mmr).to(self.device)\n",
    "\n",
    "\n",
    "        ##DO we want to tune each of these learning rates for each model?\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        # self.optimizer2 = torch.optim.Adam(self.recipe_decoder.parameters(), lr=self.lr)\n",
    "        # self.optimizer = torch.optim.AdamW([\n",
    "        #     {\"params\": self.model.image_encoder.parent_model.parameters(), \"lr\": 1e-6},\n",
    "        #     {\"params\": self.model.recipe_encoder.parameters(), \"lr\": 1e-5},\n",
    "        #     {\"params\": self.model.image_encoder.fc1.parameters(), \"lr\": 1e-5},\n",
    "        #     {\"params\": self.model.recipe_encoder.ll_e.parameters(), \"lr\": 1e-5},\n",
    "        # ])\n",
    "\n",
    "\n",
    "        #Combine Images, Recipes, Instructions in training and eval datasets\n",
    "        self.data_total = Data_Loading(\n",
    "            self.tokenized_ingredients,\n",
    "            self.tokenized_instructions,\n",
    "            self.tokenized_title,\n",
    "            self.image_tensor,\n",
    "            self.image_labels\n",
    "        )\n",
    "        training_perc = .9\n",
    "        train_size = int(training_perc * len(self.data_total))\n",
    "        eval_size = len(self.data_total) - train_size\n",
    "        train_dataset, eval_dataset = random_split(self.data_total, [train_size, eval_size])\n",
    "        self.dataloader = {}\n",
    "        self.dataloader['train'] = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True, drop_last=True)\n",
    "        self.dataloader['eval'] = DataLoader(eval_dataset, batch_size=self.batch_size, shuffle=False, drop_last=True)\n",
    "\n",
    "        #Lists to fill up during training and plotted later for learning curves\n",
    "        self.train_loss_list = []\n",
    "        self.eval_loss_list = []\n",
    "        self.eval_acc_list = []\n",
    "        self.eval_acc_list = []\n",
    "        self.best_score = 0\n",
    "        self.best_loss = 1000\n",
    "        print(\"finished initializing\")\n",
    "\n",
    "        # self.CELoss = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "        # self.decoder_lambda = kwargs['decoder_lambda']\n",
    "\n",
    "    def train(self, trial=None):\n",
    "        \"\"\"\n",
    "        Train ViT, image encoder, recipe encoder, MMR\n",
    "        \"\"\"\n",
    "        # Set initial margin\n",
    "        self.margin = self.initial_margin\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "\n",
    "            for phase in ['train', 'eval']:\n",
    "                total_loss = 0\n",
    "                total_accuracy = 0\n",
    "                total_eval_loss = 0\n",
    "                if phase == 'train':\n",
    "                    self.model.train()\n",
    "                else:\n",
    "                    self.model.eval()\n",
    "                for i, batch_data in enumerate(tqdm(self.dataloader[phase],position=0, leave=True)):\n",
    "                    #Looping through batches of training data then eval data each epoch\n",
    "                    #TODO: Add how the recipe, instructions, and titles will be tokenized\n",
    "                    ingredients, instructions, titles, images, image_labels = (\n",
    "                        batch_data['ingredients'].to(self.device),\n",
    "                        batch_data['instructions'].to(self.device),\n",
    "                        batch_data['titles'].to(self.device),\n",
    "                        batch_data['images'].to(self.device),\n",
    "                        batch_data['image_labels']\n",
    "                    )\n",
    "\n",
    "                    recipe_enc_src = [titles, ingredients, instructions]\n",
    "                    self.optimizer.zero_grad()\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        output = self.model(images, image_labels, recipe_enc_src)\n",
    "                        ##Combine the Recipe Encoder Losses and Image Encoder Losses based on TFOOD\n",
    "                        mmr_logits = output[\"mmr_logits\"]\n",
    "                        image_logits = output[\"image_logits\"]\n",
    "                        image_embeddings_proj = output[\"image_embeddings_proj\"]\n",
    "                        recipe_embeddings_proj = output[\"recipe_embeddings_proj\"]\n",
    "                        # image_embeddings = output[\"image_embeddings\"]\n",
    "                        # recipe_embeddings = output[\"recipe_embeddings\"]\n",
    "\n",
    "                        # #Train the Recipe Decoder so it can output a generative (Title, Ingredient, Instructions)\n",
    "                        # title_logits = self.recipe_decoder(image_embeddings, titles)\n",
    "                        # ingredients_logits = self.recipe_decoder(image_embeddings, ingredients)\n",
    "                        # instructions_logits = self.recipe_decoder(image_embeddings, instructions)\n",
    "\n",
    "                        # #Compute Reconstruction Loss\n",
    "                        # title_loss = self.CELoss(title_logits.transpose(1, 2), titles)\n",
    "                        # ingredients_loss = self.CELoss(ingredients_logits.transpose(1, 2), ingredients)\n",
    "                        # instructions_loss = self.CELoss(instructions_logits.transpose(1, 2), instructions)\n",
    "                        # decoder_loss = (title_loss + ingredients_loss + instructions_loss) *self.decoder_lambda\n",
    "\n",
    "                        loss = self.loss_calcs.total_loss(image_logits, image_embeddings_proj,\n",
    "                                                          recipe_embeddings_proj, mmr_logits, self.margin)\n",
    "\n",
    "                        # print(f'training loss for step: {loss.item()}')\n",
    "                        # recall_score = calc_recall(self.topk, image_embeddings_proj, recipe_embeddings_proj, image_labels)\n",
    "                        # print(recall_score)\n",
    "                        loss.backward()\n",
    "                        self.optimizer.step()\n",
    "                        # self.optimizer2.step() #decoder optimizer\n",
    "                        total_loss += loss.item()\n",
    "\n",
    "\n",
    "\n",
    "                    else: ##Eval mode\n",
    "                        with torch.no_grad():\n",
    "                            output = self.model(images, image_labels, recipe_enc_src)\n",
    "                            mmr_logits = output[\"mmr_logits\"]\n",
    "                            image_logits = output[\"image_logits\"]\n",
    "                            image_embeddings_proj = output[\"image_embeddings_proj\"]\n",
    "                            recipe_embeddings_proj = output[\"recipe_embeddings_proj\"]\n",
    "                            # #Train the Recipe Decoder so it can output a generative (Title, Ingredient, Instructions)\n",
    "                            # title_logits = self.recipe_decoder(image_embeddings, titles)\n",
    "                            # ingredients_logits = self.recipe_decoder(image_embeddings, ingredients)\n",
    "                            # instructions_logits = self.recipe_decoder(image_embeddings, instructions)\n",
    "\n",
    "                            # #Compute Reconstruction Loss\n",
    "                            # title_loss = self.CELoss(title_logits.transpose(1, 2), titles)\n",
    "                            # ingredients_loss = self.CELoss(ingredients_logits.transpose(1, 2), ingredients)\n",
    "                            # instructions_loss = self.CELoss(instructions_logits.transpose(1, 2), instructions)\n",
    "                            # decoder_loss = (title_loss + ingredients_loss + instructions_loss) * self.decoder_lambda\n",
    "                            eval_loss = self.loss_calcs.total_eval_loss(image_logits, image_embeddings_proj,\n",
    "                                                                   recipe_embeddings_proj)# + decoder_loss\n",
    "                            total_eval_loss += eval_loss.item()\n",
    "                            # print(f'eval loss for step: {loss}')\n",
    "                            # self.eval_loss_list.append(loss.item())\n",
    "\n",
    "                            # recall_score = calc_recall(self.topk, image_embeddings_proj, recipe_embeddings_proj, image_labels)\n",
    "                            # print(recall_score)\n",
    " \n",
    "                    \n",
    "                    # del unused_tensor\n",
    "                    torch.cuda.empty_cache() #clear cache after each batch\n",
    "                    # print(i)\n",
    "                    # print(output)\n",
    "                    \n",
    "\n",
    "                # Update loss margin\n",
    "                if self.margin <= (self.max_margin - self.margin_step):\n",
    "                    self.margin += self.margin_step\n",
    "                else:\n",
    "                    self.margin = self.max_margin\n",
    "                if phase == \"train\":\n",
    "                    # Avg loss over the epoch\n",
    "                    epoch_loss = total_loss / len(self.dataloader[phase])\n",
    "                    print(f\"{phase}: Epoch {epoch+1}, Loss: {epoch_loss}\")\n",
    "                    self.train_loss_list.append(epoch_loss)\n",
    "\n",
    "                    # Check if optuna's training trial should continue\n",
    "                    if trial:\n",
    "                        trial.report(epoch_loss, epoch)\n",
    "                        if trial.should_prune():\n",
    "                            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "                else:\n",
    "                  self.eval_loss_list.append(total_eval_loss/len(self.dataloader[phase]))\n",
    "                  if total_eval_loss < self.best_loss:\n",
    "                    self.best_loss = total_eval_loss\n",
    "                    torch.save(self.model.state_dict(), self.best_model_parameters)\n",
    "                    print(\"Saving best model\")\n",
    "                    # torch.save()\n",
    "\n",
    "        return epoch_loss # Epoch loss from final epoch\n",
    "\n",
    "    ##Waiting on training code to finish\n",
    "    def plot_learning_loss_curves(self, name=None, title=None):\n",
    "        \"\"\"\n",
    "        Plot accuracy and loss curves for training and eval accuracy/loss lists (item/epoch)\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(self.train_loss_list, label='Training Loss')\n",
    "        plt.plot(self.eval_loss_list, label='Validation Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        if not title:\n",
    "            title = 'Loss Curve'\n",
    "\n",
    "        plt.title(title)\n",
    "        plt.legend()\n",
    "        if not name:\n",
    "            name = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "        plt.savefig(f'{name}.png')\n",
    "        plt.show()\n",
    "\n",
    "        # plt.figure(figsize=(10, 5))\n",
    "        # plt.plot(self.train_acc_list, label='Training Accuracy')\n",
    "        # plt.plot(self.eval_acc_list, label='Validation Accuracy')\n",
    "        # plt.xlabel('Epoch')\n",
    "        # plt.ylabel('Accuracy')\n",
    "        # plt.title('Accuracy Curve')\n",
    "        # plt.legend()\n",
    "        # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "oCpaIgTRca8s"
   },
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1733360799007,
     "user": {
      "displayName": "Jacob Gronlund",
      "userId": "00200772917564897839"
     },
     "user_tz": 480
    },
    "id": "jXA0oBF70OCN",
    "outputId": "e7e2f752-662a-4f27-c5f7-987a948ed62a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "128\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "print(len(filtered_df['tokenized_ingredients'][1][0]))\n",
    "print(len(filtered_df['tokenized_instructions'][1][0]))\n",
    "print(len(filtered_df['tokenized_titles'][1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1733360799007,
     "user": {
      "displayName": "Jacob Gronlund",
      "userId": "00200772917564897839"
     },
     "user_tz": 480
    },
    "id": "4lOE7ew3Czjr",
    "outputId": "de763ca3-9a69-4081-9c58-122f686eb8c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-07 20:14:32,097] Using an existing study with name 'recipe_checkpoint_12-07_13-46' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished initializing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1becdb72b0c54817a9358ed839043387",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/447 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: Epoch 1, Loss: 3.697382930674542\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e114e80611074c77a8b7254d4566e19f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval: Epoch 1, Loss: 4.581587207560637\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a862fd973d8405c96cf586ee7b4a487",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/447 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: Epoch 2, Loss: 1.9639479636612622\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2df5b392fa645d586761f699a31a338",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval: Epoch 2, Loss: 4.5816516097711055\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00c403f9233b49da9361f0256ce81306",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/447 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: Epoch 3, Loss: 1.9639098220223548\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f481c47c5d74e22a3f5dc4cbf0ae687",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval: Epoch 3, Loss: 4.581624264619788\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40016e4e5a204fc583816476918bcf3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/447 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: Epoch 4, Loss: 1.9641580608333784\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0828432fea0d471780717bbe3569209e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval: Epoch 4, Loss: 4.581528284111801\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83128e19b7744bf89dc04fad1ee149f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/447 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: Epoch 5, Loss: 1.963999792500097\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa8b39ef7d7741309a2b705627b71bb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval: Epoch 5, Loss: 4.581521871138592\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d4ec3f39db1400fb4e71cf1d2b1a7ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/447 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: Epoch 6, Loss: 1.9636545370622502\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08f7c2bd349e4b8e9f9790109c3d06e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval: Epoch 6, Loss: 4.581516878945487\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0b997eba7cc476d843edacff77a4e0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/447 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: Epoch 7, Loss: 1.9637171872776893\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2de153364b84e67b45c9296b02d818a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval: Epoch 7, Loss: 4.581540020144716\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "328af2b1802e4479adeda0cd52685d8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/447 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: Epoch 8, Loss: 1.9637832446919725\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a75d11cfefe4115983a5525596a3d93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval: Epoch 8, Loss: 4.581588258548659\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c49ea594e73f4b7a8e59b8972b8dd5a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/447 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: Epoch 9, Loss: 1.9639321282939357\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81a2cd610ab04c92bab848aeb34ec19d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval: Epoch 9, Loss: 4.581564514004454\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8fa50645bc64afb9782f7eade14b437",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/447 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: Epoch 10, Loss: 1.96386827878504\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "939d1cc6046f49d79126e18fdf930a85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval: Epoch 10, Loss: 4.581511040123141\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-07 21:44:21,575] Trial 4 finished with value: 4.581511040123141 and parameters: {'lr': 0.0004727889979620643, 'inst_w': 0.014815001400323503, 'sem_w': 0.00013637080452503608, 'itm_w': 0.7203677321377528, 'lambda': 0.00033301918854032115}. Best is trial 1 with value: 2.031923396246774.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished initializing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbf4844a77264b6db97a5ca5b4e4fe57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/447 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: Epoch 1, Loss: 4.121718512285476\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5512299a01847e7ae044c56cbc70696",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval: Epoch 1, Loss: 4.323220486543616\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1ee5a2df7a347ea9a140c1ae49e31f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/447 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: Epoch 2, Loss: 4.10383513789849\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06bfc315121a421cb3d52870821a1ecf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval: Epoch 2, Loss: 4.323039210572535\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38fabecdb66c4aeab3c01c184dd07de2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/447 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: Epoch 3, Loss: 4.1047012288565075\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d0985f7a96140d980c821a8faac2c1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval: Epoch 3, Loss: 4.322468027776601\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13b7aae1bfa641d3b39e5b4a1512aea4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/447 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: Epoch 4, Loss: 4.1064783188053955\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44da2c7dab834be6bb7f7c1ccfdb334e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval: Epoch 4, Loss: 4.3226790817416445\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3176dc82f5b74415a38340026b237302",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/447 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: Epoch 5, Loss: 4.107824661587709\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84cd3505928049cc9df50684f81bc456",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval: Epoch 5, Loss: 4.321288877603959\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f2b825681de4b608c5e10b8cdbf9b0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/447 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: Epoch 6, Loss: 4.109717814981004\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2576eb5384514b8a9678068b1cb7ff98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval: Epoch 6, Loss: 4.321279301935313\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5327f74983ff4d56abb71546d299156b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/447 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: Epoch 7, Loss: 4.112062138465694\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c837b9983f53406cb7cb604131599116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval: Epoch 7, Loss: 4.322114584397297\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "279d98321b1d47ae93858a94c16023c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/447 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: Epoch 8, Loss: 4.113644151879637\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47eff0330b954185a0e1f071ce527642",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval: Epoch 8, Loss: 4.320825294572479\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f2a6d786cce4fd19976f77a80eb3a91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/447 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: Epoch 9, Loss: 4.115731776960744\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d05a7f4756549558c549f75278bd024",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/49 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval: Epoch 9, Loss: 4.321747468442333\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc3998f941dd4636b70a95e4aaa6578a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/447 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W 2024-12-07 23:07:33,807] Trial 5 failed with parameters: {'lr': 3.57965635465319e-05, 'inst_w': 0.04645140877198957, 'sem_w': 0.005713286466069595, 'itm_w': 0.00036067073941497234, 'lambda': 0.00010707660928078404} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/chelsea/anaconda3/envs/tfood_torch/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 197, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_25734/1366879358.py\", line 48, in objective\n",
      "    final_loss = image2recipe.train(trial)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/tmp/ipykernel_25734/464826059.py\", line 160, in train\n",
      "    output = self.model(images, image_labels, recipe_enc_src)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chelsea/anaconda3/envs/tfood_torch/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chelsea/anaconda3/envs/tfood_torch/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chelsea/Documents/GATech/DL_group_project/models/image_2_recipe.py\", line 21, in forward\n",
      "    image_logits, image_encodings = self.image_encoder(images, image_labels)\n",
      "                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chelsea/anaconda3/envs/tfood_torch/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chelsea/anaconda3/envs/tfood_torch/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chelsea/Documents/GATech/DL_group_project/models/image_encoder.py\", line 23, in forward\n",
      "    image_encodings = self.clip_model.get_image_features(pixel_values=images)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chelsea/anaconda3/envs/tfood_torch/lib/python3.12/site-packages/transformers/models/clip/modeling_clip.py\", line 1052, in get_image_features\n",
      "    vision_outputs = self.vision_model(\n",
      "                     ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chelsea/anaconda3/envs/tfood_torch/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chelsea/anaconda3/envs/tfood_torch/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chelsea/anaconda3/envs/tfood_torch/lib/python3.12/site-packages/transformers/models/clip/modeling_clip.py\", line 850, in forward\n",
      "    encoder_outputs = self.encoder(\n",
      "                      ^^^^^^^^^^^^^\n",
      "  File \"/home/chelsea/anaconda3/envs/tfood_torch/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chelsea/anaconda3/envs/tfood_torch/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chelsea/anaconda3/envs/tfood_torch/lib/python3.12/site-packages/transformers/models/clip/modeling_clip.py\", line 636, in forward\n",
      "    layer_outputs = encoder_layer(\n",
      "                    ^^^^^^^^^^^^^^\n",
      "  File \"/home/chelsea/anaconda3/envs/tfood_torch/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chelsea/anaconda3/envs/tfood_torch/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chelsea/anaconda3/envs/tfood_torch/lib/python3.12/site-packages/transformers/models/clip/modeling_clip.py\", line 388, in forward\n",
      "    hidden_states = self.mlp(hidden_states)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chelsea/anaconda3/envs/tfood_torch/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chelsea/anaconda3/envs/tfood_torch/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chelsea/anaconda3/envs/tfood_torch/lib/python3.12/site-packages/transformers/models/clip/modeling_clip.py\", line 344, in forward\n",
      "    hidden_states = self.activation_fn(hidden_states)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chelsea/anaconda3/envs/tfood_torch/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1553, in _wrapped_call_impl\n",
      "    return self._call_impl(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chelsea/anaconda3/envs/tfood_torch/lib/python3.12/site-packages/torch/nn/modules/module.py\", line 1562, in _call_impl\n",
      "    return forward_call(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/chelsea/anaconda3/envs/tfood_torch/lib/python3.12/site-packages/transformers/activations.py\", line 96, in forward\n",
      "    return input * torch.sigmoid(1.702 * input)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "[W 2024-12-07 23:07:33,809] Trial 5 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 63\u001b[0m\n\u001b[1;32m     55\u001b[0m storage_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqlite:///\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m.db\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(study_name)\n\u001b[1;32m     56\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(study_name\u001b[38;5;241m=\u001b[39mstudy_name,\n\u001b[1;32m     57\u001b[0m                             storage\u001b[38;5;241m=\u001b[39mstorage_name,\n\u001b[1;32m     58\u001b[0m                             direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminimize\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     61\u001b[0m                             load_if_exists\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m \u001b[38;5;66;03m# allows for study to be resumed\u001b[39;00m\n\u001b[1;32m     62\u001b[0m                             )\n\u001b[0;32m---> 63\u001b[0m study\u001b[38;5;241m.\u001b[39moptimize(objective, n_trials\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m     65\u001b[0m pruned_trials \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mget_trials(states\u001b[38;5;241m=\u001b[39m(optuna\u001b[38;5;241m.\u001b[39mtrial\u001b[38;5;241m.\u001b[39mTrialState\u001b[38;5;241m.\u001b[39mPRUNED,))\n\u001b[1;32m     66\u001b[0m complete_trials \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mget_trials(states\u001b[38;5;241m=\u001b[39m(optuna\u001b[38;5;241m.\u001b[39mtrial\u001b[38;5;241m.\u001b[39mTrialState\u001b[38;5;241m.\u001b[39mCOMPLETE,))\n",
      "File \u001b[0;32m~/anaconda3/envs/tfood_torch/lib/python3.12/site-packages/optuna/study/study.py:475\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[0;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    375\u001b[0m     func: ObjectiveFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    382\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    383\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    384\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[1;32m    385\u001b[0m \n\u001b[1;32m    386\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[1;32m    474\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 475\u001b[0m     _optimize(\n\u001b[1;32m    476\u001b[0m         study\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    477\u001b[0m         func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m    478\u001b[0m         n_trials\u001b[38;5;241m=\u001b[39mn_trials,\n\u001b[1;32m    479\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[1;32m    480\u001b[0m         n_jobs\u001b[38;5;241m=\u001b[39mn_jobs,\n\u001b[1;32m    481\u001b[0m         catch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(catch) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(catch, Iterable) \u001b[38;5;28;01melse\u001b[39;00m (catch,),\n\u001b[1;32m    482\u001b[0m         callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[1;32m    483\u001b[0m         gc_after_trial\u001b[38;5;241m=\u001b[39mgc_after_trial,\n\u001b[1;32m    484\u001b[0m         show_progress_bar\u001b[38;5;241m=\u001b[39mshow_progress_bar,\n\u001b[1;32m    485\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/tfood_torch/lib/python3.12/site-packages/optuna/study/_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[0;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m---> 63\u001b[0m         _optimize_sequential(\n\u001b[1;32m     64\u001b[0m             study,\n\u001b[1;32m     65\u001b[0m             func,\n\u001b[1;32m     66\u001b[0m             n_trials,\n\u001b[1;32m     67\u001b[0m             timeout,\n\u001b[1;32m     68\u001b[0m             catch,\n\u001b[1;32m     69\u001b[0m             callbacks,\n\u001b[1;32m     70\u001b[0m             gc_after_trial,\n\u001b[1;32m     71\u001b[0m             reseed_sampler_rng\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     72\u001b[0m             time_start\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     73\u001b[0m             progress_bar\u001b[38;5;241m=\u001b[39mprogress_bar,\n\u001b[1;32m     74\u001b[0m         )\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/tfood_torch/lib/python3.12/site-packages/optuna/study/_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[0;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[1;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 160\u001b[0m     frozen_trial \u001b[38;5;241m=\u001b[39m _run_trial(study, func, catch)\n\u001b[1;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[1;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[1;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[0;32m~/anaconda3/envs/tfood_torch/lib/python3.12/site-packages/optuna/study/_optimize.py:248\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    241\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    243\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    244\u001b[0m     frozen_trial\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    246\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[1;32m    247\u001b[0m ):\n\u001b[0;32m--> 248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
      "File \u001b[0;32m~/anaconda3/envs/tfood_torch/lib/python3.12/site-packages/optuna/study/_optimize.py:197\u001b[0m, in \u001b[0;36m_run_trial\u001b[0;34m(study, func, catch)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 197\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m func(trial)\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[0;32mIn[19], line 48\u001b[0m, in \u001b[0;36mobjective\u001b[0;34m(trial)\u001b[0m\n\u001b[1;32m     45\u001b[0m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mempty_cache() \u001b[38;5;66;03m#clear cache before each run\u001b[39;00m\n\u001b[1;32m     47\u001b[0m image2recipe \u001b[38;5;241m=\u001b[39m Trainer(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 48\u001b[0m final_loss \u001b[38;5;241m=\u001b[39m image2recipe\u001b[38;5;241m.\u001b[39mtrain(trial)\n\u001b[1;32m     49\u001b[0m image2recipe\u001b[38;5;241m.\u001b[39mplot_learning_loss_curves(name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstudy_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m__Trial_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrial\u001b[38;5;241m.\u001b[39mnumber\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     50\u001b[0m                                        title\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrial \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrial\u001b[38;5;241m.\u001b[39mnumber\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Loss Curves\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m final_loss\n",
      "Cell \u001b[0;32mIn[13], line 160\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, trial)\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m    159\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m phase \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 160\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(images, image_labels, recipe_enc_src)\n\u001b[1;32m    161\u001b[0m     \u001b[38;5;66;03m##Combine the Recipe Encoder Losses and Image Encoder Losses based on TFOOD\u001b[39;00m\n\u001b[1;32m    162\u001b[0m     mmr_logits \u001b[38;5;241m=\u001b[39m output[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmmr_logits\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/tfood_torch/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tfood_torch/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GATech/DL_group_project/models/image_2_recipe.py:21\u001b[0m, in \u001b[0;36mImage2Recipe.forward\u001b[0;34m(self, images, image_labels, src)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, images, image_labels, src):\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;66;03m# Get encodings from both encoders\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m     image_logits, image_encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_encoder(images, image_labels)\n\u001b[1;32m     22\u001b[0m     t_R, e_R \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecipe_encoder(src)\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m####Not completely sure what should be happening below but I know they should probably be in same dimension\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfood_torch/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tfood_torch/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GATech/DL_group_project/models/image_encoder.py:23\u001b[0m, in \u001b[0;36mImage_Encoder.forward\u001b[0;34m(self, images, image_labels)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, images, image_labels):\n\u001b[0;32m---> 23\u001b[0m     image_encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclip_model\u001b[38;5;241m.\u001b[39mget_image_features(pixel_values\u001b[38;5;241m=\u001b[39mimages)\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# image_encodings = F.normalize(dim=-1, keepdim=True)\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     image_encodings \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mnormalize(image_encodings, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/tfood_torch/lib/python3.12/site-packages/transformers/models/clip/modeling_clip.py:1052\u001b[0m, in \u001b[0;36mCLIPModel.get_image_features\u001b[0;34m(self, pixel_values, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1047\u001b[0m output_hidden_states \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1048\u001b[0m     output_hidden_states \u001b[38;5;28;01mif\u001b[39;00m output_hidden_states \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39moutput_hidden_states\n\u001b[1;32m   1049\u001b[0m )\n\u001b[1;32m   1050\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1052\u001b[0m vision_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvision_model(\n\u001b[1;32m   1053\u001b[0m     pixel_values\u001b[38;5;241m=\u001b[39mpixel_values,\n\u001b[1;32m   1054\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m   1055\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[1;32m   1056\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m   1057\u001b[0m )\n\u001b[1;32m   1059\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m vision_outputs[\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# pooled_output\u001b[39;00m\n\u001b[1;32m   1060\u001b[0m image_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvisual_projection(pooled_output)\n",
      "File \u001b[0;32m~/anaconda3/envs/tfood_torch/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tfood_torch/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfood_torch/lib/python3.12/site-packages/transformers/models/clip/modeling_clip.py:850\u001b[0m, in \u001b[0;36mCLIPVisionTransformer.forward\u001b[0;34m(self, pixel_values, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    847\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(pixel_values)\n\u001b[1;32m    848\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_layrnorm(hidden_states)\n\u001b[0;32m--> 850\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[1;32m    851\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39mhidden_states,\n\u001b[1;32m    852\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m    853\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[1;32m    854\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m    855\u001b[0m )\n\u001b[1;32m    857\u001b[0m last_hidden_state \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    858\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m last_hidden_state[:, \u001b[38;5;241m0\u001b[39m, :]\n",
      "File \u001b[0;32m~/anaconda3/envs/tfood_torch/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tfood_torch/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfood_torch/lib/python3.12/site-packages/transformers/models/clip/modeling_clip.py:636\u001b[0m, in \u001b[0;36mCLIPEncoder.forward\u001b[0;34m(self, inputs_embeds, attention_mask, causal_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    628\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    629\u001b[0m         encoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    630\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    633\u001b[0m         output_attentions,\n\u001b[1;32m    634\u001b[0m     )\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 636\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m encoder_layer(\n\u001b[1;32m    637\u001b[0m         hidden_states,\n\u001b[1;32m    638\u001b[0m         attention_mask,\n\u001b[1;32m    639\u001b[0m         causal_attention_mask,\n\u001b[1;32m    640\u001b[0m         output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m    641\u001b[0m     )\n\u001b[1;32m    643\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    645\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m output_attentions:\n",
      "File \u001b[0;32m~/anaconda3/envs/tfood_torch/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tfood_torch/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfood_torch/lib/python3.12/site-packages/transformers/models/clip/modeling_clip.py:388\u001b[0m, in \u001b[0;36mCLIPEncoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, causal_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    386\u001b[0m residual \u001b[38;5;241m=\u001b[39m hidden_states\n\u001b[1;32m    387\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayer_norm2(hidden_states)\n\u001b[0;32m--> 388\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(hidden_states)\n\u001b[1;32m    389\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    391\u001b[0m outputs \u001b[38;5;241m=\u001b[39m (hidden_states,)\n",
      "File \u001b[0;32m~/anaconda3/envs/tfood_torch/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tfood_torch/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfood_torch/lib/python3.12/site-packages/transformers/models/clip/modeling_clip.py:344\u001b[0m, in \u001b[0;36mCLIPMLP.forward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    342\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m    343\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc1(hidden_states)\n\u001b[0;32m--> 344\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactivation_fn(hidden_states)\n\u001b[1;32m    345\u001b[0m     hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfc2(hidden_states)\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m hidden_states\n",
      "File \u001b[0;32m~/anaconda3/envs/tfood_torch/lib/python3.12/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/tfood_torch/lib/python3.12/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfood_torch/lib/python3.12/site-packages/transformers/activations.py:96\u001b[0m, in \u001b[0;36mQuickGELUActivation.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m*\u001b[39m torch\u001b[38;5;241m.\u001b[39msigmoid(\u001b[38;5;241m1.702\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;28minput\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##  Optuna\n",
    "\n",
    "# name of the resuting optuna file\n",
    "# current_time = datetime.now().strftime('%m-%d_%H-%M')\n",
    "# study_name=f\"recipe_checkpoint_{current_time}\"\n",
    "study_name= \"recipe_checkpoint_12-07_13-46\"\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "vocab_size = tokenizer_recipes.vocab_size\n",
    "param_path = os.path.join(GOOGLE_DRIVE_PATH, \"models/best_model_jake.pth\")\n",
    "recipe_embeddings_path  = os.path.join(GOOGLE_DRIVE_PATH, \"models/recipe_embeddings.pth\")\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    kwargs = {\n",
    "        'epochs': 10,\n",
    "        'ingredient_tokens': filtered_df['tokenized_ingredients'].to_list(),\n",
    "        'instruction_tokens': filtered_df['tokenized_instructions'].to_list(),\n",
    "        'title_tokens': filtered_df['tokenized_titles'].to_list(),\n",
    "        'image_tensors': filtered_tensors,\n",
    "        'image_labels': filtered_df['Image_Name'],\n",
    "        'device': device,\n",
    "        'vocab_size': vocab_size,\n",
    "        'max_len': total_max,\n",
    "        'clip_model': clip_model,\n",
    "        'optimizer': 'adam',\n",
    "        'learning_rate': trial.suggest_float('lr', 1e-6, 1e-2, log=True),\n",
    "        'batch_size': 10,\n",
    "        'instance_weight': trial.suggest_float('inst_w', 1e-5, 1, log=True),\n",
    "        'sem_weight': trial.suggest_float('sem_w', 1e-5, 1, log=True),\n",
    "        'itm_weight': trial.suggest_float('itm_w', 1e-5, 1, log=True),\n",
    "        'initial_margin': 0.05,\n",
    "        'margin_step': 0.005,\n",
    "        'max_margin':0.3,\n",
    "        'best_model_parameters_path': param_path,\n",
    "        'decoder_lambda': trial.suggest_float('lambda', 1e-5, 1, log=True),\n",
    "        'topk': 10\n",
    "        # 'max_lengths': {\n",
    "        #     'ingredient_tokens': max_length_ing,\n",
    "        #     'instruction_tokens': max_length_inst,\n",
    "        #     'title_tokens': max_length_title\n",
    "        # }\n",
    "    }\n",
    "    torch.cuda.empty_cache() #clear cache before each run\n",
    "\n",
    "    image2recipe = Trainer(**kwargs)\n",
    "    final_loss = image2recipe.train(trial)\n",
    "    image2recipe.plot_learning_loss_curves(name=f\"{study_name}__Trial_{trial.number}\",\n",
    "                                           title=f\"Trial {trial.number} Loss Curves\")\n",
    "    return final_loss\n",
    "\n",
    "# Create a study object and optimize the objective function.\n",
    "# A new file will be saved called {study_name}.db containing the study\n",
    "storage_name = \"sqlite:///{}.db\".format(study_name)\n",
    "study = optuna.create_study(study_name=study_name,\n",
    "                            storage=storage_name,\n",
    "                            direction='minimize',\n",
    "                            sampler=optuna.samplers.RandomSampler(),\n",
    "                            pruner=optuna.pruners.MedianPruner(),\n",
    "                            load_if_exists=True # allows for study to be resumed\n",
    "                            )\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "pruned_trials = study.get_trials(states=(optuna.trial.TrialState.PRUNED,))\n",
    "complete_trials = study.get_trials(states=(optuna.trial.TrialState.COMPLETE,))\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IQDow2_yJQO1"
   },
   "source": [
    "Now that the model is trained, use it to guess images recipes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z-U9830iF48G"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  #same size as training\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) #same norm as training\n",
    "])\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    return transform(image).unsqueeze(0) #add batch dim of 1 at 0 indice\n",
    "\n",
    "def extract_image_features(image, model, device):\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "      image_features = model.image_encoder(image.to(device))\n",
    "      image_features = torch.nn.functional.normalize(image_features, p=2, dim=-1)\n",
    "  return image_features\n",
    "\n",
    "def load_model(model_path):\n",
    "    image_encoder = Image_Encoder(device, clip_model, num_classes).to(device)\n",
    "    recipe_encoder = RecipeEncoder(device, vocab_size, max_len).to(device)\n",
    "    mmr = MMR(hidden_dim=image_encoder.clip_model.config.projection_dim).to(device)\n",
    "    model = Image2Recipe(image_encoder, recipe_encoder, mmr).to(device)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "image_path = \"insert test image path\"\n",
    "tensor_image = preprocess_image(image_path)\n",
    "image2recipe = load_model(param_path)\n",
    "image_features = extract_image_features(tensor_image, image2recipe.model, device)\n",
    "print(image_features.shape)\n",
    "\n",
    "recipe_embeddings = np.load(recipe_embeddings_path)\n",
    "\n",
    "\n",
    "#Compute cosine similarities\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tfood_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "358a4e5e3b984f279ae03e8d26d43d2b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "36365b4998824614b8bfa84a9e5e86a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_407856979a714799a01c25eec68c93d1",
      "placeholder": "​",
      "style": "IPY_MODEL_a71edb6d334e4eef82c827cbc0817a65",
      "value": "  0%"
     }
    },
    "37d2b668bb2a4230bfedaa925bb70551": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "407856979a714799a01c25eec68c93d1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5428352e9fab4cd3a415bee09d5cc6e9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "946ba10c9b9b4d4b90e317deff7c73ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ab6173676ed54c13a72323956e0fcc08",
      "placeholder": "​",
      "style": "IPY_MODEL_37d2b668bb2a4230bfedaa925bb70551",
      "value": " 0/447 [00:01&lt;?, ?it/s]"
     }
    },
    "a71edb6d334e4eef82c827cbc0817a65": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ab6173676ed54c13a72323956e0fcc08": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bdff5aea515a4f6a88a4aef08c1d0792": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c8d80345b3d04503a0ba492d2e21437f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_36365b4998824614b8bfa84a9e5e86a9",
       "IPY_MODEL_f38e682756534d4bae6e203cdb371697",
       "IPY_MODEL_946ba10c9b9b4d4b90e317deff7c73ab"
      ],
      "layout": "IPY_MODEL_bdff5aea515a4f6a88a4aef08c1d0792"
     }
    },
    "f38e682756534d4bae6e203cdb371697": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5428352e9fab4cd3a415bee09d5cc6e9",
      "max": 447,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_358a4e5e3b984f279ae03e8d26d43d2b",
      "value": 0
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
