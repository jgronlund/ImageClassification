{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PSBW6ryo-H9v"
   },
   "source": [
    "If using google drive please edit this line to connect to drive location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "w6ZQ_d3W-aQq"
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2225,
     "status": "ok",
     "timestamp": 1733360749282,
     "user": {
      "displayName": "Jacob Gronlund",
      "userId": "00200772917564897839"
     },
     "user_tz": 480
    },
    "id": "1YCGTlkW99pN",
    "outputId": "3b5de00c-1a21-4ae3-b1dc-f110855f0831"
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "import os, sys\n",
    "\n",
    "# # Mount the google colab\n",
    "# drive.mount(\"/content/drive/\")\n",
    "# GOOGLE_DRIVE_PATH_POST_MYDRIVE = 'DeepLearning_GroupProject/'\n",
    "# GOOGLE_DRIVE_PATH = os.path.join('/content', 'drive', 'MyDrive', GOOGLE_DRIVE_PATH_POST_MYDRIVE)\n",
    "# !ls {GOOGLE_DRIVE_PATH}\n",
    "# sys.path.append(GOOGLE_DRIVE_PATH)\n",
    "\n",
    "GOOGLE_DRIVE_PATH = '.'\n",
    "\n",
    "\n",
    "# relative paths\n",
    "models_dir = 'models'\n",
    "csv_path = 'Data/updated_data_with_lists.csv'\n",
    "tensors_dir = 'Data/tensor_batch_notaugmented'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "executionInfo": {
     "elapsed": 3645,
     "status": "ok",
     "timestamp": 1733360752925,
     "user": {
      "displayName": "Jacob Gronlund",
      "userId": "00200772917564897839"
     },
     "user_tz": 480
    },
    "id": "sGHSvkJG5fbt",
    "outputId": "441d26a7-d8e7-49a8-8fd9-d00753c22da2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13496\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Title</th>\n",
       "      <th>Instructions</th>\n",
       "      <th>Image_Name</th>\n",
       "      <th>Cleaned_Ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Miso-Butter Roast Chicken With Acorn Squash Pa...</td>\n",
       "      <td>[Pat chicken dry with paper towels, season all...</td>\n",
       "      <td>miso-butter-roast-chicken-acorn-squash-panzanella</td>\n",
       "      <td>[1 (3½–4-lb.) whole chicken, 2¾ tsp. kosher sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Crispy Salt and Pepper Potatoes</td>\n",
       "      <td>[Preheat oven to 400°F and line a rimmed bakin...</td>\n",
       "      <td>crispy-salt-and-pepper-potatoes-dan-kluger</td>\n",
       "      <td>[2 large egg whites, 1 pound new potatoes (abo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Thanksgiving Mac and Cheese</td>\n",
       "      <td>[Place a rack in middle of oven; preheat to 40...</td>\n",
       "      <td>thanksgiving-mac-and-cheese-erick-williams</td>\n",
       "      <td>[1 cup evaporated milk, 1 cup whole milk, 1 ts...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Italian Sausage and Bread Stuffing</td>\n",
       "      <td>[Preheat oven to 350°F with rack in middle. Ge...</td>\n",
       "      <td>italian-sausage-and-bread-stuffing-240559</td>\n",
       "      <td>[1 (¾- to 1-pound) round Italian loaf, cut int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Newton's Law</td>\n",
       "      <td>[Stir together brown sugar and hot water in a ...</td>\n",
       "      <td>newtons-law-apple-bourbon-cocktail</td>\n",
       "      <td>[1 teaspoon dark brown sugar, 1 teaspoon hot w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                              Title  \\\n",
       "0           0  Miso-Butter Roast Chicken With Acorn Squash Pa...   \n",
       "1           1                    Crispy Salt and Pepper Potatoes   \n",
       "2           2                        Thanksgiving Mac and Cheese   \n",
       "3           3                 Italian Sausage and Bread Stuffing   \n",
       "4           4                                       Newton's Law   \n",
       "\n",
       "                                        Instructions  \\\n",
       "0  [Pat chicken dry with paper towels, season all...   \n",
       "1  [Preheat oven to 400°F and line a rimmed bakin...   \n",
       "2  [Place a rack in middle of oven; preheat to 40...   \n",
       "3  [Preheat oven to 350°F with rack in middle. Ge...   \n",
       "4  [Stir together brown sugar and hot water in a ...   \n",
       "\n",
       "                                          Image_Name  \\\n",
       "0  miso-butter-roast-chicken-acorn-squash-panzanella   \n",
       "1         crispy-salt-and-pepper-potatoes-dan-kluger   \n",
       "2         thanksgiving-mac-and-cheese-erick-williams   \n",
       "3          italian-sausage-and-bread-stuffing-240559   \n",
       "4                 newtons-law-apple-bourbon-cocktail   \n",
       "\n",
       "                                 Cleaned_Ingredients  \n",
       "0  [1 (3½–4-lb.) whole chicken, 2¾ tsp. kosher sa...  \n",
       "1  [2 large egg whites, 1 pound new potatoes (abo...  \n",
       "2  [1 cup evaporated milk, 1 cup whole milk, 1 ts...  \n",
       "3  [1 (¾- to 1-pound) round Italian loaf, cut int...  \n",
       "4  [1 teaspoon dark brown sugar, 1 teaspoon hot w...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from ast import literal_eval\n",
    "import numpy as np\n",
    "import torch\n",
    "import optuna\n",
    "\n",
    "\n",
    "# Explicitly adding models to the search path\n",
    "models_path = os.path.join(GOOGLE_DRIVE_PATH, models_dir)\n",
    "if models_path not in sys.path:\n",
    "    sys.path.insert(0, models_path)\n",
    "\n",
    "from models import recipe_encoder\n",
    "\n",
    "csv_file = os.path.join(GOOGLE_DRIVE_PATH,csv_path)\n",
    "df = pd.read_csv(csv_file, converters={\"Cleaned_Ingredients\": literal_eval, \"Instructions\": literal_eval})\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zhh--PCsDH3b"
   },
   "source": [
    "Concatenate the batches of preprocessed images into 1 tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4136,
     "status": "ok",
     "timestamp": 1733360757054,
     "user": {
      "displayName": "Jacob Gronlund",
      "userId": "00200772917564897839"
     },
     "user_tz": 480
    },
    "id": "Wi-yY_TlDHPn",
    "outputId": "1d9ce4a1-df50-4a25-ce6f-24be3bbac290"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded batch_6.pt\n",
      "Loaded batch_7.pt\n",
      "Loaded batch_0.pt\n",
      "Loaded batch_11.pt\n",
      "Loaded batch_10.pt\n",
      "Number of images: 5000\n",
      "Number of labels: 5000\n"
     ]
    }
   ],
   "source": [
    "pt_files = os.listdir(os.path.join(GOOGLE_DRIVE_PATH,tensors_dir))\n",
    "all_image_tensors = []\n",
    "all_image_labels = []\n",
    "\n",
    "# Load and combine all .pt files\n",
    "for pt_file in pt_files[:5]:\n",
    "    pt_filepath = os.path.join(GOOGLE_DRIVE_PATH,tensors_dir,pt_file)\n",
    "    image_tensors, image_labels = torch.load(pt_filepath, weights_only=False)\n",
    "    all_image_tensors.append(image_tensors)\n",
    "    all_image_labels.extend(image_labels)\n",
    "    print(f\"Loaded {pt_file}\")\n",
    "\n",
    "# Concatenate tensors\n",
    "all_image_tensors = torch.cat(all_image_tensors)\n",
    "print(f\"Number of images: {all_image_tensors.size(0)}\")\n",
    "print(f\"Number of labels: {len(all_image_labels)}\")\n",
    "assert all_image_tensors.size(0) == len(all_image_labels), \"Mismatch between images and labels!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xPDFYvqaJv5w"
   },
   "source": [
    "Reorganize dataframe to be in the same order as the Image Tensors using the image_label as the matching key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 337,
     "status": "ok",
     "timestamp": 1733360757386,
     "user": {
      "displayName": "Jacob Gronlund",
      "userId": "00200772917564897839"
     },
     "user_tz": 480
    },
    "id": "rtFcFs4-Ji7b",
    "outputId": "f8beaaf9-4e17-4804-edcf-1b18fcbd7173"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lemon-rhubarb-chicken-237100', 'maple-soy-barbecue-grilled-chicken', 'little-gem-wedge-salad-with-tahini-ranch', 'lemon-balm-honeysuckle-366697', 'nectarine-and-peach-salad-with-pecans-blue-cheese-and-lavender-syrup', 'old-fashioned-fruitcake-cookies-350832', 'kona-swizzle-394668', 'lemon-souffles-with-boysenberries-241606', 'lemony-green-beans-and-peas-368550', 'miso-cured-black-cod-with-chilled-cucumbers-56389995']\n",
      "1      crispy-salt-and-pepper-potatoes-dan-kluger\n",
      "3       italian-sausage-and-bread-stuffing-240559\n",
      "4              newtons-law-apple-bourbon-cocktail\n",
      "5            warm-comfort-tequila-chamomile-toddy\n",
      "7               turmeric-hot-toddy-claire-sprouse\n",
      "10       hot-pimento-cheese-dip-polina-chesnakova\n",
      "12             butternut-squash-apple-soup-365210\n",
      "13                     caesar-salad-roast-chicken\n",
      "14    chicken-and-rice-with-leeks-and-salsa-verde\n",
      "17                   caramelized-plantain-parfait\n",
      "Name: Image_Name, dtype: object\n",
      "(13496, 5)\n",
      "(4969, 5) 5000\n",
      "Number of filtered tensors: 4969\n",
      "Number of filtered labels: 4969\n",
      "Number of rows in filtered_df: 4969\n",
      "0                         lemon-rhubarb-chicken-237100\n",
      "1                   maple-soy-barbecue-grilled-chicken\n",
      "2             little-gem-wedge-salad-with-tahini-ranch\n",
      "3                        lemon-balm-honeysuckle-366697\n",
      "4    nectarine-and-peach-salad-with-pecans-blue-che...\n",
      "5               old-fashioned-fruitcake-cookies-350832\n",
      "6                                  kona-swizzle-394668\n",
      "7             lemon-souffles-with-boysenberries-241606\n",
      "8                   lemony-green-beans-and-peas-368550\n",
      "9    miso-cured-black-cod-with-chilled-cucumbers-56...\n",
      "Name: Image_Name, dtype: object\n"
     ]
    }
   ],
   "source": [
    "##Reset order of dataframe to match the image labels orders\n",
    "all_image_labels_cleaned = [label.split(\".\")[0] for label in all_image_labels] #remove the .png and .jgp\n",
    "print(all_image_labels_cleaned[:10]) #print to see if at the end the df matches\n",
    "\n",
    "filtered_df = df[df[\"Image_Name\"].isin(all_image_labels_cleaned)] #filter the df to only have values from the images\n",
    "print(filtered_df[\"Image_Name\"][:10])\n",
    "print(df.shape)\n",
    "print(filtered_df.shape, len(all_image_labels_cleaned))\n",
    "\n",
    "valid_labels = set(filtered_df['Image_Name'])\n",
    "\n",
    "# Filter labels and tensors\n",
    "filtered_labels_and_tensors = [\n",
    "    (tensor, label) for tensor, label in zip(all_image_tensors, all_image_labels_cleaned) if label in valid_labels\n",
    "]\n",
    "\n",
    "# Unpack the filtered data\n",
    "filtered_tensors, filtered_labels = zip(*filtered_labels_and_tensors)\n",
    "\n",
    "# Convert back to tensors\n",
    "filtered_tensors = torch.stack(filtered_tensors)\n",
    "filtered_labels = list(filtered_labels)\n",
    "\n",
    "# Verify alignment\n",
    "print(f\"Number of filtered tensors: {len(filtered_tensors)}\")\n",
    "print(f\"Number of filtered labels: {len(filtered_labels)}\")\n",
    "print(f\"Number of rows in filtered_df: {len(filtered_df)}\")\n",
    "\n",
    "# Finally reorganize the df to be in the same order as the image tensors\n",
    "filtered_df = filtered_df.set_index(\"Image_Name\").loc[filtered_labels].reset_index()\n",
    "print(filtered_df[\"Image_Name\"][:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 276
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1733360757387,
     "user": {
      "displayName": "Jacob Gronlund",
      "userId": "00200772917564897839"
     },
     "user_tz": 480
    },
    "id": "GeAOZnJ6A5mR",
    "outputId": "7618adce-cc40-4bed-9a8b-cf7f366bdaed"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image_Name</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Title</th>\n",
       "      <th>Instructions</th>\n",
       "      <th>Cleaned_Ingredients</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lemon-rhubarb-chicken-237100</td>\n",
       "      <td>11165</td>\n",
       "      <td>Lemon-Rhubarb Chicken</td>\n",
       "      <td>[Heat 2 tablespoons olive oil in heavy large s...</td>\n",
       "      <td>[5 tablespoons olive oil, divided, 2 tablespoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>maple-soy-barbecue-grilled-chicken</td>\n",
       "      <td>57</td>\n",
       "      <td>Maple Barbecue Grilled Chicken</td>\n",
       "      <td>[Heat olive oil in a small saucepan over mediu...</td>\n",
       "      <td>[2 Tbsp. extra-virgin olive oil, 3 garlic clov...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>little-gem-wedge-salad-with-tahini-ranch</td>\n",
       "      <td>1300</td>\n",
       "      <td>Little Gem Wedge Salad with Tahini Ranch</td>\n",
       "      <td>[Whisk garlic, yogurt, tahini, lemon juice, an...</td>\n",
       "      <td>[1 small garlic clove, finely grated, 1 cup pl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lemon-balm-honeysuckle-366697</td>\n",
       "      <td>6946</td>\n",
       "      <td>Lemon Balm Honeysuckle</td>\n",
       "      <td>[Stir honey and 6 tablespoons hot water in a l...</td>\n",
       "      <td>[6 tablespoons honey, 2 cups lemon vodka or wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nectarine-and-peach-salad-with-pecans-blue-che...</td>\n",
       "      <td>1924</td>\n",
       "      <td>Nectarines and Peaches with Lavender Syrup</td>\n",
       "      <td>[Preheat oven to 350°F. Toast pecans on a rimm...</td>\n",
       "      <td>[1/2 cup pecans, 3 tablespoons honey, 2 tables...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Image_Name  Unnamed: 0  \\\n",
       "0                       lemon-rhubarb-chicken-237100       11165   \n",
       "1                 maple-soy-barbecue-grilled-chicken          57   \n",
       "2           little-gem-wedge-salad-with-tahini-ranch        1300   \n",
       "3                      lemon-balm-honeysuckle-366697        6946   \n",
       "4  nectarine-and-peach-salad-with-pecans-blue-che...        1924   \n",
       "\n",
       "                                        Title  \\\n",
       "0                       Lemon-Rhubarb Chicken   \n",
       "1              Maple Barbecue Grilled Chicken   \n",
       "2    Little Gem Wedge Salad with Tahini Ranch   \n",
       "3                      Lemon Balm Honeysuckle   \n",
       "4  Nectarines and Peaches with Lavender Syrup   \n",
       "\n",
       "                                        Instructions  \\\n",
       "0  [Heat 2 tablespoons olive oil in heavy large s...   \n",
       "1  [Heat olive oil in a small saucepan over mediu...   \n",
       "2  [Whisk garlic, yogurt, tahini, lemon juice, an...   \n",
       "3  [Stir honey and 6 tablespoons hot water in a l...   \n",
       "4  [Preheat oven to 350°F. Toast pecans on a rimm...   \n",
       "\n",
       "                                 Cleaned_Ingredients  \n",
       "0  [5 tablespoons olive oil, divided, 2 tablespoo...  \n",
       "1  [2 Tbsp. extra-virgin olive oil, 3 garlic clov...  \n",
       "2  [1 small garlic clove, finely grated, 1 cup pl...  \n",
       "3  [6 tablespoons honey, 2 cups lemon vodka or wh...  \n",
       "4  [1/2 cup pecans, 3 tablespoons honey, 2 tables...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mFbLiKRFJxmj"
   },
   "source": [
    "Reformat Ingredients, Recipes, and Image titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XgK81ynndVtG"
   },
   "source": [
    "Tokenize Recipes, Ingredients, and Image Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 35793,
     "status": "ok",
     "timestamp": 1733360793175,
     "user": {
      "displayName": "Jacob Gronlund",
      "userId": "00200772917564897839"
     },
     "user_tz": 480
    },
    "id": "wyHgDU2OmUO0",
    "outputId": "4487ffb3-fd35-47d0-cc02-e64cc0867cd7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chelsea/anaconda3/envs/tfood_torch/lib/python3.12/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[[101, 1019, 7251, 24667, 3619, 9724, 3514, 1010, 4055, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1016, 7251, 24667, 3619, 4606, 1015, 1013, 1018, 2452, 24881, 4618, 12868, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1018, 1015, 1013, 1016, 10268, 18740, 2094, 1054, 6979, 8237, 2497, 1010, 4055, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1015, 7251, 24667, 2078, 4840, 14380, 10869, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1016, 5572, 13102, 27174, 22126, 24665, 4383, 14380, 14113, 1010, 4055, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1015, 1013, 1018, 2452, 1006, 1015, 1013, 1016, 6293, 1007, 12136, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1015, 1013, 1016, 2452, 15920, 4895, 28084, 3709, 4840, 14580, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1017, 1013, 1018, 2452, 5699, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1020, 7251, 24667, 3619, 17951, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1018, 10268, 2659, 1011, 5474, 7975, 22953, 2705, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1015, 2878, 2732, 2019, 5562, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1015, 3016, 7053, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1020, 5923, 3238, 7975, 7388, 23672, 2007, 3096, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n",
      "[[101, 3684, 1016, 7251, 24667, 3619, 9724, 3514, 1999, 3082, 2312, 8066, 3388, 2058, 5396, 1011, 2152, 3684, 1012, 5587, 1016, 7251, 24667, 3619, 24881, 4618, 12868, 1998, 1016, 10268, 1054, 6979, 8237, 2497, 1025, 7842, 10421, 2127, 3730, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2055, 1019, 2781, 1012, 16130, 1999, 14380, 10869, 1998, 1015, 5572, 13102, 7828, 14380, 14113, 1012, 2161, 2007, 5474, 1998, 11565, 1012, 4658, 1054, 6979, 8237, 2497, 28652, 1012, 14899, 12136, 1999, 3082, 2312, 12901, 9739, 2058, 2659, 3684, 1012, 5587, 2538, 1013, 1016, 10268, 1054, 6979, 8237, 2497, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1015, 1013, 1018, 2452, 4618, 12868, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1998, 14580, 1025, 7842, 10421, 2127, 3730, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2055, 2184, 2781, 1012, 3623, 3684, 2000, 2152, 1012, 5587, 5699, 1998, 17951, 1025, 26077, 1015, 3371, 1012, 5587, 22953, 2705, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2732, 2019, 5562, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1998, 3016, 7053, 1012, 21934, 5017, 2058, 2659, 3684, 2127, 8150, 2003, 4359, 2000, 1016, 10268, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2055, 1015, 3178, 1012, 10178, 12901, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 5860, 29154, 26778, 1999, 10178, 2121, 1012, 16130, 1015, 1013, 1017, 2452, 1054, 6979, 8237, 2497, 28652, 2046, 12901, 1012, 2079, 3805, 28652, 1998, 12901, 2064, 2022, 2081, 1016, 2420, 3805, 1012, 3104, 2169, 10329, 1998, 10720, 1012, 2128, 9028, 2213, 12901, 2077, 2478, 1012, 3653, 20192, 2102, 17428, 2000, 23285, 7737, 2546, 1012, 2478, 12206, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 3584, 3096, 2013, 5771, 1997, 7975, 12682, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 5716, 4979, 1012, 2173, 2055, 1016, 7251, 24667, 3619, 1054, 6979, 8237, 2497, 28652, 1999, 4979, 1012, 11867, 6657, 19099, 7975, 2007, 5474, 1998, 11565, 1012, 3684, 1017, 7251, 24667, 3619, 3514, 1999, 2312, 8066, 3388, 2058, 5396, 1011, 2152, 3684, 1012, 2551, 1999, 1016, 14108, 2229, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 5587, 7975, 12682, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 3096, 2217, 2091, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2000, 8066, 3388, 1025, 5660, 2127, 2829, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2055, 1021, 2781, 1012, 4651, 7975, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 3096, 2217, 2091, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2000, 25043, 2075, 6090, 1012, 25043, 7975, 2184, 2781, 1025, 19021, 2618, 2007, 6090, 10869, 2015, 1012, 25043, 2127, 12984, 2083, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 2055, 2184, 2781, 2936, 1012, 4651, 7975, 2000, 28005, 2121, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 11867, 6657, 19099, 2007, 1015, 5572, 13102, 7828, 14380, 14113, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1998, 3710, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 4458, 12901, 4077, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "total_max = 128\n",
    "# Initialize the tokenizer\n",
    "tokenizer_recipes = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "def tokenize_nested_list(nested_list, max_length=128):\n",
    "    \"\"\"\n",
    "    Tokenizes a nested list of strings (list of ingredients per recipe).\n",
    "    Each inner list is tokenized into a list of token IDs.\n",
    "    \"\"\"\n",
    "    tokenized_list = []\n",
    "    for sublist in nested_list:\n",
    "        # Join the inner list into a string\n",
    "        # text = \" \".join(sublist)\n",
    "        text = str(sublist)\n",
    "        # Tokenize the string\n",
    "        tokens = tokenizer_recipes(\n",
    "            text,\n",
    "            max_length=max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "        # Append tokenized input_ids to the result list\n",
    "        tokenized_list.append(tokens[\"input_ids\"].squeeze(0).tolist())\n",
    "    return tokenized_list\n",
    "\n",
    "filtered_df['Title_List'] = df['Title'].apply(lambda x: [x])\n",
    "filtered_df['tokenized_ingredients'] = filtered_df['Cleaned_Ingredients'].apply(lambda x: tokenize_nested_list(x, total_max))\n",
    "filtered_df['tokenized_instructions'] = filtered_df['Instructions'].apply(lambda x: tokenize_nested_list(x, total_max))\n",
    "filtered_df['tokenized_titles'] = filtered_df['Title_List'].apply(lambda x: tokenize_nested_list(x, total_max))\n",
    "\n",
    "\n",
    "# # Store tokenized data in a dictionary for your DataLoader\n",
    "# filtered_df[\"tokenized_titles\"] = title_tokens[\"input_ids\"]\n",
    "# filtered_df[\"title_attention_mask\"] = title_tokens[\"attention_mask\"]\n",
    "\n",
    "# filtered_df[\"tokenized_ingredients\"] = ingredients_tokens[\"input_ids\"]\n",
    "# filtered_df[\"ingredients_attention_mask\"] = ingredients_tokens[\"attention_mask\"]\n",
    "\n",
    "# filtered_df[\"tokenized_instructions\"] = instructions_tokens[\"input_ids\"]\n",
    "# filtered_df[\"instructions_attention_mask\"] = instructions_tokens[\"attention_mask\"]\n",
    "print(len(filtered_df[\"tokenized_titles\"][0]))\n",
    "print(filtered_df[\"tokenized_ingredients\"][0])\n",
    "print(filtered_df[\"tokenized_instructions\"][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1733360793176,
     "user": {
      "displayName": "Jacob Gronlund",
      "userId": "00200772917564897839"
     },
     "user_tz": 480
    },
    "id": "52oSgq6k7Ldn",
    "outputId": "3286a7d5-3516-49e1-db8b-238a603fd33f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51 22 1\n",
      "51\n",
      "[[101, 1015, 9044, 2598, 4977, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1017, 1013, 1018, 2452, 4840, 7852, 13675, 25438, 2015, 1006, 2013, 1016, 25609, 2422, 2878, 1011, 10500, 7852, 1007, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1015, 1013, 1016, 2452, 22126, 24881, 29259, 2401, 2030, 2060, 4086, 24444, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1015, 1013, 1017, 2452, 24665, 4383, 25659, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1015, 1013, 1018, 2452, 1015, 1003, 6501, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1015, 1013, 1018, 2452, 20856, 12901, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1015, 2312, 8288, 1010, 8217, 7854, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1015, 20548, 18856, 21818, 1010, 22126, 24881, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1015, 7251, 24667, 2078, 20218, 12901, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1017, 1013, 1018, 5572, 13102, 7828, 5474, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1015, 1013, 1018, 5572, 13102, 7828, 20229, 2598, 2304, 11565, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1016, 7251, 24667, 3619, 17710, 10649, 6279, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1016, 5572, 13102, 27174, 2422, 2829, 5699, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1015, 5572, 13102, 7828, 3756, 23187, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]\n"
     ]
    }
   ],
   "source": [
    "def pad_or_truncate_nested(sublist, target_length, max_length, pad_token=0):\n",
    "        \"\"\"\n",
    "            Pad or truncate the outer list of a nested list to match the target_length.\n",
    "            Each inner list remains untouched.\n",
    "        \"\"\"\n",
    "        # Pad with [pad_token] or truncate the outer list\n",
    "        if len(sublist) < target_length:\n",
    "            sublist.extend([[pad_token]* max_length] * (target_length - len(sublist)))\n",
    "        else:\n",
    "            sublist = sublist[:target_length]\n",
    "        return sublist\n",
    "\n",
    "max_length_ing = filtered_df['tokenized_ingredients'].apply(len).max()\n",
    "max_length_inst = filtered_df['tokenized_instructions'].apply(len).max()//4\n",
    "max_length_title = filtered_df['tokenized_titles'].apply(len).max()\n",
    "filtered_df['tokenized_ingredients'] = filtered_df['tokenized_ingredients'].apply(\n",
    "    lambda ing: pad_or_truncate_nested(ing, max_length_ing,total_max))\n",
    "\n",
    "filtered_df['tokenized_instructions'] = filtered_df['tokenized_instructions'].apply(\n",
    "    lambda inst: pad_or_truncate_nested(inst, max_length_inst, total_max))\n",
    "# new_token_ing = [pad_or_truncate_nested(ing, max_length_title) for ing in tokenized_ingredients] #titles were all list length of 1\n",
    "max_length_ing = filtered_df['tokenized_ingredients'].apply(len).max()\n",
    "max_length_inst = filtered_df['tokenized_instructions'].apply(len).max()\n",
    "max_length_title = filtered_df['tokenized_titles'].apply(len).max()\n",
    "print(max_length_ing, max_length_inst, max_length_title)\n",
    "print(len(filtered_df['tokenized_ingredients'][5]))\n",
    "print(filtered_df['tokenized_ingredients'][100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1jZ1lhBw2DnV"
   },
   "source": [
    "Tokenize the Image Labels for the Image Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "w8EKVqNG2CGJ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chelsea/anaconda3/envs/tfood_torch/lib/python3.12/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import CLIPModel\n",
    "model_name = \"openai/clip-vit-base-patch16\"\n",
    "clip_model = CLIPModel.from_pretrained(model_name)\n",
    "tokenizer_images = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "tokenized_labels = tokenizer_images(\n",
    "    filtered_labels,\n",
    "    padding=\"max_length\",\n",
    "    truncation=True,\n",
    "    max_length=tokenizer_images.model_max_length,\n",
    "    return_tensors=\"pt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1733360798470,
     "user": {
      "displayName": "Jacob Gronlund",
      "userId": "00200772917564897839"
     },
     "user_tz": 480
    },
    "id": "ilxU3rfNFI8j",
    "outputId": "ff756ea5-34c3-481a-ec39-4ae4038ac240"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chelsea/anaconda3/envs/tfood_torch/lib/python3.12/site-packages/torch/cuda/__init__.py:128: UserWarning: CUDA initialization: CUDA unknown error - this may be due to an incorrectly set up environment, e.g. changing env variable CUDA_VISIBLE_DEVICES after program start. Setting the available devices to be zero. (Triggered internally at /opt/conda/conda-bld/pytorch_1720538439675/work/c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "%reload_ext autoreload\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "cOR7eQshjPKL"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class RecipeDecoder(nn.Module):\n",
    "    def __init__(self, embedding_dim, hidden_dim, vocab_size):\n",
    "        super(RecipeDecoder, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.rnn = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.fc_out = nn.Linear(hidden_dim, vocab_size)\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "    def forward(self, input_tokens):\n",
    "        embedded = self.embedding(input_tokens)\n",
    "        outputs, hidden_state = self.rnn(embedded, hidden_state)\n",
    "        predictions = self.fc_out(outputs)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "N_UNJWI5GMCg"
   },
   "outputs": [],
   "source": [
    "def calc_recall(top, image_features, recipe_embeddings, image_labels):\n",
    "  true_pos = 0\n",
    "  false_neg = 0\n",
    "  tmp_batches = image_features.shape[0]\n",
    "  print(image_features.shape, recipe_embeddings.shape)\n",
    "  for i in range(tmp_batches):\n",
    "    cosine_similarity = torch.nn.CosineSimilarity(dim=1)\n",
    "    similarities = cosine_similarity(image_features[i, :].unsqueeze(0), recipe_embeddings)\n",
    "    print(similarities)\n",
    "    #top = amount of top results to retrieve\n",
    "    top_results = top\n",
    "    top_k_values, top_k_indices = torch.topk(similarities, top_results, largest=True)\n",
    "    print(top_k_values, top_k_indices)\n",
    "    top_images = [(filtered_df['Image_Name'][i]) for i in top_k_indices]\n",
    "    if image_labels[i] in [image[0] for image in top_images]:\n",
    "      true_pos += 1\n",
    "    else:\n",
    "      false_neg += 1\n",
    "\n",
    "  return (true_pos / tmp_batches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "nc71r5-Uyouz"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torch\n",
    "from models.image_2_recipe import Image2Recipe\n",
    "from models.image_encoder import Image_Encoder\n",
    "from models.recipe_encoder import RecipeEncoder\n",
    "from models.MMR import MMR\n",
    "from models.MMR import MMR_losses\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "class Data_Loading(Dataset):\n",
    "    \"\"\"\n",
    "    Class to combine the Images, Labels, Recipes together to be used in combination when inputted into Model\n",
    "    \"\"\"\n",
    "    def __init__(self, tokenized_ingredients, tokenized_instructions, tokenized_titles, image_tensors, image_labels):\n",
    "        self.ingredients = torch.tensor(tokenized_ingredients, dtype=torch.int16)\n",
    "        self.instructions = torch.tensor(tokenized_instructions, dtype=torch.int16)\n",
    "        self.titles = torch.tensor(tokenized_titles, dtype=torch.int16)\n",
    "        self.images = image_tensors\n",
    "        self.image_labels = image_labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"ingredients\": self.ingredients[idx],\n",
    "            \"instructions\": self.instructions[idx],\n",
    "            \"titles\": self.titles[idx],\n",
    "            \"images\": self.images[idx],\n",
    "            \"image_labels\": self.image_labels[idx]\n",
    "            # \"tokenized_labels\": {\n",
    "            #     \"input_ids\": self.tokenized_labels['input_ids'][idx].to(dtype=torch.long),\n",
    "            #     \"attention_mask\": self.tokenized_labels['attention_mask'][idx].to(dtype=torch.uint8)\n",
    "            # }\n",
    "        }\n",
    "\n",
    "\n",
    "\n",
    "class Trainer(object):\n",
    "    \"\"\"\n",
    "    Class designed to run ViT (train, evaluate, plot)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        \"\"\"\n",
    "        Initialize ViT\n",
    "        \"\"\"\n",
    "        self.epochs = kwargs['epochs']\n",
    "        self.optimizer_name = kwargs['optimizer']\n",
    "        self.device = kwargs['device']\n",
    "        self.batch_size = kwargs['batch_size']\n",
    "        self.lr = kwargs['learning_rate']\n",
    "\n",
    "        self.tokenized_ingredients = kwargs['ingredient_tokens']\n",
    "        self.tokenized_instructions = kwargs['instruction_tokens']\n",
    "        self.tokenized_title = kwargs['title_tokens']\n",
    "        self.image_tensor = kwargs['image_tensors']\n",
    "        self.image_labels = kwargs['image_labels']\n",
    "        self.clip_model = kwargs['clip_model']\n",
    "        self.vocab_size = kwargs['vocab_size']\n",
    "        self.max_len = kwargs['max_len']\n",
    "        self.instance_weight = kwargs['instance_weight']\n",
    "        self.sem_weight = kwargs['sem_weight']\n",
    "        self.itm_weight = kwargs['itm_weight']\n",
    "        self.best_model_parameters = kwargs['best_model_parameters_path']\n",
    "        # self.margin = kwargs['margin']\n",
    "        self.initial_margin = kwargs['initial_margin']\n",
    "        self.margin_step = kwargs['margin_step']\n",
    "        self.max_margin = kwargs['max_margin']\n",
    "        self.topk = kwargs['topk']\n",
    "        # self.patience = kwargs['patience']\n",
    "        self.patience = 5\n",
    "        # Pending variable margin calc\n",
    "        # self.loss_calcs = MMR_losses(margin=1.0, instance_weight=self.instance_weight, sem_weight=self.sem_weight, itm_weight=self.itm_weight)\n",
    "        self.loss_calcs = MMR_losses(instance_weight=self.instance_weight, sem_weight=self.sem_weight, itm_weight=self.itm_weight)\n",
    "        # num_classes = len(set(self.image_labels['input_ids']))\n",
    "        num_classes = len(set(self.image_labels))\n",
    "        # print(num_classes)\n",
    "\n",
    "\n",
    "        self.image_encoder = Image_Encoder(self.device, self.clip_model, num_classes).to(self.device)\n",
    "        self.recipe_encoder = RecipeEncoder(self.device, self.vocab_size, self.max_len).to(self.device)\n",
    "        self.mmr = MMR(hidden_dim=self.image_encoder.clip_model.config.projection_dim).to(self.device)\n",
    "        # self.recipe_decoder = RecipeDecoder(512,512,self.vocab_size).to(self.device)\n",
    "        # MMR varaibles: num_heads=num_heads, ITEM_lyrs=ITEM_lyrs, MTD_lyrs=MTD_lyrs, projection_dim=projection_dim\n",
    "        self.model = Image2Recipe(self.image_encoder, self.recipe_encoder, self.mmr).to(self.device)\n",
    "\n",
    "\n",
    "        ##DO we want to tune each of these learning rates for each model?\n",
    "        self.optimizer = torch.optim.Adam(self.model.parameters(), lr=self.lr)\n",
    "        # self.optimizer2 = torch.optim.Adam(self.recipe_decoder.parameters(), lr=self.lr)\n",
    "        # self.optimizer = torch.optim.AdamW([\n",
    "        #     {\"params\": self.model.image_encoder.parent_model.parameters(), \"lr\": 1e-6},\n",
    "        #     {\"params\": self.model.recipe_encoder.parameters(), \"lr\": 1e-5},\n",
    "        #     {\"params\": self.model.image_encoder.fc1.parameters(), \"lr\": 1e-5},\n",
    "        #     {\"params\": self.model.recipe_encoder.ll_e.parameters(), \"lr\": 1e-5},\n",
    "        # ])\n",
    "\n",
    "\n",
    "        #Combine Images, Recipes, Instructions in training and eval datasets\n",
    "        self.data_total = Data_Loading(\n",
    "            self.tokenized_ingredients,\n",
    "            self.tokenized_instructions,\n",
    "            self.tokenized_title,\n",
    "            self.image_tensor,\n",
    "            self.image_labels\n",
    "        )\n",
    "        training_perc = .9\n",
    "        train_size = int(training_perc * len(self.data_total))\n",
    "        eval_size = len(self.data_total) - train_size\n",
    "        train_dataset, eval_dataset = random_split(self.data_total, [train_size, eval_size])\n",
    "        self.dataloader = {}\n",
    "        self.dataloader['train'] = DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True, drop_last=True)\n",
    "        self.dataloader['eval'] = DataLoader(eval_dataset, batch_size=self.batch_size, shuffle=False, drop_last=True)\n",
    "\n",
    "        #Lists to fill up during training and plotted later for learning curves\n",
    "        self.train_loss_list = []\n",
    "        self.eval_loss_list = []\n",
    "        self.eval_acc_list = []\n",
    "        self.eval_acc_list = []\n",
    "        self.best_score = 0\n",
    "        self.best_loss = 1000\n",
    "        print(\"finished initializing\")\n",
    "\n",
    "        # self.CELoss = nn.CrossEntropyLoss(ignore_index=PAD_IDX)\n",
    "        # self.decoder_lambda = kwargs['decoder_lambda']\n",
    "\n",
    "    def train(self, trial=None):\n",
    "        \"\"\"\n",
    "        Train ViT, image encoder, recipe encoder, MMR\n",
    "        \"\"\"\n",
    "        # Set initial margin\n",
    "        self.margin = self.initial_margin\n",
    "        patience_count = 0\n",
    "\n",
    "        for epoch in range(self.epochs):\n",
    "\n",
    "            for phase in ['train', 'eval']:\n",
    "                total_loss = 0\n",
    "                total_accuracy = 0\n",
    "                total_eval_loss = 0\n",
    "                if phase == 'train':\n",
    "                    self.model.train()\n",
    "                else:\n",
    "                    self.model.eval()\n",
    "                for i, batch_data in enumerate(tqdm(self.dataloader[phase],position=0, leave=True)):\n",
    "                    #Looping through batches of training data then eval data each epoch\n",
    "                    #TODO: Add how the recipe, instructions, and titles will be tokenized\n",
    "                    ingredients, instructions, titles, images, image_labels = (\n",
    "                        batch_data['ingredients'].to(self.device),\n",
    "                        batch_data['instructions'].to(self.device),\n",
    "                        batch_data['titles'].to(self.device),\n",
    "                        batch_data['images'].to(self.device),\n",
    "                        batch_data['image_labels']\n",
    "                    )\n",
    "\n",
    "                    recipe_enc_src = [titles, ingredients, instructions]\n",
    "                    self.optimizer.zero_grad()\n",
    "\n",
    "                    if phase == 'train':\n",
    "                        output = self.model(images, image_labels, recipe_enc_src)\n",
    "                        ##Combine the Recipe Encoder Losses and Image Encoder Losses based on TFOOD\n",
    "                        mmr_logits = output[\"mmr_logits\"]\n",
    "                        image_logits = output[\"image_logits\"]\n",
    "                        image_embeddings_proj = output[\"image_embeddings_proj\"]\n",
    "                        recipe_embeddings_proj = output[\"recipe_embeddings_proj\"]\n",
    "                        # image_embeddings = output[\"image_embeddings\"]\n",
    "                        # recipe_embeddings = output[\"recipe_embeddings\"]\n",
    "\n",
    "                        # #Train the Recipe Decoder so it can output a generative (Title, Ingredient, Instructions)\n",
    "                        # title_logits = self.recipe_decoder(image_embeddings, titles)\n",
    "                        # ingredients_logits = self.recipe_decoder(image_embeddings, ingredients)\n",
    "                        # instructions_logits = self.recipe_decoder(image_embeddings, instructions)\n",
    "\n",
    "                        # #Compute Reconstruction Loss\n",
    "                        # title_loss = self.CELoss(title_logits.transpose(1, 2), titles)\n",
    "                        # ingredients_loss = self.CELoss(ingredients_logits.transpose(1, 2), ingredients)\n",
    "                        # instructions_loss = self.CELoss(instructions_logits.transpose(1, 2), instructions)\n",
    "                        # decoder_loss = (title_loss + ingredients_loss + instructions_loss) *self.decoder_lambda\n",
    "\n",
    "                        loss = self.loss_calcs.total_loss(image_logits, image_embeddings_proj,\n",
    "                                                          recipe_embeddings_proj, mmr_logits, self.margin)\n",
    "\n",
    "                        # print(f'training loss for step: {loss.item()}')\n",
    "                        # recall_score = calc_recall(self.topk, image_embeddings_proj, recipe_embeddings_proj, image_labels)\n",
    "                        # print(recall_score)\n",
    "                        loss.backward()\n",
    "                        self.optimizer.step()\n",
    "                        # self.optimizer2.step() #decoder optimizer\n",
    "                        total_loss += loss.item()\n",
    "\n",
    "\n",
    "\n",
    "                    else: ##Eval mode\n",
    "                        with torch.no_grad():\n",
    "                            output = self.model(images, image_labels, recipe_enc_src)\n",
    "                            mmr_logits = output[\"mmr_logits\"]\n",
    "                            image_logits = output[\"image_logits\"]\n",
    "                            image_embeddings_proj = output[\"image_embeddings_proj\"]\n",
    "                            recipe_embeddings_proj = output[\"recipe_embeddings_proj\"]\n",
    "                            # #Train the Recipe Decoder so it can output a generative (Title, Ingredient, Instructions)\n",
    "                            # title_logits = self.recipe_decoder(image_embeddings, titles)\n",
    "                            # ingredients_logits = self.recipe_decoder(image_embeddings, ingredients)\n",
    "                            # instructions_logits = self.recipe_decoder(image_embeddings, instructions)\n",
    "\n",
    "                            # #Compute Reconstruction Loss\n",
    "                            # title_loss = self.CELoss(title_logits.transpose(1, 2), titles)\n",
    "                            # ingredients_loss = self.CELoss(ingredients_logits.transpose(1, 2), ingredients)\n",
    "                            # instructions_loss = self.CELoss(instructions_logits.transpose(1, 2), instructions)\n",
    "                            # decoder_loss = (title_loss + ingredients_loss + instructions_loss) * self.decoder_lambda\n",
    "                            eval_loss = self.loss_calcs.total_eval_loss(image_logits, image_embeddings_proj,\n",
    "                                                                   recipe_embeddings_proj)# + decoder_loss\n",
    "                            total_eval_loss += eval_loss.item()\n",
    "                            # print(f'eval loss for step: {loss}')\n",
    "                            # self.eval_loss_list.append(loss.item())\n",
    "\n",
    "                            # recall_score = calc_recall(self.topk, image_embeddings_proj, recipe_embeddings_proj, image_labels)\n",
    "                            # print(recall_score)\n",
    " \n",
    "                    \n",
    "                    # del unused_tensor\n",
    "                    torch.cuda.empty_cache() #clear cache after each batch\n",
    "                    # print(i)\n",
    "                    # print(output)\n",
    "                    \n",
    "\n",
    "                # Update loss margin\n",
    "                if self.margin <= (self.max_margin - self.margin_step):\n",
    "                    self.margin += self.margin_step\n",
    "                else:\n",
    "                    self.margin = self.max_margin\n",
    "                if phase == \"train\":\n",
    "                    # Avg loss over the epoch\n",
    "                    epoch_loss = total_loss / len(self.dataloader[phase])\n",
    "                    print(f\"{phase}: Epoch {epoch+1}, Loss: {epoch_loss}\")\n",
    "                    self.train_loss_list.append(epoch_loss)\n",
    "\n",
    "                    # Check if optuna's training trial should continue\n",
    "                    if trial:\n",
    "                        trial.report(epoch_loss, epoch)\n",
    "                        if trial.should_prune():\n",
    "                            raise optuna.exceptions.TrialPruned()\n",
    "\n",
    "                else:\n",
    "                    epoch_eval_loss = total_eval_loss/len(self.dataloader[phase])\n",
    "                    self.eval_loss_list.append(epoch_eval_loss)\n",
    "                    print(f\"{phase}: Epoch {epoch+1}, Loss: {epoch_eval_loss}\")\n",
    "\n",
    "                    if total_eval_loss < self.best_loss:\n",
    "                        patience_count = 0\n",
    "                        self.best_loss = total_eval_loss\n",
    "                        torch.save(self.model.state_dict(), self.best_model_parameters)\n",
    "                        print(\"Saving best model\")\n",
    "                        # torch.save()\n",
    "                    else:\n",
    "                        patience_count += 1\n",
    "                        if patience_count >= self.patience:\n",
    "                            print(\"Early stopping\")\n",
    "                            break\n",
    "\n",
    "        return epoch_loss # Epoch loss from final epoch\n",
    "\n",
    "    ##Waiting on training code to finish\n",
    "    def plot_learning_loss_curves(self, name=None, title=None):\n",
    "        \"\"\"\n",
    "        Plot accuracy and loss curves for training and eval accuracy/loss lists (item/epoch)\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(self.train_loss_list, label='Training Loss')\n",
    "        plt.plot(self.eval_loss_list, label='Validation Loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        if not title:\n",
    "            title = 'Loss Curve'\n",
    "\n",
    "        plt.title(title)\n",
    "        plt.legend()\n",
    "        if not name:\n",
    "            name = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "        plt.savefig(f'{name}.png')\n",
    "        plt.show()\n",
    "\n",
    "        # plt.figure(figsize=(10, 5))\n",
    "        # plt.plot(self.train_acc_list, label='Training Accuracy')\n",
    "        # plt.plot(self.eval_acc_list, label='Validation Accuracy')\n",
    "        # plt.xlabel('Epoch')\n",
    "        # plt.ylabel('Accuracy')\n",
    "        # plt.title('Accuracy Curve')\n",
    "        # plt.legend()\n",
    "        # plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "oCpaIgTRca8s"
   },
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1733360799007,
     "user": {
      "displayName": "Jacob Gronlund",
      "userId": "00200772917564897839"
     },
     "user_tz": 480
    },
    "id": "jXA0oBF70OCN",
    "outputId": "e7e2f752-662a-4f27-c5f7-987a948ed62a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "128\n",
      "128\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "print(len(filtered_df['tokenized_ingredients'][1][0]))\n",
    "print(len(filtered_df['tokenized_instructions'][1][0]))\n",
    "print(len(filtered_df['tokenized_titles'][1][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1733360799007,
     "user": {
      "displayName": "Jacob Gronlund",
      "userId": "00200772917564897839"
     },
     "user_tz": 480
    },
    "id": "4lOE7ew3Czjr",
    "outputId": "de763ca3-9a69-4081-9c58-122f686eb8c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n",
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-12-08 14:56:39,183] A new study created in RDB with name: recipe_checkpoint_12-08_14-56\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished initializing\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a814d53d60b54781b307f1f9d22c5f9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/447 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##  Optuna\n",
    "\n",
    "# name of the resuting optuna file\n",
    "current_time = datetime.now().strftime('%m-%d_%H-%M')\n",
    "study_name=f\"recipe_checkpoint_{current_time}\"\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "vocab_size = tokenizer_recipes.vocab_size\n",
    "param_path = os.path.join(GOOGLE_DRIVE_PATH, \"best_models/{}-best_model.pth\")\n",
    "os.makedirs(os.path.join(GOOGLE_DRIVE_PATH, \"best_models\"))\n",
    "recipe_embeddings_path  = os.path.join(GOOGLE_DRIVE_PATH, \"models/recipe_embeddings.pth\")\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    trial_name = f\"{study_name}__Trial_{trial.number}\"\n",
    "\n",
    "    kwargs = {\n",
    "        'epochs': 10,\n",
    "        'ingredient_tokens': filtered_df['tokenized_ingredients'].to_list(),\n",
    "        'instruction_tokens': filtered_df['tokenized_instructions'].to_list(),\n",
    "        'title_tokens': filtered_df['tokenized_titles'].to_list(),\n",
    "        'image_tensors': filtered_tensors,\n",
    "        'image_labels': filtered_df['Image_Name'],\n",
    "        'device': device,\n",
    "        'vocab_size': vocab_size,\n",
    "        'max_len': total_max,\n",
    "        'clip_model': clip_model,\n",
    "        'optimizer': 'adam',\n",
    "        'learning_rate': trial.suggest_float('lr', 1e-9, 1e-2, log=True),\n",
    "        'batch_size': 10,\n",
    "        'instance_weight': trial.suggest_float('inst_w', 1e-5, 1, log=True),\n",
    "        'sem_weight': trial.suggest_float('sem_w', 1e-5, 1, log=True),\n",
    "        'itm_weight': trial.suggest_float('itm_w', 1e-5, 1, log=True),\n",
    "        'initial_margin': 0.05,\n",
    "        'margin_step': 0.005,\n",
    "        'max_margin':0.3,\n",
    "        'best_model_parameters_path': param_path.format(f\"{trial_name}\"),\n",
    "        'decoder_lambda': trial.suggest_float('lambda', 1e-5, 1, log=True),\n",
    "        'topk': 10\n",
    "        # 'max_lengths': {\n",
    "        #     'ingredient_tokens': max_length_ing,\n",
    "        #     'instruction_tokens': max_length_inst,\n",
    "        #     'title_tokens': max_length_title\n",
    "        # }\n",
    "    }\n",
    "    torch.cuda.empty_cache() #clear cache before each run\n",
    "\n",
    "    image2recipe = Trainer(**kwargs)\n",
    "    final_loss = image2recipe.train(trial)\n",
    "    image2recipe.plot_learning_loss_curves(name=f\"{trial_name}\",\n",
    "                                           title=f\"Trial {trial.number} Loss Curves\")\n",
    "    return final_loss\n",
    "\n",
    "# Create a study object and optimize the objective function.\n",
    "# A new file will be saved called {study_name}.db containing the study\n",
    "storage_name = \"sqlite:///{}.db\".format(study_name)\n",
    "study = optuna.create_study(study_name=study_name,\n",
    "                            storage=storage_name,\n",
    "                            direction='minimize',\n",
    "                            sampler=optuna.samplers.RandomSampler(),\n",
    "                            pruner=optuna.pruners.MedianPruner(),\n",
    "                            load_if_exists=True # allows for study to be resumed\n",
    "                            )\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "pruned_trials = study.get_trials(states=(optuna.trial.TrialState.PRUNED,))\n",
    "complete_trials = study.get_trials(states=(optuna.trial.TrialState.COMPLETE,))\n",
    "\n",
    "print(\"Study statistics: \")\n",
    "print(\"  Number of finished trials: \", len(study.trials))\n",
    "print(\"  Number of pruned trials: \", len(pruned_trials))\n",
    "print(\"  Number of complete trials: \", len(complete_trials))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IQDow2_yJQO1"
   },
   "source": [
    "Now that the model is trained, use it to guess images recipes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z-U9830iF48G"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/home/chelsea/Documents/GATech/DL_group_project/insert test image path'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[1;32m     30\u001b[0m image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minsert test image path\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 31\u001b[0m tensor_image \u001b[38;5;241m=\u001b[39m preprocess_image(image_path)\n\u001b[1;32m     32\u001b[0m image2recipe \u001b[38;5;241m=\u001b[39m load_model(param_path)\n\u001b[1;32m     33\u001b[0m image_features \u001b[38;5;241m=\u001b[39m extract_image_features(tensor_image, image2recipe\u001b[38;5;241m.\u001b[39mmodel, device)\n",
      "Cell \u001b[0;32mIn[18], line 11\u001b[0m, in \u001b[0;36mpreprocess_image\u001b[0;34m(image_path)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpreprocess_image\u001b[39m(image_path):\n\u001b[0;32m---> 11\u001b[0m     image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(image_path)\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m transform(image)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/tfood_torch/lib/python3.12/site-packages/PIL/Image.py:3469\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3466\u001b[0m     filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mrealpath(os\u001b[38;5;241m.\u001b[39mfspath(fp))\n\u001b[1;32m   3468\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[0;32m-> 3469\u001b[0m     fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3470\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   3471\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/home/chelsea/Documents/GATech/DL_group_project/insert test image path'"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  #same size as training\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) #same norm as training\n",
    "])\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    return transform(image).unsqueeze(0) #add batch dim of 1 at 0 indice\n",
    "\n",
    "def extract_image_features(image, model, device):\n",
    "  model.eval()\n",
    "  with torch.no_grad():\n",
    "      image_features = model.image_encoder(image.to(device))\n",
    "      image_features = torch.nn.functional.normalize(image_features, p=2, dim=-1)\n",
    "  return image_features\n",
    "\n",
    "def load_model(model_path):\n",
    "    image_encoder = Image_Encoder(device, clip_model, num_classes).to(device)\n",
    "    recipe_encoder = RecipeEncoder(device, vocab_size, max_len).to(device)\n",
    "    mmr = MMR(hidden_dim=image_encoder.clip_model.config.projection_dim).to(device)\n",
    "    model = Image2Recipe(image_encoder, recipe_encoder, mmr).to(device)\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "image_path = \"insert test image path\"\n",
    "tensor_image = preprocess_image(image_path)\n",
    "image2recipe = load_model(param_path)\n",
    "image_features = extract_image_features(tensor_image, image2recipe.model, device)\n",
    "print(image_features.shape)\n",
    "\n",
    "recipe_embeddings = np.load(recipe_embeddings_path)\n",
    "\n",
    "\n",
    "#Compute cosine similarities\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tfood_torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "358a4e5e3b984f279ae03e8d26d43d2b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "36365b4998824614b8bfa84a9e5e86a9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_407856979a714799a01c25eec68c93d1",
      "placeholder": "​",
      "style": "IPY_MODEL_a71edb6d334e4eef82c827cbc0817a65",
      "value": "  0%"
     }
    },
    "37d2b668bb2a4230bfedaa925bb70551": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "407856979a714799a01c25eec68c93d1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5428352e9fab4cd3a415bee09d5cc6e9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "946ba10c9b9b4d4b90e317deff7c73ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ab6173676ed54c13a72323956e0fcc08",
      "placeholder": "​",
      "style": "IPY_MODEL_37d2b668bb2a4230bfedaa925bb70551",
      "value": " 0/447 [00:01&lt;?, ?it/s]"
     }
    },
    "a71edb6d334e4eef82c827cbc0817a65": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ab6173676ed54c13a72323956e0fcc08": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bdff5aea515a4f6a88a4aef08c1d0792": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c8d80345b3d04503a0ba492d2e21437f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_36365b4998824614b8bfa84a9e5e86a9",
       "IPY_MODEL_f38e682756534d4bae6e203cdb371697",
       "IPY_MODEL_946ba10c9b9b4d4b90e317deff7c73ab"
      ],
      "layout": "IPY_MODEL_bdff5aea515a4f6a88a4aef08c1d0792"
     }
    },
    "f38e682756534d4bae6e203cdb371697": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "danger",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5428352e9fab4cd3a415bee09d5cc6e9",
      "max": 447,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_358a4e5e3b984f279ae03e8d26d43d2b",
      "value": 0
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
